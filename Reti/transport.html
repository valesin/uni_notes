<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it">
<head>
<!-- 2025-04-05 Sat 19:08 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Transport layer</title>
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" onerror="this.onerror=null;this.href='local.css';" />
<script>
    window.MathJax = {
      tex: {
        ams: { multlineWidth: '85%' },
        {packages: {'[+]': ['mathtools']}},
        tags: 'ams',
        tagSide: 'right',
        tagIndent: '.8em'
      },
      chtml: {
        scale: 1.0,
        displayAlign: 'center',
        displayIndent: '0em'
      },
      svg: {
        scale: 1.0,
        displayAlign: 'center',
        displayIndent: '0em'
      },
      output: {
        font: 'mathjax-modern',
        displayOverflow: 'scale'
      },
      loader: {
        load: ['[tex]/mathtools']
      },
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Transport layer</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orge13bc42">Transmission Control Protocol (TCP)</a>
<ul>
<li><a href="#org70ca7ab">Socket</a></li>
<li><a href="#org6f04268">Header</a></li>
<li><a href="#org40ef85c">Apertura della connessione</a>
<ul>
<li><a href="#org4a11789">SYN flood</a></li>
</ul>
</li>
<li><a href="#org1e64419">Comunicazione</a>
<ul>
<li><a href="#org7d6a37f">Segmenti piccoli</a>
<ul>
<li><a href="#org4508143">Delayed ACK</a></li>
<li><a href="#org506234f">Algoritmo di Nagle</a></li>
</ul>
</li>
<li><a href="#orgc15da12">Ritrasmissione</a>
<ul>
<li><a href="#org6084d8b">Calcolo dell'RTO</a></li>
</ul>
</li>
<li><a href="#org164e067">Controllo del flusso</a>
<ul>
<li><a href="#org212d61d">Silly window syndrome</a></li>
<li><a href="#orgf84e958">Persist timer</a></li>
</ul>
</li>
<li><a href="#orga44c5b8">Controllo della congestione</a>
<ul>
<li><a href="#org7e5e6c2">Explicit congestion notification</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orga75c9e4">Chiusura della connessione</a>
<ul>
<li><a href="#org0e5940e">Timer keepalive</a></li>
</ul>
</li>
<li><a href="#org2d286f6">Timestamp</a></li>
<li><a href="#orgfb01149">Window Scale</a></li>
<li><a href="#org3e6a839">SACK</a></li>
</ul>
</li>
<li><a href="#orgfc87beb">UDP</a></li>
</ul>
</div>
</div>
<p>
Il transport layer è il primo livello <b>end-to-end</b>.
</p>

<p>
I due protocolli diffusi a questo livello sono <b>TCP</b> e <b>UDP</b>.
</p>
<div id="outline-container-orge13bc42" class="outline-2">
<h2 id="orge13bc42">Transmission Control Protocol (TCP)</h2>
<div class="outline-text-2" id="text-orge13bc42">
<p>
Il protocollo <b>TCP</b> ha fra i vari obiettivi quelli di:
</p>
<ul class="org-ul">
<li>reimplementare l'<b>affidabilità</b> su un network best-effort quale IP;</li>
<li>implementare il <b>controllo degli errori</b>;</li>
<li>operare <b>controllo di flusso</b> (orizzontale), ovvero evitando l'overflow nel caso di differenze nel rate in e rate out in una connessione;</li>
<li>operare un <b>controllo di congestione</b> (verticale), riconoscendo una rete congestionata e diminuendo il rate di immissione sulla stessa.</li>
</ul>

<p>
TCP è basato sulla <b>connessione</b>. Prima che avvenga lo scambio di dati, i due host TCP stabiliscono una connessione logica fra essi, inizializzando i numeri di sequenza. La connessione è <b>bilaterale</b>.
</p>

<p>
Inoltre, esso è basato sullo <b>stream di byte</b>.
</p>

<p>
L'<b>indirizzamento</b> in TCP avviene utilizzando delle <b>porte</b>, che servono per identificare l'applicazione che sta usando una specifica connessione.
</p>
</div>
<div id="outline-container-org70ca7ab" class="outline-3">
<h3 id="org70ca7ab">Socket</h3>
<div class="outline-text-3" id="text-org70ca7ab">
<p>
Il TCP utilizza delle <b>socket</b>, ovvero degli <b>endpoint</b> per scambiare dati sul network.
</p>

<p>
Lo standard <i>de facto</i> è quello di <b>Berkeley Unix</b>.
</p>

<p>
Il funzionamento prevede una chiamata alla primitiva <code>socket()</code> che genera <b>Access Point</b> lato client e lato server, insieme ai <b>sending</b> e <b>receiving buffer</b>, sui quali l'applicazione scrive o da cui legge.
</p>

<p>
Il protocollo TCP, in base a specifici criteri, si occupa di svuotare il sending buffer e riempire il receiving, avvalendosi di un <b>ulteriore livello di buffer</b>, in modo da garantire l'ordine.
</p>

<p>
Attraverso la chiamata <code>bind()</code>, con parametri un IP e una porta, si specifica l'indirizzo IP e la porta assegnati alla specifica socket.
</p>

<p>
La <code>listen()</code> crea una coda di richieste per la specifica socket.
</p>

<p>
A questo punto, il server è in attesa, mediante <code>accept()</code> e questa si chiama <b>apertura passiva</b>.
</p>

<p>
Il client aprirà una socket con <code>socket()</code> e una <code>connect()</code> sull'IP e porte decise dalla <code>bind()</code> del server, rimanendo in attesa con <code>accept()</code>.
</p>

<p>
A quel punto, il server fa una sequenza <code>fork()</code>, <code>socket()</code>, <code>bind()</code> per avere un nuovo access point e soddisfare le richieste del client. Ora la connessione è attiva e questa si chiama <b>apertura attiva</b>.
</p>

<p>
Una serie di <code>send()</code> e <code>receive()</code> permette lo scambio di informazioni fino alla <code>receive(EOF)</code>, seguita da una <code>close()</code>.
</p>

<p>
Una quintupla <b>[protocol, IPsrc, IPdst, portSrc, portDst]</b> descrive univocamente una comunicazione aperta con le chiamate di primitiva socket.
</p>
</div>
</div>
<div id="outline-container-org6f04268" class="outline-3">
<h3 id="org6f04268">Header</h3>
<div class="outline-text-3" id="text-org6f04268">
<p>
Lo header TCP è costituito da pagine larghe \(32\) bit.
</p>

<p>
Le porte sorgente e destinazione occupano \(16\) bit ciascuna.
</p>

<p>
Poi c'è il numero di sequenza da \(32\) bit.
</p>

<p>
Il campo <code>ACK</code> da \(32\) bit indica il prossimo numero di sequenza che ci si aspetta.
</p>

<p>
C'è poi il campo <b>Maximum Segment Size</b> il cui valore di default è \(536\), in modo da evitare che IP frammenti, introducendo overhead per gli header e aumentando il rischio di problemi nella trasmissione.
</p>

<p>
Il resto dei campi sono legati alle funzionalità fornite dal TCP.
</p>
</div>
</div>
<div id="outline-container-org40ef85c" class="outline-3">
<h3 id="org40ef85c">Apertura della connessione</h3>
<div class="outline-text-3" id="text-org40ef85c">
<p>
Il TCP opera una apertura in 3 fasi chiamata <b>three-way handshake</b>.
</p>

<p>
Entrambe le macchine inizializzano un <b>numero di sequenza casuale</b> (nell'esempio \(x\) e \(y\)), per motivi di sicurezza.
</p>

<p>
Le tre fasi sono le seguenti:
</p>
<ul class="org-ul">
<li>il client chiede l'apertura mandando un segmento con i campi: <b>SYN</b> = 1, <b>Seq</b> = \(x\);</li>
<li>se l'AP del server (ovvero IP/portaTCP) è in <code>listen()</code>, il server risponde con:  <b>SYN</b> = 1, <b>Seq</b> = y, <b>ACK</b> = 1, <b>Ack</b> = \(x+1\), dove <b>ACK</b> indica che il valore <b>Ack</b> è significativo. Se il server non è in <code>listen()</code>, risponde con <b>RST</b> = 1.</li>
<li>il client conferma l'apertura con <b>ACK</b> = 1, <b>Ack</b> = \(y+1\).</li>
</ul>

<p>
I campi non indicati nell'esempio sono irrilevanti.
</p>

<p>
Esiste inoltre un timer <b>RTO</b> alla scadenza del quale si assume che qualche segmento sia stato perso e si ritenta l'apertura della connessione.
</p>
</div>
<div id="outline-container-org4a11789" class="outline-4">
<h4 id="org4a11789">SYN flood</h4>
<div class="outline-text-4" id="text-org4a11789">
<p>
È possibile sfruttare il three-way handshake maliziosamente aprendo tante connessioni senza finalizzarle con il terzo handshake.
</p>

<p>
Il server dovrà tenere in tabella le informazioni di tutte le richieste arrivate. Questo attacco si chiama <b>SYN flood</b>.
</p>

<p>
Rispondendo con un <b>RST</b> = 1 come terzo segmento si evita di pesare computazionalmente al server, ma vengono analizzate le porte aperte. Questa procedura si chiama <b>port scanning</b>.
</p>
</div>
</div>
</div>
<div id="outline-container-org1e64419" class="outline-3">
<h3 id="org1e64419">Comunicazione</h3>
<div class="outline-text-3" id="text-org1e64419">
<p>
Una volta aperta la connessione mediante il <b>three-way handshake</b>, può iniziare la trasmissione.
</p>

<p>
Immaginiamo, per semplicità, che la Maximum Segment Size sia \(500\).
</p>

<p>
Una comunicazione <b>senza errori</b> andrebbe così:
</p>
<ul class="org-ul">
<li>il livello applicazione lato sender scrive 2000 byte nel <b>sending buffer</b> della socket in questione;</li>
<li>i 2000 byte vengono inseriti nel <b>TCP sending buffer</b>, divisi in \(4\) segmenti da 500 byte;</li>
<li>il TCP lato <b>client</b> manda uno dei segmenti con <b>SEQ</b> = X</li>
<li>il TCP lato <b>server</b> riconosce che il byte che attendeva era proprio \(X\), mette il contenuto del segmento nel <b>TCP receiving buffer</b> e risponde con un segmento con header contenente <b>ACK</b> = 1 e <b>Ack</b> = \(X + 500\)</li>
<li>il TCP lato <b>server</b> muove immediatamente il contenuto al <b>receiving buffer</b> esposto all'applicazione, perchè i nuovi byte sono in ordine.</li>
</ul>

<p>
Si procede così fino alla fine della comunicazione.
</p>
</div>
<div id="outline-container-org7d6a37f" class="outline-4">
<h4 id="org7d6a37f">Segmenti piccoli</h4>
<div class="outline-text-4" id="text-org7d6a37f">
<p>
Quando l'applicazione richiede uno scambio di dati atomici real-time, come <b>ssh</b> o <b>telnet</b> su server remoto, può farlo settando la flag <b>PUSH</b> a \(1\).
</p>

<p>
In questo caso, la Maximum Segment Size viene ignorata e il singolo byte è trasmesso.
</p>

<p>
Il server risponde con una <b>echo</b> del byte inviato, in modo che il client è sicuro che il byte sia stato recepito e l'applicazione può prenderlo dal receiving buffer.
</p>

<p>
Sia il carattere originale che l'echo prevedono <code>ACK</code>.
</p>

<p>
Di conseguenza, questa tecnica prevede un totale di <b>4 segmenti</b>, due di dati uguali e due di ack.
</p>
</div>
<div id="outline-container-org4508143" class="outline-5">
<h5 id="org4508143">Delayed ACK</h5>
<div class="outline-text-5" id="text-org4508143">
<p>
Per limitare l'overhead causato dai 4 segmenti per byte nel caso del PSH=1, viene utilizzato il <b>delay acknowledgment</b>.
</p>

<p>
Il server, alla ricezione del byte, non emette subito l'<code>ACK</code>, ma attende un certo tempo (default \(200ms\)), alla scadenza del quale invia l'intero contenuto del sending buffer, utilizzando questo segmento come <code>ACK</code>.
</p>

<p>
Questa tecnica si chiama <b>piggybacking</b> e riduce il numero di segmenti scambiati.
</p>

<p>
Anche la <b>echo</b> è contenuta in questo segmento <i>duplice</i>.
</p>

<p>
La tecnica del delayed ACK è efficiente per la rete, ma non per la <b>user-experience</b>.
</p>

<p>
Infatti, essa comporta un <b>ritardo costante minimo</b> per l'aggiornamento dell'applicazione lato client
</p>
</div>
</div>
<div id="outline-container-org506234f" class="outline-5">
<h5 id="org506234f">Algoritmo di Nagle</h5>
<div class="outline-text-5" id="text-org506234f">
<p>
Per ovviare alla scarsa user-experience del delayed ACK, viene utilizzata la tecnica dell'<b>algoritmo di Nagle</b>.
</p>

<p>
Essa combina l'utilizzo di PSH e dei segmenti normali.
</p>

<p>
Il primo byte della comunicazione è inviato da solo, poi il sender si mette in attesa di ricevere l'ack/echo. A quel punto, viene trasmesso l'intero contenuto del sending buffer (o un segmento intero se la dimensione e maggiore o uguale alla Maximum Segment Size)
</p>

<p>
Quindi, il server risponde con una echo prima e un semplice <b>ack cumulativo</b> poi.
</p>
</div>
</div>
</div>
<div id="outline-container-orgc15da12" class="outline-4">
<h4 id="orgc15da12">Ritrasmissione</h4>
<div class="outline-text-4" id="text-orgc15da12">
<p>
Utilizzando un <b>ACK cumulativo</b>, il campo <b>Ack</b> del ricevitore è sempre fermo all'indice del primo byte che ci si aspetta.
</p>

<p>
Se un segmento viene perso, l'<code>ACK</code> rimarrà ancorato al primo byte di quel segmento.
</p>

<p>
In questo caso, in TCP, il sender continua ad <b>inviare segmenti successivi</b>, fino alla scadenza dell'<b>RTO</b> (<i>retransmission timeout interval</i>), quando il segmento a cui l'<code>ACK</code> è fermo viene reinviato.
</p>

<p>
Inoltre, viene usata una tecnica chiamata <b>fast retransmit</b>, che prevede che al <b>terzo ACK</b> fermo ad un certo numero di sequenza, si assume che il relativo segmento sia smarrito e viene reinviato, anche prima della scadenza dell'RTO.
</p>

<p>
Il timer rimane necessario per alcuni casi, ad esempio negli <b>ultimi 2 segmenti</b>, dopo i quali non esistono 3 <code>ACK</code> che attivino la fast retransmit.
</p>
</div>
<div id="outline-container-org6084d8b" class="outline-5">
<h5 id="org6084d8b">Calcolo dell'RTO</h5>
<div class="outline-text-5" id="text-org6084d8b">
<p>
La formula per il calcolo del RTO, come indicata nella <b>RFC6298</b> prevede di calcolare l'RTO sulla base dello <b>SRTT</b> (<i>smoothed round trip time</i>) e del <b>RTTVAR</b> (<i>round-trip time variation</i>) come segue:
\[\text{RTO} = \text{SRTT} + 4\text{RTTVAR}\]
</p>

<p>
I due valori nella formula dipendono dalla misurazione \(R\) del tempo effettivo fra l'invio del segmento e la ricezione dell'<code>ACK</code>.
</p>

<p>
Quando la <b>prima misurazione</b> è effettuata, si assegnano \(\text{SRTT} = R\) e \(\text{RTTVAR} = \frac{R}{2}\), quindi \(\text{RTO} = 3R\).
</p>

<p>
Dalla <b>seconda</b> misurazione <b>in poi</b>, i valori sono i seguenti:
</p>
\begin{*align}
\text{SRTT} = \alpha \cdot \text{SRTT} + (1-\alpha) \cdot R \\
\text{RTTVAR} = \beta\cdot \text{RTTVAR} + (1-\beta)\cdot |\text{SRTT}-R|
\end{*align}

<p>
I valori consigliati nella <b>RFC6298</b> sono \(\alpha = \frac{7}{8}\) e \(\beta = \frac{3}{4}\)
</p>
</div>
</div>
</div>
<div id="outline-container-org164e067" class="outline-4">
<h4 id="org164e067">Controllo del flusso</h4>
<div class="outline-text-4" id="text-org164e067">
<p>
Quando il sender è più veloce ad inviare di quanto il receiver lo sia ad elaborare i dati, il buffer di ricezione si <b>satura</b> e tutti i segmenti successivi vengono <b>scartati</b>, causando un'<b>inefficienza</b>.
</p>

<p>
Viene quindi introdotto il <b>controllo di flusso</b>, che garantisce che ci sia sempre spazio libero nel buffer per i nuovi dati in arrivo.
</p>

<p>
A questo proposito vengono introdotte le due variabili \(W_s\) e \(W_r\), ovvero dimensione della finestra di invio e di ricezione.
</p>

<p>
Queste variabili sono aggiornate nel singolo host TCP l'una in base al numero di byte liberi nel buffer dell'altro host e l'altra in base al proprio.
</p>

<p>
Per ottenere il numero di byte liberi nell'altra macchina, si utilizza il campo <b>Win</b>, che comunica esattamente questa informazione.
</p>

<p>
Quando il buffer del ricevente si satura, esso manda un segmento con <b>Ack</b> uguale al byte successivo all'ultimo correttamente ricevuto e <b>Win = 0</b>.
</p>

<p>
Il sender, quindi, ferma la trasmissione.
</p>

<p>
Quando il ricevitore legge \(x\) byte, manda un nuovo segmento con <b>stesso Ack</b> e <b>Win</b> = \(x\).
</p>

<p>
Così il sender può riprendere l'invio fino ad una nuova saturazione.
</p>
</div>
<div id="outline-container-org212d61d" class="outline-5">
<h5 id="org212d61d">Silly window syndrome</h5>
<div class="outline-text-5" id="text-org212d61d">
<p>
La tecnica utilizzata per il controllo di flusso, in cui uno host con buffer saturo comunica appena dello spazio è liberato, comporta un <b>problema</b>.
</p>

<p>
Immaginiamo di avere una applicazione dal lato del ricevitore che legge <b>un byte alla volta</b>, e che il sender invii un <b>grande file</b> che occupi l'<b>intero buffer</b>.
</p>

<p>
In questi casi, si verifica la <b>silly window syndrome</b>, che consiste in questo ciclo:
</p>
<ul class="org-ul">
<li>il receiver si satura e invia un <code>ACK</code> con <b>Win = 0</b>;</li>
<li>il receiver legge un byte, togliendolo dal buffer, poi invia un segmento con <b>Win = 1</b>;</li>
<li>il sender allora invia un segmento contenente <b>un solo byte</b>;</li>
<li>ricomincia da capo&#x2026;</li>
</ul>

<p>
La soluzione è l'<b>algoritmo di Clark</b>, che <b>impedisce</b> agli host TCP di <b>annunciare</b> una finestra che sia più piccola sia della <b>metà del buffer</b> che della <b>Maximum Segment Size</b>.
</p>
</div>
</div>
<div id="outline-container-orgf84e958" class="outline-5">
<h5 id="orgf84e958">Persist timer</h5>
<div class="outline-text-5" id="text-orgf84e958">
<p>
Immaginiamo la situazione in cui il sender sia fermo perchè la finestra di invio \(W_s = 0\).
</p>

<p>
Quando il receiver legge dei dati e libera spazio nel buffer, lo comunica mediante nel campo <b>Win</b> di un nuovo segmento.
</p>

<p>
Se quel segmento venisse smarrito, il sender rimarrebbe bloccato con \(W_s = 0\), mentre il receiver rimarrebbe in attesa con \(W_r > 0\).
</p>

<p>
Per risolvere lo stallo, viene introdotto un timer detto <b>persist timer</b>, alla scadenza del quale il sender manda un segmento contenente <b>un solo byte</b>, per controllare la situazione del receiver, il quale risponderà con un segmento con <b>Ack</b> uguale al byte successivo a quello inviato e <b>Win</b> uguale allo spazio libero.
</p>

<p>
Se invece non fosse stato smarrito alcun segmento, ma il receiver fosse veramente saturo, risponderà con un nuovo segmento con <b>Win = 0</b>.
</p>

<p>
La procedura si ripete ogni <b>60 secondi</b>, finchè il buffer di ricezione si liberi, o la connessione venga chiusa dopo un certo numero di tentativi.
</p>
</div>
</div>
</div>
<div id="outline-container-orga44c5b8" class="outline-4">
<h4 id="orga44c5b8">Controllo della congestione</h4>
<div class="outline-text-4" id="text-orga44c5b8">
<p>
Quando la rete è congestionata e i router nella rete sono costretti a scartare dei pacchetti (vedi <a href="terzo.html#ID-5cf15a68-c0c4-40c9-8889-e9d4150881d1">Network layer</a>), TCP mette in atto delle politiche per ridurre il numero di segmenti inviati ed allo stesso tempo non contribuire alla congestione della rete.
</p>

<p>
Il controllo della congestione assume che ogni segmento non ricevuto dall'altro host (riconoscibile da 3 <code>ACK</code> consecutivi sul primo byte di tale segmento) ed ogni <code>ACK</code> non ricevuto, siano stati persi <b>a causa della congestione</b> e non per errori di trasmissione. L'uso estensivo della fibra garantisce infatti una ridotta corruzione dei dati.
</p>

<p>
Ogni host mantiene una variabile detta <b>finestra di congestione</b> \(W_{c}\) che, come per le finestre di ricezione ed invio nel controllo di flusso, limita la <b>finestra di invio</b>.
</p>

<p>
All'apertura della trasmissione, \(W_c\) è uguale alla <b>MSS</b> ed aumenta <b>esponenzialmente</b>. Questa si chiama <b>fase di partenza lenta</b>.
</p>

<p>
Una volta raggiunto lo <b>slow start threshold</b> (SST), impostato di solito a <b>64 byte</b>, si entra nella <b>fase di prevenzione della congestione</b>, in cui la finestra di congestione aumenta linearmente alla MSS. Quindi, ad ogni ricezione di un <code>ACK</code> \(W_c^{'} = W_c + \text{MSS}\).
</p>

<p>
Una volta raggiunta una <b>seconda soglia</b>, il valore di \(W_c\) rimane costante.
</p>

<p>
La finestra viene <b>decrementata</b> quando accade un evento che dimostri la <b>perdita di un pacchetto</b>, ovvero la <b>scadenza dell'RTO</b> o l'attivazione della <b>fast retransmit</b> in caso di 3 <code>ACK</code> uguali.
</p>

<p>
Nel caso della <b>fast retransmit</b>, si suppone che la congestione sia <b>lieve</b> e quindi si <b>dimezza</b> la finestra e si imposta lo <b>slow start threshold</b> a quel valore, in modo da ricominciare subito in <b>fase di prevenzione della congestione</b>.
</p>

<p>
Nel caso della <b>scadenza dell'RTO</b>, si presume che la congestione sia <b>elevata</b> e si imposta immediatamente la finestra ad \(1\).
</p>
</div>
<div id="outline-container-org7e5e6c2" class="outline-5">
<h5 id="org7e5e6c2">Explicit congestion notification</h5>
<div class="outline-text-5" id="text-org7e5e6c2">
<p>
<b>ECN</b> (<i>Explicit congestion notification</i>) è una funzione di livello 3, sfruttata da TCP.
</p>

<p>
Se entrambi gli host TCP sono abilitati all'utilizzo di ECN, possono <b>negoziare</b> il suo utilizzo con le apposite opzioni durante il <b>three-way handshake</b>.
</p>

<p>
Quando un router utilizza una funzione di <b>active queue management</b> come <b>RED</b>, se entrambi gli endpoint supportano la funzione di <b>ECN</b>, al posto di <b>scartare il pacchetto</b> scrive nel campo <b>ECN</b> dello header o negli <b>ultimi 2 bit</b> del campo <b>Traffic Class</b> un <b>segnale di congestione</b>.
</p>

<p>
Quando il segmento arriva a destinazione, lo host TCP viene segnalato e effettua una <b>echo</b> del segnale con il bit <b>ECE</b> (<i>ECN-echo</i>) settato.
</p>

<p>
Alla ricezione di tale segnale, il sender agisce decrementando la finestra di congestione ugualmente al caso della <b>fast retransmit</b>. Poi, risponde con un <b>CWR</b> (<i>Congestion Window Reduced</i>).
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orga75c9e4" class="outline-3">
<h3 id="orga75c9e4">Chiusura della connessione</h3>
<div class="outline-text-3" id="text-orga75c9e4">
<p>
Esistono <b>quattro tipologie</b> di chiusura della connessione:
</p>
<ul class="org-ul">
<li><b>chiusura attiva/passiva</b>:: lo host <b>attivo</b> manda un segmento con <b>FIN=1</b>, a cui quello <b>passivo</b> risponde con un <code>ACK</code> ad \(X+1\), come se il segmento di fine fosse lungo un byte e con un <b>EOF</b> segnala che i dati in arrivo sono terminati.
Poi manda un <b>FIN=1</b> a sua volta.
Quando lo host <b>attivo</b> riceve il segmento di fine, manda un <code>ACK</code> a sua volta e fa partire un timer detto <b>2MSL</b> (<i>Maximum Segment Life</i>) e va in stato <b>TIMED<sub>WAIT</sub></b>, ovvero il doppio del tempo massimo che un segmento può rimanere in rete. In questo modo, nel caso in cui l'<code>ACK</code> fosse perso, esso sarebbe ancora in grado di ricevere il <b>FIN</b> da parte dello host passivo <b>ritrasmesso</b>.</li>
<li><b>piggyback</b>:: se lo host che avvia la chiusura <b>attiva</b> sta ancora trasmettendo, può mandare un segmento che contiene gli ultimi dati e il bit <b>FIN</b> settato. Lo host passivo, a sua volta, può fare piggybacking con un segmento che è sia di <code>ACK</code> che di fine. In questo modo, la chiusura è in 3 passaggi, invece che 4.</li>
<li><b>chiusura simultanea</b>:: se gli host avviano la chiusura <b>contemporaneamente</b>, ovvero ricevono un segmento di fine quando ne avevano già mandato uno, allora inviano entrambi anche l'<code>ACK</code> e fanno partire il timer <b>2MSL</b>, alla fine del quale la connessione sarà chiusa.</li>
<li><b>mezza chiusura</b>:: quando lo host che riceve il segmento di fine non ha ancora completato la trasmissione dei segmenti in buffer, esso indica con un <b>EOF</b> che la ricezione è finita, ma continua a trasmettere, aspettandosi normalmente degli <code>ACK</code>. Quando avrà finito, invierà a sua volta un segmento di fine e tutto finisce come nel caso standard, ovvero con lo host attivo che fa partire un timer e poi chiude.</li>
</ul>
</div>
<div id="outline-container-org0e5940e" class="outline-4">
<h4 id="org0e5940e">Timer keepalive</h4>
<div class="outline-text-4" id="text-org0e5940e">
<p>
Se uno host si disconnette senza effettuare alcuna procedura di chiusura, l'altro host rimane bloccato in attesa di nuovi segmenti.
</p>

<p>
Per ovviare al problema, viene introdotto un timer di durata standard uguale a <b>2 ore</b>.
</p>

<p>
Se questo scade, lo host manda un <code>probe</code> segmento <b>vuoto</b> e con <b>Seq = X-1</b>. Se è ancora attivo, l'altro host risponde con un <code>ACK</code> con la sua attuale V(R).
</p>

<p>
Se l'altro host è irragiungibile dopo 2 ore, viene rimandato il <code>probe</code> con timer \(75\) secondi. Dopo il <b>decimo</b> probe senza successo, la connessione viene chiusa.
</p>
</div>
</div>
</div>
<div id="outline-container-org2d286f6" class="outline-3">
<h3 id="org2d286f6">Timestamp</h3>
<div class="outline-text-3" id="text-org2d286f6">
<p>
Per il controllo degli errori è necessario che venga calcolato il <b>round trip time</b> per settare il <b>RTO</b> dopo cui ritrasmettere un segmento senza <code>ACK</code>.
</p>

<p>
Spesso il calcolo non viene effettuato per ogni segmento, ma ogni certo numero di essi.
</p>

<p>
Questo dà luogo ad una misurazione molto approssimata del round trip time.
</p>

<p>
Per ottenere una misurazione più accurata, gli host possono negoziare in apertura una funzione detta <b>time-stamp</b>.
</p>

<p>
Questa prevede che entrambi gli host mantengono un <b>timer indipendente</b> e includano il suo valore ad ogni invio di un segmento. Tale valore è poi restituito nel momento dello <code>ACK</code> e la differenza fra la ricezione dell'<code>ACK</code> e il timestamp sono uguali all'RTT.
</p>

<p>
Quando è usato il <b>delayed ACK</b>, vale sempre il <b>primo timestamp</b>, in quanto è necessario che il sender includa il tempo necessario per l'invio di tutti i segmenti della finestra, prima di ritrasmettere.
</p>

<p>
Il receiver usa una variabile che contiene l'ultimo timestamp <b>che ha fatto avanzare l'estremo sinistro della finestra</b> e inserisce il suo valore negli <code>ACK</code> di risposta.
</p>

<p>
Quindi esistono 3 casi:
</p>
<ul class="org-ul">
<li>Gli \(n\) segmenti arrivano in ordine. Lo host riceve il primo segmento, salva il timestamp in una variabile e quindi ricevuto l'$n$-esimo segmento manda uno <code>ACK</code> che comprende il timestamp del primo segmento.</li>
<li>Viene ricevuto un segmento fuori ordine. Allora il receiver continua a includere l'ultimo timestamp che ha fatto scorrere la parte sinistra della finestra, che sarà una sovrastima dell'RTT ma utile perchè la perdita del pacchetto può indicare congestione.</li>
<li>Viene ricevuto un segmento che <i>riempie un buco</i>. Allora il receiver aggiorna la variabile e fa echo di quel timestamp.</li>
</ul>

<p>
Inoltre, il sender mantiene una variabile per il timestamp del primo segmento. In questo modo, se il primo segmento è perso e il receiver non contiene nessun timestamp per quella finestra, il sender la include nella ritrasmissione. Anche questa è una sovrastima.
</p>
</div>
</div>
<div id="outline-container-orgfb01149" class="outline-3">
<h3 id="orgfb01149">Window Scale</h3>
<div class="outline-text-3" id="text-orgfb01149">
<p>
Quando degli host TCP comunicano su un network lungo e ad alta bandwidth possono attivare la funzione <i>window scale</i>, in un opzione dello header e negoziata all'inizio, indicando un <b>fattore</b> per cui moltiplicare la dimensione della finestra indicata.
</p>

<p>
Lo header contiene un numero di <b>shift</b> da effettuare fino a <b>14</b>, quindi i <b>16</b> bit della finestra possono indicare fino a \(2^{30}\) bytes.
</p>

<p>
Una volta negoziato questo fattore di shift, ogni host manda una dimensione della finestra che è in realtà ridotta dello stesso fattore, in modo che l'alto possa ricostituirla.
</p>

<p>
La dimensione della finestra è comunque sempre controllata dalla dimensione del buffer di ricezione.
</p>

<p>
In questo modo aumenta l'utilizzo delle reti lunghe e ad alta bandwidth.
</p>
</div>
</div>
<div id="outline-container-org3e6a839" class="outline-3">
<h3 id="org3e6a839">SACK</h3>
<div class="outline-text-3" id="text-org3e6a839">
<p>
Quando un <code>ACK</code> non è ricevuto dal sender, quest'ultimo attende 3 <code>ACK</code> o un RTO. Se la distanza è lunga, il tempo perso sarebbe notevole.
</p>

<p>
La funzione <b>SACK</b>, negoziata in apertura attiva con il segmento SYN, prevede di utilizzare un campo opzione per inserirvi gli ACK per i segmenti ricevuti fuori sequenza.
</p>

<p>
In questo modo il sender riconosce velocemente i "buchi" nella sequenza e può ritrasmetterli senza aspettare la scadenza dell'RTO o il fast retransmit.
</p>
</div>
</div>
</div>
<div id="outline-container-orgfc87beb" class="outline-2">
<h2 id="orgfc87beb">UDP</h2>
<div class="outline-text-2" id="text-orgfc87beb">
<p>
UDP non implementa alcune delle funzionalità di TCP su flusso, congestione o errori.
</p>

<p>
Le primitive consistono in <code>socket</code> e <code>bind</code> per aprire una porta e poi soltanto <code>sendto</code> e <code>receive</code>. <code>shutdown</code> per chiudere.
</p>

<p>
Non è a stream di byte ma a datagrammi ed opera in modo analogo ad IP.
</p>

<p>
Ogni segmento in UDP viene arricchitto di un piccolo header contenente soltanto:
</p>
<ul class="org-ul">
<li>porta di origine e di destinazione, 32 byte</li>
<li>lunghezza e checksum, 32 byte</li>
</ul>

<p>
Il checksum è calcolato su uno <b>pseudo-header</b> che comprende alcune parti dello header IP e usa lo stesso algoritmo del checksum IP (somma in complemento a uno).
</p>

<p>
Anche in UDP la MSS è legata alla minima MTU delle reti che vengono attraversate.
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2025-04-05 Sat 19:08</p>
</div>
</body>
</html>
