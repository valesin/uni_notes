<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-12-18 Wed 14:55 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Retibozza</title>
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" onerror="this.onerror=null;this.href='local.css';" />
<script>
    window.MathJax = {
      tex: {
        ams: { multlineWidth: '85%' },
        {packages: {'[+]': ['mathtools']}},
        tags: 'ams',
        tagSide: 'right',
        tagIndent: '.8em'
      },
      chtml: {
        scale: 1.0,
        displayAlign: 'center',
        displayIndent: '0em'
      },
      svg: {
        scale: 1.0,
        displayAlign: 'center',
        displayIndent: '0em'
      },
      output: {
        font: 'mathjax-modern',
        displayOverflow: 'scale'
      },
      loader: {
        load: ['[tex]/mathtools']
      },
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Retibozza</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0dd4273">References</a></li>
<li><a href="#orgf255c02">Host computer dove risiedono le app finali e un sistema di rete composto da un insieme di nodi e link.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#orga72eea2">Gli unici dati che viaggiano nel sistema sono denominati pacchetti, di dimensione massima fissa. Semplifica l'architettura dei nodi di switch, cioè i router, che svolgono funzionalità di instradamento. In questo modo ogni router si occupa soltanto di ricevere e smistare i pacchetti su link stabiliti in base a metriche di instradamento.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#org048c219">Una divisione funzionale delle varie parti è: il sistema di reti, attraverso ip, decide il percorso migliore in base a quel momento specifico (le condizioni variano nel tempo), concetto chiamato instradamento.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#org10c3285">Pacchetti con stesso mittente e destinatario non necessariamente percorrono lo stesso cammino. Non solo la comunicazione non è affidabile, ma anche ogni pacchetto è completamente indipendente dagli altri, sebbene siano tutti risultato dello stesso processo di frammentazione da parte dell'host. Servirà poi un modo per reassemblarli a destinazione.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#orge760ef0">Ogni pacchetto è indipendente, ma in qualche modo verrà ricostruito, quindi c'è qualche legame logico fra il singolo frammento e l'unità generale. Finchè i pacchetti sono nel sistema di rete, questo collegamento è perso.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#org453408d">A questo punto abbiamo definito dei concetti come affidabilità e valori tempo di trasmissione, tempo di propagazione, round-trip tie, error-rate su un canale, gitter, che tornano.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#org2248166">Abbiamo identificato le componenti architetturali di una rete, con link fra router e host, entrambi con software e funzioni utili alla comunicazione, IP lato router e TCP lato host&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#orgb9fa6b1">Adesso analizzeremo le altre componenti della rete, e come sono organizzate all'interno della struttura, le varie funzioni di rete.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#orgba3d816">Per la struttura gerarchica a 5 (7) livelli, i collegamenti fra le due macchine sorgente e destinazione sono allo stesso livello. Non sono ammesse cross-layer communication.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#org3c3b284">Finora abbiamo capito come, su un canale che collega il nodo a al nodo b, inviare frame in modo affidabile (rimando alle 3 condizioni)&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></a></li>
<li><a href="#org0c61d0a">A volte la topologia di rete è un grafo parzialmente connesso e in particolare in cui i punti sono collegati fra loro in una <b>maglia</b>, ed è per questo chiamata anche punto-a-punto, ma spesso non è così.</a>
<ul>
<li><a href="#orga6bd011">In una LAN (local a.. network) la rete è broadcast, ovvero c'è un dispositivo che comunica a tutti gli altri, compreso quello da cui ha ricevuto il segnale in entrata. Ovvero un HUB, chiamato anche <b>centro stella passivo</b></a></li>
<li><a href="#org1f978e3">Un terzo modo, che è come ethernet era fatto inizialmente, si ha una struttura a bus lineare, in cui tutti i dispositivi sono collegati in serie. Sia questa che la seconda sono chiamate <b>broadcast</b>.</a></li>
<li><a href="#org6d810c1">Il problema delle strutture broadcast è innanzitutto quello di creare l'equivalente semantico di una comunicazione fra due soli dispositivi, e si fa utilizzando header di mittente e destinatario, così che nel secondo driver di IO capiscono se salvano o buttano via i dati.</a></li>
<li><a href="#org2881bba">Un altro problema è che trasmettere sull'hub o su bus lineare è critico e va quindi garantita la mutua esclusività per l'accesso a canale condiviso: non tutti i dispositivi possono trasmettere nello stesso momento.</a>
<ul>
<li><a href="#org7e3739a">Si può sfruttare un token unico e condiviso dalle stazioni. La struttura è fatta ad anello e chi lo riceve, lo estrae e trasmette. Una volta che la trasmissione torna al primo dispositivo, vuol dire che la comunicazione è arrivata a tutti e cede il token ad un altro.</a></li>
<li><a href="#org5d8c7ae">Ethernet utilizza, invece, una soluzione <b>non deterministica</b>, fuzzy, in cui c'entra molto la probabilità ed in cui le collisioni sono ammesse, chiamato CSMA-CD.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org6356937">Di solito, alla salita del fronte d'onda, legge il valore in volt, e se è 5 il bit è 1, altrimenti 0</a>
<ul>
<li><a href="#orgb0cf1f5">Con ethernet, però, abbiamo vari problemi. Uno è quello di disambiguare sequenze di bit uguali, un'altra è quella di far arrivare il valore in modo chiaro al ricevitore.</a>
<ul>
<li><a href="#org838dfae">Ethernet utilizza quindi la codifica Manchester, che a differenza del solito, legge nel momento centrale del bit, che è il punto meno soggetto a distorsione.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org79cdd2e">Per stabilire l'utilizzo (efficienza) del mio MAC layer, che presiede la connessione Ethernet, bisogna introdurre al tempo di propagazione, nella formula originale, ovvero tx su tx + 2tp, il contention time medio, ovvero il tempo perso in carrier sense, nel discardare trasmissioni corrotte e nei ritardi. (Bisogna sommare l'inverso (perchè?), e quindi 1/A)</a>
<ul>
<li><a href="#org949a6dc">Si dimostra che al tendere delle stazioni K all'infinito, 1/A tende a "e".</a></li>
<li><a href="#org9f31a1b">Inoltre, si ricorda che abbiamo definito tx come dimFrame/velBanda e tp come Lunghezza/velCavo.</a>
<ul>
<li><a href="#org1aca4cd">Allora divido tutto per tx e ottengo \(\frac{1}{1+2 \frac{BL}{CF}e }\). Quindi, all'aumentare della banda e della lunghezza, l'utilizzo diminuisce di tanto.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgc17ce27">Per aumentare le prestazioni di Ethernet, potrei scalare il tasso di trasmissione di un ordine di grandezza. Il problema è che il rame non va oltre 25Mbps.</a>
<ul>
<li><a href="#org8c4e1f1">Una soluzione immediata sarebbe quella di usare 4 fili e dividere un bit in ognuno. In realtà, se ne usano solo 3 per la trasmissione, perchè il 2 è quello usato per CarrierSense e CollisionDetection.</a></li>
<li><a href="#org7e91497">Come si raggiungono 1000Mbit, con solo 3 fili da 25Mbps? Si usa una codifica diversa, ternaria non binaria, chiamata 8B6T, ovvero "mappo 8 bit Binari su 6 Ternari".</a>
<ul>
<li><a href="#org1bfed1d">A questo punto abbiamo 100 * 10<sup>6</sup> Mbit *6/8 diviso i 3 fili, ottengo 25 bit ternari per filo, che corrispondono a 33 binari.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org0b89e4e">Nell'architettura Ethernet, il primo apparato utilizzato è il repeating hub, passivo, in cui tutte le stazioni contendono per il canale di trasmissione. Gli hub sono collegati da un bridging hub, attivo, che attraverso il principio di Store-and-Forward, separa i domini di collisione dei vari hub. Un bridge ha tante porte ethernet quanti sono i domini collegati. Inoltre, contiene una tabella aggiornata ogni volta che riceve una comunicazione (bridge trasparente). Quando la comunicazione è destinata a una stazione non salvata in tabella, fa flading.</a>
<ul>
<li><a href="#org5307182">flading, broadcast ma senza restituire alla porta da cui è arrivato.</a></li>
<li><a href="#org8305a94">Un problema è che se un dispositivo, con un certo MAC address, si sposta da un dominio all'altro, la tabella non è più valida. Ogni entrata deve quindi avere un timer, Il flading è quindi parte integrante dell'apparato</a></li>
</ul>
</li>
<li><a href="#org36652b5">A livello superiore, c'è uno switch, che funziona come un hub, ma con una memoria ed una cpu, per memorizzare e switchare in modo intelligente. Le connessioni da e per lo switch NON richiedono Carrier Sense, perchè sono punto-punto, in quanto già univocate dal bridge. Il cavo utilizzato è un duplex e può essere anche in fibra. Le porte sono comunque compliant con IEEE nel formato della porta.</a></li>
<li><a href="#orgb89f129">Nel CSMA-CD, l'efficienza è \(\frac{1}{1+\frac{2BL}{CF}e}\), quindi se aumento la Bandwidth, devo necessariamente ridurre la lunghezza e aumentare la dimensione del frame.</a>
<ul>
<li><a href="#org1baa389">E' stato deciso, in sede di standard, ogni tratta deve essere grande al massimo 200 metri, quindi 800 metri in tutto al massimo ( per andare sulle 2 tratte e tornare sulle stesse).</a>
<ul>
<li><a href="#org42933ce">Su 800 metri, il tempo andata e ritorno è circa 4ms. Con 1Gbit, esce fuori 4000bit, ovvero 500bit, arrotondati a 512B.</a></li>
<li><a href="#org413f565">Se si fosse lasciato il tempo di 51.2 microsecondi, avremmo dovuto mandare 51200 bit per ogni minimo frame e sarebbe stato poco efficiente. Viene quindi ridotto il diametro, e anche la dimensione dei frame.</a></li>
<li><a href="#orgf566c10">Per evitare di cambiare anche la porta MAC, che fa il padding di solo 64Byte, il padding viene fatto a livello fisico.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org24e246f">Notiamo che nel Data-Link, a questo punto, non ci sono più collegamenti punto-punto, ma un MAC layer, che controlla l'accesso a un canale condiviso.</a>
<ul>
<li><a href="#orgb7de6e0">C'è, però, anche un'interfaccia aggiuntiva, posizionata appena sopra il MAC, ma sempre a livello 2, chiamata <b>Logical Link Control</b>.</a></li>
<li><a href="#orgae28138">Quello che facciamo con questo sottolivello serve a creare dei canali logici punto-punto fra sè e le altre stazioni.</a>
<ul>
<li><a href="#orgd99e44a">Quindi, a livello MAC gestisco la situazione Broadcast, e nel Logical Link Control, creo una sovrastruttura logica che modella i collegamenti come punto-punto. In questo modo, dal Logical Link Control in sù, ignoro qualunque ragionamento riguardo il MAC e le sue operazioni.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org77bff1d">Una VLAN viene utilizzata per introdurre una nuova divisione virtuale fra stazioni. Un motivo per cui viene utilizzata è per aumentare la sicurezza.</a>
<ul>
<li><a href="#orge2c33c7">Stazioni che fanno parte di VLAN diverse, non possono comunicare fra loro, anche se fanno parte dello stesso hub. Serve uno switching intelligente per attivare questa funzione, perchè di base le comunicazioni sullo stesso hub girano liberamente</a></li>
<li><a href="#org7e1de6f">Per permettere a macchine appartenenti a VLAN diversi, è necessario utilizzare il routing di livello 3, perchè la separazione introdotta, sebbene logica, è finale.</a>
<ul>
<li><a href="#org8b1d767">Gli switch avanzati posseggono una funzione di routing incorporata</a></li>
</ul>
</li>
<li><a href="#orgdc6aa01">Le informazioni riguardo le VLAN sono contenute nello switch, che <b>tagga</b> le porte e le frame a esse corrispondenti</a>
<ul>
<li><a href="#orgfab95dd">Quindi, le stazioni mandano i soliti frame 802.3, e lo switch si occupa di taggarli e smistarli secondo un nuovo standard, chiamato 802.1Q</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org6bd004a">Per riassumere i primi 2 livelli, sono entrambi composti da due sottolivelli.</a>
<ul>
<li><a href="#org0aba66a">Convergence sublayer e Physical-medium dependent layer per il physical layer, il cui primo serve per separare ulteriormente il livello fisico finale, che è fortemente dipendente dall'architettura</a></li>
<li><a href="#org70665e6">LLC(Logical Link Control) e MAC(Multiple Access Control), il cui primo si occupa di rendere trasparente la gestione complicata del CSMA-CD da parte del MAC, gestendo apparentemente le connessioni come punto-punto.</a></li>
</ul>
</li>
<li><a href="#org45c9f92">Le LAN occupano spazi geografici molto limitati. E' necessario collegare LAN, anche lontane, così che siano tutte raggiungibili. Per farlo, vengono collegate ad uno strato superiore, che sarebbe l'ISP, fino ad arrivare ad un terzo strato che è quello intercontinentale.</a>
<ul>
<li><a href="#org6954209">Chiaramente, il MAC address smette di avere valore, su questa scala, e viene introdotto l'IP, che identifica univocamente qualunque stazione appartenente a qualunque LAN.</a></li>
<li><a href="#orgf84501b">Nell'andare da una stazione ad un altra, quindi da un livello Application all'altro, attraversiamo un numero indefinito di macchine che operano al massimo a livello 3. Ognuna di esse deve occuparsi dell'Addressing, ovvero come gestire l'univocità dell'IP, ed il routing, ovvero come trovare una strada fra le stazioni in modo efficiente.</a></li>
<li><a href="#org1da444c">Nel livello 3 non c'è solo un entità, ma 5, di cui analizzeremo due e IP in particolare, con il suo sottomodulo OSPF, per il routing. L'altro è ARP, con cui si mappa/risolve l'IP globale nel MAC.</a></li>
</ul>
</li>
<li><a href="#orgda67ff5">Nel livello 3 dobbiamo gestire l'indirizzamento e l'instradamento.</a>
<ul>
<li><a href="#org50bafa6">Il formato di un pacchetto IP è formato da 5 parole (ovvero 4 byte, 32 bit) ed un ultimo spazio opzionale, utilizzato ad esempio per il source routing.</a>
<ul>
<li><a href="#orgce08afc">Il primo campo è quello versione, che occupa i primi 4 bit e indica la versione del protocollo, di cui ne esistono due, la v4 e la v6.</a></li>
<li><a href="#orgdc7b777">Dopodichè c'è la header length, che occupa altri 4 bit e specifica quanti byte è lungo l'header. Serve nel caso in cui il campo option venga utilizzato, perchè ha lunghezza variabile.</a></li>
<li><a href="#org549abef">Gli 8 bit successivi sono occupati dal Type Of Service (TOS),</a></li>
<li><a href="#org37c9240">I successivi 16 bit che completano la parola riguardano la Total Length, che quindi può arrivare a \(2^{16}\).</a></li>
<li><a href="#org2da84a2">Nella prossima parola, si inizia con 16 bit per l'ID, seguito da 3 bit, di cui il primo vuoto per futuro uso e due bit chiamati D (Do not fragment) e M (More fragment)</a></li>
<li><a href="#org50c95b6">Poi ci sono i restanti 13 bit della parola, che si chiama Fragment Offset</a></li>
<li><a href="#org8af348b">Nella terza parola, i primi 8 bit sono un timestamp, TTL (Time to live).</a></li>
<li><a href="#org3e15e9a">Il secondo campo di 8 bit si chiama Protocol selector.</a></li>
<li><a href="#org50421cd">I restanti 16 sono di Header Checksum</a></li>
<li><a href="#org58ab6f6">Nella quarta e quinta parola troviamo rispettivamente il Source e il Destination address, che quindi sono di 32 bit ognuno.</a></li>
</ul>
</li>
<li><a href="#org5e8aaeb">Immaginiamo di avere due stazioni che comunicano, passando attraverso vari gateway, che collegano stazioni attraverso tecnologie diverse.</a>
<ul>
<li><a href="#org2b88605">Ad esempio, immaginiamo che la source esca con un ring, con un limite di 4000 byte per frame, passi per due gateway, di cui il secondo è collegato ethernet, con un limite di 1500 byte per frame alla stazione di arrivo.</a></li>
</ul>
</li>
<li><a href="#orgdbdf437">L'indirizzamento avviene attraverso l'IP address, che consiste in 4 sequenze di 8 bit, di cui viene rappresentato il valore decimale.</a>
<ul>
<li><a href="#org8a501eb">L'indirizzo IP è unico a livello globale. Esiste un organismo internazionale, chiamato ICANN, ovvero "&#x2026; for Name and Numbers" e se voglio assegnare un nome al mio dispositivo, devo chiedere a loro.</a></li>
<li><a href="#org8da7c41">Abbiamo 5 modalità di addressing:</a></li>
<li><a href="#orgb4d7b68">Nel CLASS based, esistono 3 classi diverse, che gestiscono trasmissioni Unicast, ovvero punto-punto.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org8d00d39">Riguardo l'indirizzamento IP, abbiamo visto metodi per garantire l'unicità dell'indirizzo. Abbiamo visto il subnetting, che va di pari passo con il metodo CLASS based. Subnetting non nasce con l'obiettivo di superare il limite delle classi, ma è trucco organizzativo per inserire un nuovo livello gerarchico per gestire le reti in modo che riflettano di più la struttura.</a>
<ul>
<li><a href="#org0bbf7ca">Gli altri metodi, CIDR e NAT, sono usati per superare il problema della frammentazione interna degli IP e aumentare la longevità di IPv4.</a>
<ul>
<li><a href="#org8262a39">Prima o poi, gli indirizzi a 32 bit di v4 finiranno, e saremmo costretti a utilizzare i 128 bit del IPv6.</a></li>
<li><a href="#orgaaeeae4">CIDR sta per Classless Inter Domain Routing e invece di dividere in classi, lo fa in blocchi autonomi e indipendenti, geografici (europeo, nord-americano, asiatico, ecc.).</a></li>
<li><a href="#org8e57fd9">Il NAT estende ulteriormente la vita di IPv4.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf2d0b45">Sebbene l'indirizzamento sia parte del livello 3 a livello globale, ogni livello possiede il proprio indirizzo per comunicare con altre macchine.</a>
<ul>
<li><a href="#org9949c36">A livello 2, in una rete CSMA-CD l'indirizzo è il MAC</a></li>
<li><a href="#orgc24557f">A livello 3, l'indirizzo è quello IP, con tutte le considerazioni fatte in precedenza.</a></li>
<li><a href="#orgf878fff">Un problema che dobbiamo risolvere è quello di mappare l'IP al corrispondente MAC.</a>
<ul>
<li><a href="#orga5ebf2f">Infatti, finora non c'è nessun modo per far arrivare un pacchetto a destinazione.</a></li>
</ul>
</li>
<li><a href="#org8fe718b">Immaginiamo che A e B siano sulla stessa rete locale.</a>
<ul>
<li><a href="#org0256618">Se la macchina A manda un pacchetto al modulo B, chiede ad ARP di risolvere l'IP in un MAC address, così che possa mandarglielo attraverso il livello 2</a></li>
<li><a href="#org3197514">In pratica l'ARP, per conto di IP, manda ai livelli sottostanti una richiesta, ARPRequest, così che il dispositivo in questione risponda con un ARPReply, rispondendo con il proprio MAC, che ARP fornirà al livello IP della macchina sorgente.</a></li>
</ul>
</li>
<li><a href="#org006ece3">Immaginiamo adesso che siano su macchine diverse.</a>
<ul>
<li><a href="#org3825012">A manda richiesta a Z, su un'altra rete.</a></li>
<li><a href="#org62703d6">Il site access gateway leggerà il NETID e vedrà che non appartiene alla rete locale e che quindi va cercato al di fuori. Prenderà lui in carico l'operazione.</a></li>
<li><a href="#org6908c02">A questo punto, risponderà con il proprio MAC, in modo che A mandi le richieste al gateway.</a></li>
<li><a href="#org0c3ea64">Il gateway aspetterà autonomamente per la ARPReply della macchina remota e salverà il risultato.</a></li>
<li><a href="#orgc106fa6">Questo servizio si chiama ProxyARP.</a></li>
</ul>
</li>
<li><a href="#org27f1974">ARP in ogni dispositivo terrà una ARP Cache, in cui salverà tutte le associazioni IP-MAC, così che le volte successive non servirà una nuova richiesta.</a></li>
<li><a href="#org47c76d8">Quindi uso ARP per fare una discovery delle macchine che sono raggiungibili in rete.</a></li>
<li><a href="#org7362afc">Anche in questo caso, abbiamo un livello 3 che per funzionare (anzi, il suo obiettivo) è di livello 2. Deve infatti andare a toccare il MAC, indirizzo di livello 2, ma in questo caso almeno fa una richiesta</a></li>
<li><a href="#org5a1fe8f">Notiamo che nello header di livello 3, il campo type è usato anche per identificare se la richiesta sia IPv4 o ARP</a></li>
</ul>
</li>
<li><a href="#orga364f3b">Introduciamo il DHCP</a>
<ul>
<li><a href="#orgfb8a238">Abbiamo tante macchine collegate ad una LAN, che possono essere nostre oppure di ospiti che arrivano transitoriamente. Come assegniamo l'IP privato alle macchine?</a>
<ul>
<li><a href="#org5145849">La LAN potrebbe essere Wireless, collegata tramite un Access Point ad una Lan fisica, che tramite il suo Access Gateway è collegata alla rete fisica.</a></li>
</ul>
</li>
<li><a href="#org702346e">Il Gateway riesce a fare Address Resolution e quindi è anche un NAT. Ovvero, riesce a mascherare un indirizzo interno.</a>
<ul>
<li><a href="#org8bc15cf">Ci presenta con un IP pubblico alla rete, ma poi smista alle macchine singole con gli indirizzi privati.</a></li>
</ul>
</li>
<li><a href="#org7ade03f">Questi indirizzi potrebbero esere statici, ma questo è scomodo. (Perchè?).</a></li>
<li><a href="#org177e6b8">E' più comodo se al momento della prima connessione alla rete, venga assegnato un IP dinamico al dispositivo, che rimanga fino allo spegnimento.</a></li>
<li><a href="#org41645d7">Per assegnare l'IP dinamico, usiamo il server DHCP (eventualmente molteplici)</a>
<ul>
<li><a href="#orgd49fe90">Appena una macchina cliente viene bootata, fa un operazione di Request DHCP al server, che farà a sua volta una Reply.</a></li>
<li><a href="#org3f89800">La reply assegna un IP privato, valido per tutto il tempo necessario.</a></li>
<li><a href="#orgd7e28a6">La RequestForComment che lo definisce è la 2131.</a></li>
<li><a href="#orgd6cfeff">Il client triggera la richiesta, che nello specifico si chiama DHCP Discover.</a></li>
<li><a href="#orgf03f68d">Il server riceve la richiesta e reagisce con una DHCP Offer.</a></li>
<li><a href="#orgcb74896">A questo punto il client ha <b>apparentemente</b> risolto il suo problema.</a></li>
<li><a href="#orgd8c95be">Diventa necessaria un ulteriore fase, una commit, chiamata DHCP Request.</a></li>
<li><a href="#org4781086">A questo punto, si chiude il commitment con una DHCP Ack, che è una validazione della request. Anche questo è mandato in broadcast secondo IP.</a></li>
<li><a href="#org56834c6">Questo protocollo è un protocollo a 4 vie, a causa della necessità di selezionare fra i vari server.</a></li>
<li><a href="#orgfc04fe1">Servono inoltre dei check per verificare la validità degli IP, anche dal punto di vista del client.</a></li>
<li><a href="#orgf269c02">Esistono dei meccanismi di ricovero, per gestire i casi in cui i messaggi vengano persi. Si utilizza ad esempio un timer T, che viene eseguito massimo K volte (numero di retry). Una volta aver provato K volte, si ritorna alle origini e si ricomincia da capo.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb708918">L'ICMP utilizzato per il ping e per capire delle statistiche sulla rete, fa uso di uno Header IP ed utilizza un Checksum, oltre che il tipo di richiesta (ce ne sono varie).</a></li>
<li><a href="#orge7c1a2a">Un importante compito del livello 3 è quello di instradare i pacchetti verso la giusta destinazione. Il grafo della rete è parzialmente connesso e serve un livello superiore a quello del data link che abbia una visione più ampia e riesca a smistare i pacchetti in un modo intelligente ed efficiente</a>
<ul>
<li><a href="#orge2b9391">Immaginiamo di avere due macchine con porte I/O e un forwarder in mezzo, che contiene una tabella e fa un lookup per capire su quale porta trasmettere il messaggio entrato.</a>
<ul>
<li><a href="#org7142a67">A livello 2, questo è fatto dal bridge, che popola e spopola le tabelle periodicamente per lasciar spostare le macchine.</a></li>
<li><a href="#org89bdb66">Se saliamo di un piano, quello che cambia radicalmente è che non è più vero che la macchina destinazione sia attaccata al link. La validità di un forwarding livello 2, a livello 3 non è più sufficiente.</a></li>
</ul>
</li>
<li><a href="#org6435a20">A livello 3, la tabella viene popolata da un secondo processo, che chiamiamo <b>router</b>, che lavora con i suoi pacchetti di controllo, utili soltanto a lui, tramite i quali impara la topologia della rete e popola la tabella in modo da permettere di raggiungere ogni host in un modo efficiente, possibilmente il cammino minimo.</a>
<ul>
<li><a href="#orgc52154f">La cosa interessante è che abbiamo una separazione netta fra tutto ciò che è gestione dei dati utente e la gestione di controllo di tutto ciò che serve alla rete autonomamente perchè funzioni.</a></li>
<li><a href="#org2ea2758">Con il routing questa diventa chiara.</a></li>
</ul>
</li>
<li><a href="#org8f6637a">Il router opera attraverso 3 tecniche:</a>
<ul>
<li><a href="#orgfcf33ee">Il protocollo con Distance vector opera assegnando due etichette con numero del link e corrispondente peso su ogni arco bidirezionale.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org521936a">Ci rifacciamo alla stessa struttura riguardante il routing, con un router che contiene un forwarder con porte IO di ingresso ed uscita e che opera su una tabella di routing, facendo un lookup e stabilendo la corretta porta di output. Chi scrive sulla tabella è il router, che ha i propri pacchetti di controllo e opera come un processo totalmente asincrono ed indipendente.</a>
<ul>
<li><a href="#org51cd9b2">Il router è attivato periodicamente, mentre il forwarder è attivato alla presenza di un pacchetto in coda di input.</a></li>
<li><a href="#org571f68f">Vogliamo sviluppare una soluzione alternativa in cui oltre al peso e alla destinazione del cammino, si dice anche il link che si vuole utilizzare</a></li>
<li><a href="#org697fcc3">La gran parte delle reti fondamentali di internet, ovvero quelle intermedie fra LAN, utilizza un protocollo chiamato OSPF Link State</a>
<ul>
<li><a href="#org47992c6">Voglio costruirmi il grafo della connettività, con i costi di ogni arco, dopo aver scambiato abbastanza informazioni fra nodi.</a></li>
<li><a href="#org00d24d9">Ogni nodo manda la distanza sui suoi link a TUTTI gli altri nodi, quindi esistono N(N-1) messaggi di controllo</a></li>
<li><a href="#orgb8fd215">Adesso immaginiamo di avere una topologia di nodi con due nodi, R1 ed R3, connessi ad una rete (ad esempio lan, ma qualunque) con netID rispettivamente 1 e 3, che contengono al loro interno uno degli host H1 e H3.</a></li>
<li><a href="#org8131ac2">OSPF ruota sicuramente sulla area 0, ovvero il backbone dello Autonomous System. All'area 0 sono collegate sotto-aree che per comunicare da loro devono necessariamente passare attraverso l'area 0. L'area 0 contiene dei border-router attraverso cui passa TUTTO il traffico, intra area ed extra area.</a></li>
<li><a href="#org6f08b51">Per mettere in comunicazione AS diversi, serve avere dei link che li collegano e i router fra essi utilizzano un altro protocollo, BGP.</a></li>
</ul>
</li>
<li><a href="#org3e58627">Per migliorare la efficienza e generare le tabelle di routing vengono messe in atto delle tecniche avanzate, fra cui centralizzare il calcolo dei cammini minimi. Un router specifico, chiamato Designated Router, che calcola i cammini minimi per tutte i nodi e gli rimanda le tabelle già calcolate.</a>
<ul>
<li><a href="#org60d766f">Si riduce un po' il traffico, ma si ha lo svantaggio di congestionare i link verso lo stesso, su cui convergono le comunicazioni.</a></li>
<li><a href="#org666388c">Ormai tutte le reti lo usano.</a></li>
<li><a href="#org24a0f73">Lo spunto di eleggere un designated router è stato preso tanto bene che invece di eleggere uno dei router, si è deciso di portarlo in cloud, inventando il Software Designed Network SDN.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org61b258a">Supponiamo di avere due macchina che ha uno strato applicativo, seguito da TCP, IP ecc&#x2026;, attaccata ad una rete IP.</a>
<ul>
<li><a href="#org04fc82a">Ora immaginiamo che una macchina in mezzo a queste macchine ci sia una rete non IP.</a></li>
<li><a href="#org187735f">La macchina centrale deve avere IP per riuscire a prendere i pacchetti e poi l'altro network per processarli correttamente. Poi andranno reinviati in IP</a></li>
<li><a href="#org52f3f9c">Il TUNNELLING è il modo di gestire lo header durante il passaggio in quella macchina</a></li>
<li><a href="#org5c344b4">La soluzione banale è che l'intero pacchetto, compreso header, viene incapsulato e lo header dell'altro protocollo viene semplicemente aggiunto, per poi essere rimosso dopo</a></li>
</ul>
</li>
<li><a href="#orge6504bb">TRANSPORT LAYER NUOVE LEZIONI</a></li>
<li><a href="#org8d7cb01">Transport layer è il primo livello ad essere end-to-end, ovvero che comunica fra due macchine ed astrae ai livelli superiori la rete sottostante (la nasconde).</a>
<ul>
<li><a href="#org673fe20">Offre dei servizi che abbiamo già visto nel data-link.</a></li>
<li><a href="#orgcf600e8">Varie funzionalità possono essere attivate o disattivate.</a></li>
<li><a href="#orgb0d486e">TCP e UDP sono ortogonali fra loro. La prima offre disponibilità, mentre la seconda è best-effort e non aggiunge nulla ai livelli superiori.</a></li>
<li><a href="#orgc1e4ed4">A livello data-link, tra due porte di rete abbiamo una trasmissione può essere affidabile, avere controllo degli errori ecc.</a>
<ul>
<li><a href="#org843e1e9">Quello che non è considerato a livello data-link è se qualcosa va perso a livello network.</a></li>
</ul>
</li>
<li><a href="#orgfc4bf2e">In Transport viene riimplementata l'affidabilità in modo che quando un segmento venga perso, venga gestita la ritrasmissione.</a>
<ul>
<li><a href="#org1785644">La trasmissione su cavo è molto affidabile e quindi l'affidabilità a livello data link è passata in secondo piano e diventa più importante quella su tratte più lunghe, con tutta la rete in mezzo, che coinvolgono i router di livello 3.</a></li>
</ul>
</li>
<li><a href="#org3ff757c">Le unità base di comunicazione a livello 4 sono chiamate <b>messaggi</b> o <b>segmenti</b>.</a></li>
<li><a href="#orga1e150e">Il livello di trasporto ha anche un suo indirizzamento (naming) utilizzando le porte, che servono per identificare l'applicazione che sta utilizzando il collegamento di livello 4.</a>
<ul>
<li><a href="#org3316c32">Mentre l'indirizzo IP serve per identificare l'host di rete</a></li>
<li><a href="#org4b5328b">Immaginiamo di avere un client ed un server con TCP o UDP a livello 4, IP sotto e poi una rete completamente trasparente.</a></li>
<li><a href="#orgee3f750">A livello di Trasporto si usano le socket.</a></li>
<li><a href="#orgda566c2">Il TCP garantisce che la comunicazione sia <b>affidabile</b> e <b>ordinata</b>.</a></li>
<li><a href="#orge947154">Lo header TCP è rappresentato in pagine larghe 32 bit.</a></li>
<li><a href="#orgcdcabee">Come si diceva, TCP è orientato alla connessione.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org789ff9e">Quindi siamo arrivati al SYN che uno manda per aprire la connessione, con un numero di sequenza generato in numero casuale. Il canale è bidirezionale e quindi avviene tutto nello stesso modo in entrambi gli host.</a>
<ul>
<li><a href="#org5ac5acf">Il SYN parte a 1, in risposta il SYN è a uno e anche l'ACK, che indica che il campo Ack è significativo e tale campo è numDiSequenza +1, per indicare che quello è il prossimo bit che si è pronti a ricevere.</a>
<ul>
<li><a href="#org1725f4a">Ovviamente manda anche il proprio numero di sequenza.</a></li>
</ul>
</li>
<li><a href="#orgc2b1f8f">Se tutto va a buon fine, la terza risposta dal sender è uguale alla seconda dal receiver e da lì in poi la connessione è aperta.</a></li>
<li><a href="#orgdda5b9e">C'è un timer che garantisce che se l'ACK viene perso, o impiega troppo tempo ad arrivare, venga mandato un messaggio con RESET a 1 che annulla l'handshake, che va rieffettuato</a></li>
<li><a href="#orgbf4586b">In ogni header è indicato il Max Segment Size, che indica la dimensione massima di segmento che l'host può gestire senza andare in overflow.</a>
<ul>
<li><a href="#orgd78dc40">La dimensione Standard, quando il campo è vuoto, il segmento è di 536 byte.</a></li>
</ul>
</li>
<li><a href="#orgb287bbb">L'obiettivo di TCP è trasferire i dati nel miglior modo, garantendo affidabilità, gest.errori, ordine ecc., e anche farlo in modo efficiente, evitando un overhead eccessivo</a></li>
<li><a href="#orgd8f2ed5">Il motivo per cui viene scelta 536 byte è che siamo sicuri che il livello IP non frammenterà tale segmento in più pacchetti.</a>
<ul>
<li><a href="#org942fbbe">Per ogni frammentazione effettuata dall'IP, serve copiare sia header TCP che IP, introducendo overhead.</a></li>
<li><a href="#orgef443cc">Inoltre, essendo la rete best-effort, quanti più sotto-segmenti vengono mandati quanto più è probabile che avvengano dei problemi che dovranno essere poi gestiti</a></li>
</ul>
</li>
<li><a href="#org97fa749">Immaginiamo di avere una connessione A-B in TCP, necessariamente bidirezionale.</a>
<ul>
<li><a href="#orge644438">Dato che noi analizziamo solo i casi "unidirezionali", noi valutiamo solo SendingBuffer e TcpSendingBuffer nel sender, e i corrispondenti ma per il receiver nel receiver.</a></li>
<li><a href="#org3eefcf8">Assumiamo che la segment size sia 500.</a></li>
<li><a href="#org2b1cccc">L'applicazione lato sender scrive 2000 byte nell'SB della socket esposto.</a></li>
<li><a href="#org508f3e4">Ovviamente, va eseguita una frammentazione a livello trasporto.</a></li>
<li><a href="#org02f0f24">Nel sending buffer della TCP, nascosto al livello applicazione, vengono copiati e segmentati opportunamente i byte del buffer superiore.</a></li>
<li><a href="#orgb707ed8">Nello header è presente l'informazione SEQ=X. Il payload sarà dal byte X a quello X + 499</a></li>
<li><a href="#orgb281d46">Nel frattempo, il receiver si aspettava il Sequence Number = X e così si accerta che l'ordine sia corretto.</a></li>
<li><a href="#org8c02c5d">I dati arrivano nel buffer inferiore, ma dato che l'ordine è corretto, vengono subito copiati nel buffer superiore.</a></li>
<li><a href="#org4574c99">Lo header risposta del receiving buffer contiene il campo ACK a 1 e quello Ack a X + 500, che è il primo byte successivo a quello ricevuto.</a></li>
<li><a href="#org50f5227">Il sender elimina dal buffer del TCP il segmento corrispondente.</a></li>
<li><a href="#org062816f">Allora, il prossimo segmento mandato è quello che parte da X+500 e questo valore è nel SEQ dello header.</a></li>
<li><a href="#org37c127b">Anche questo pacchetto è in ordine e quindi va subito spostato nel buffer superiore.</a></li>
<li><a href="#org29fb1a4">Analogamente al messaggio precedente, il receiver risponde con un Ack = X+1000.</a></li>
<li><a href="#org8c845de">Procedo così fino allo svuotamento del buffer di invio.</a></li>
</ul>
</li>
<li><a href="#org7d8160e">Nella configurazione precedente, c'è un problema nel caso in cui ho bisogno di (real-time?) ad esempio ssh su una console remota.</a>
<ul>
<li><a href="#org736a6a7">Voglio che i dati vengano processati byte per byte</a></li>
<li><a href="#orgd5747e3">Allora uso la flag PUSH, in modo che TCP spedisca il singolo byte, senza arrivare ad una dimensione del segmento di 500 byte come prima</a></li>
<li><a href="#orgb5242e6">Quando PUSH viene usata, il receiver manda un regolare ACK, con Ack X+1</a></li>
<li><a href="#org201f848">In questo caso, però, viene fatta una eco dello stesso byte, questa volta</a></li>
<li><a href="#org57d9e51">Il motivo per cui viene fatta la eco è che il sender prende input a tastiera ma non mostra direttamente a schermo, perchè non è sicuro che dall'altra parte sia correttamente ricevuto. Solo quando si è sicuri che dall'altra parte sia stato ricevuto, viene stampato a tastiera</a></li>
</ul>
</li>
<li><a href="#org6ac355d">Per garantire&#x2026;(?) viene introdotto il delay acknowledgment.</a>
<ul>
<li><a href="#orgb2fdadf">La questione è che TCP ignora l'obiettivo delle applicazioni, ma loro lo sanno e potrebbero voler inserire più informazioni nello header.</a></li>
<li><a href="#org69595ee">Immaginiamo una situazione come prima: si riceve un byte pushato.</a></li>
<li><a href="#orga9226a7">Il receiver, però, non risponde subito con un Ack, ma aspetta un tempo (standard 200ms).</a></li>
<li><a href="#org59ab2ea">Se in quel tempo arriva qualcosa nel buffer di invio del ricevitore, quei dati vengono incorporati nel messaggio di Ack.</a></li>
<li><a href="#org70d296c">In questo caso, quando la eco viene aggiunta nel buffer di invio della ricezione, viene inserita nello stesso frame di Ack. Così ri risparmia un messaggio TCP.</a></li>
<li><a href="#org6f22efe">Questa soluzione è efficiente dal punto di vista di rete, ma inefficiente dal punto di vista della user-experience.</a></li>
<li><a href="#org407a920"></a></li>
</ul>
</li>
<li><a href="#orgee2f73a">In caso di errori, è lo stesso TCP che se ne accorge e cerca di sanarlo.</a>
<ul>
<li><a href="#org16e9401">TCP è orientato allo stream.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org5bb05e1">Negle ha un utilità quando vogliamo garantire un utilizzo efficiente della rete.</a>
<ul>
<li><a href="#org8f8d57e">Lo si usa al posto di mandare ogni carattere da solo, con un overhead altissimo dovuto allo header IP e TCP.</a>
<ul>
<li><a href="#orgcbf8cf5">Per mandare un byte, mi servono 4 messaggi.</a></li>
<li><a href="#org47acb6b">Si usa il delay per diminuire i messaggi che vengono mandati, ma si paga troppo tempo per l'attesa del delay ogni volta, con piggy bagging in cui nei dati da comunicare si inserisce anche l'ack cumulativo</a></li>
<li><a href="#org39fb0dc">Un compromesso e il nagle</a></li>
</ul>
</li>
<li><a href="#orgbe3283e">Il Nagle viene in supporto quando abbiamo un quantitativo di dati dall'applicazione, ovvero nel SB (superiore) che è minore alla maximum segment size.</a>
<ul>
<li><a href="#orga6c4c17">Nagle innanzitutto guarda il TCP Sending Buffer (quello inferiore). Se è vuoto vuol dire che non sto aspettando nessun ACK.</a></li>
<li><a href="#orgf9ef4af">Se invece ci sono altri segmenti nel buffer inferiore, lo accoda.</a></li>
<li><a href="#orgd141bc7">Uno dei lati negativi di Nagle è che sebbene utilizzi bene la rete, ovvero limitando l'overhead, (QUAL è L'ASPETTO NEGATIVO)?</a></li>
</ul>
</li>
<li><a href="#org6b18eb6">Un altro aspetto è che tcp è orientato allo stream e ragiona in base ai bit.</a>
<ul>
<li><a href="#org3d8908a">Una sequenza di dati presente nel sending buffer non dev'essere multiplo della max segment size. Il TCP suddivide in blocchetti della dimensione corretta.</a></li>
<li><a href="#org385f1d6">Quindi si parla di segmento numero n come divisione logica, ma tutto è relativo al byte di inizio sequenza.</a></li>
<li><a href="#orgb15e7e1">Il principio è che si occupa il meno possibile. L'eventuale padding è fatto ai livelli inferiori.</a></li>
</ul>
</li>
<li><a href="#org76901b1">Quando TCP invia un pacchetto ad IP, quest'ultimo, conoscendo perfettamente la max transfer unit del suo livello 2, frammenta ulteriormente se necessario.</a>
<ul>
<li><a href="#org72c941f">IP stesso riassemblerà poi la serie di pacchetti e la fornirà a tcp</a></li>
<li><a href="#orgf7476f5">Se non ci riesce, a TCP non arriverà assolutamente nulla.</a></li>
</ul>
</li>
<li><a href="#org8fcad55">Come abbiamo già visto, il round trip time è il tempo necessario perchè un segmento venga inviato ed ackAto.</a>
<ul>
<li><a href="#org57ee5ee">Possiamo però anche inviare più segmenti nello stesso momento.</a></li>
<li><a href="#org4e1963c">Ogni segmento fa partire un timer, che dev'essere dimensionato correttamente e quindi non può essere statico.</a></li>
<li><a href="#orgc16ac5a">Esiste uno standard che ci spiega come calcolarlo</a></li>
</ul>
</li>
<li><a href="#org031bb7f">Il controllo di flusso viene messo in atto quando il produttore produce molto più velocemente del ricevente.</a>
<ul>
<li><a href="#org2192ebc">Infatti, il buffer di ricezione andrebbe poi in overflow.</a></li>
<li><a href="#org77c131c">Il problema della silly window syndrome accade quando il receiver riempie la propria window e continua a notificare la nuova disponibilità ma per una quantità di byte minima.</a></li>
<li><a href="#orgcab06bd">La rete ignora completamente il controllo di flusso.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orga251260"><span class="todo TODO">TODO</span> Riempire con ultime 2 lezioni di livello 4</a></li>
<li><a href="#orgadebd5c">Iniziamo il livello applicazione parlando del DNS, ovvero il Domain Name System.</a>
<ul>
<li><a href="#org76fab46">E' un sistema che permette di rendere più semplice raggiungere un host</a>
<ul>
<li><a href="#orgfb45920">Normalmente si usa un IP per raggiungere un host, ma è praticamente impossibile ricordare un IP.</a></li>
</ul>
</li>
<li><a href="#org42eaae4">Funziona associando un nome (dominio) all'ip di uno specifico host.</a>
<ul>
<li><a href="#org099be27">Permette anche di recuperare altre informazioni</a></li>
</ul>
</li>
<li><a href="#orgb8aebe0">L'idea è quella di disaccoppiare il modo in cui un essere umano raggiunga un certo servizio.</a>
<ul>
<li><a href="#org3eccfb4">Ad esempio il servizio potrebbe cambiare indirizzo ip in modo trasparente agli utenti.</a></li>
</ul>
</li>
<li><a href="#orgde325ea">Il fully qualified domain name (FQDN) contiene un punto alla fine che indica il root domain</a></li>
<li><a href="#orgf2b9605">Il modo in cui avviene la risoluzione del FQDN fra due macchine, ovvero fra un host che richiede e il server che risponde, è sostituendo ad ogni punto il numero di caratteri che seguono quel punto prima di quello successivo, esempio 2DI5UNIMI2IT0.</a></li>
<li><a href="#org4724f81">Una query DNS contiene uno header, il FQDN specifico, il tipo di query(A, AAAA, Mx), la classe (che indica la rete su cui si vuole risolvere, che di fatto è sempre internet)</a>
<ul>
<li><a href="#org9a9a73f">Il tipo può essere2 A per IPv4, AAAA per IPv6, MX per posta, CNAME (canonical name) che è un altro nome per lo stesso sito</a></li>
</ul>
</li>
<li><a href="#orge544d47">La risposta ricopia i dati e inserisce l'indirizzo nell'ultimo campo.</a></li>
<li><a href="#org91dd862">Un record DNS in cache può essere associato ad uno specifico TTL, dopo il quale il record scade e la prossima richiesta effettuata da qualunque client dovrà essere risoluta di nuovo</a>
<ul>
<li><a href="#org194e3ec"><span class="todo TODO">TODO</span> Capire funzionamento in caso di record scaduto</a></li>
</ul>
</li>
<li><a href="#orgc750b61">Il resolving DNS avviene con un client che chiede la risoluzione di uno specifico FQDN al resolver all'interno della stessa macchina.</a>
<ul>
<li><a href="#org476d13d">Il resolver usa UDP perchè non gli serve instaurare la connessione e parla con il Local DNS, che viene impostato in fase di configurazione.</a></li>
</ul>
</li>
<li><a href="#org5ba88f0">A livello globale ci sono dei root DNS servers che contengono soltanto i domini di primo livello, con gli IP corrispondenti dei NameServer.</a>
<ul>
<li><a href="#orge949334">Usiamo questi se non sappiamo come raggiungere il dominio di primo livello, che di solito però conosciamo già perchè rimane in cache</a></li>
<li><a href="#org96bc3f5">Sul libro sono indicati due approcci, uno iterativo e uno ricorsivo, ma gli esempi sono tutti iterativi.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org0dd4273" class="outline-2">
<h2 id="org0dd4273">References</h2>
<div class="outline-text-2" id="text-org0dd4273">
<p>
<a href="https://computer.howstuffworks.com/ethernet.htm">How Ethernet works</a>
<a href="https://intronetworks.cs.luc.edu/1/html/index.html">Exercises from Chicago University</a>
</p>
</div>
</div>
<div id="outline-container-orgf255c02" class="outline-2">
<h2 id="orgf255c02">Host computer dove risiedono le app finali e un sistema di rete composto da un insieme di nodi e link.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>

<div id="outline-container-orga72eea2" class="outline-2">
<h2 id="orga72eea2">Gli unici dati che viaggiano nel sistema sono denominati pacchetti, di dimensione massima fissa. Semplifica l'architettura dei nodi di switch, cioè i router, che svolgono funzionalità di instradamento. In questo modo ogni router si occupa soltanto di ricevere e smistare i pacchetti su link stabiliti in base a metriche di instradamento.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>

<div id="outline-container-org048c219" class="outline-2">
<h2 id="org048c219">Una divisione funzionale delle varie parti è: il sistema di reti, attraverso ip, decide il percorso migliore in base a quel momento specifico (le condizioni variano nel tempo), concetto chiamato instradamento.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>
<div id="outline-container-org10c3285" class="outline-2">
<h2 id="org10c3285">Pacchetti con stesso mittente e destinatario non necessariamente percorrono lo stesso cammino. Non solo la comunicazione non è affidabile, ma anche ogni pacchetto è completamente indipendente dagli altri, sebbene siano tutti risultato dello stesso processo di frammentazione da parte dell'host. Servirà poi un modo per reassemblarli a destinazione.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>
<div id="outline-container-orge760ef0" class="outline-2">
<h2 id="orge760ef0">Ogni pacchetto è indipendente, ma in qualche modo verrà ricostruito, quindi c'è qualche legame logico fra il singolo frammento e l'unità generale. Finchè i pacchetti sono nel sistema di rete, questo collegamento è perso.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>

<div id="outline-container-org453408d" class="outline-2">
<h2 id="org453408d">A questo punto abbiamo definito dei concetti come affidabilità e valori tempo di trasmissione, tempo di propagazione, round-trip tie, error-rate su un canale, gitter, che tornano.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>
<div id="outline-container-org2248166" class="outline-2">
<h2 id="org2248166">Abbiamo identificato le componenti architetturali di una rete, con link fra router e host, entrambi con software e funzioni utili alla comunicazione, IP lato router e TCP lato host&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>

<div id="outline-container-orgb9fa6b1" class="outline-2">
<h2 id="orgb9fa6b1">Adesso analizzeremo le altre componenti della rete, e come sono organizzate all'interno della struttura, le varie funzioni di rete.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>

<div id="outline-container-orgba3d816" class="outline-2">
<h2 id="orgba3d816">Per la struttura gerarchica a 5 (7) livelli, i collegamenti fra le due macchine sorgente e destinazione sono allo stesso livello. Non sono ammesse cross-layer communication.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>
<div id="outline-container-org3c3b284" class="outline-2">
<h2 id="org3c3b284">Finora abbiamo capito come, su un canale che collega il nodo a al nodo b, inviare frame in modo affidabile (rimando alle 3 condizioni)&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ARCHIVE">ARCHIVE</span></span></h2>
</div>
<div id="outline-container-org0c61d0a" class="outline-2">
<h2 id="org0c61d0a">A volte la topologia di rete è un grafo parzialmente connesso e in particolare in cui i punti sono collegati fra loro in una <b>maglia</b>, ed è per questo chiamata anche punto-a-punto, ma spesso non è così.</h2>
<div class="outline-text-2" id="text-org0c61d0a">
</div>
<div id="outline-container-orga6bd011" class="outline-3">
<h3 id="orga6bd011">In una LAN (local a.. network) la rete è broadcast, ovvero c'è un dispositivo che comunica a tutti gli altri, compreso quello da cui ha ricevuto il segnale in entrata. Ovvero un HUB, chiamato anche <b>centro stella passivo</b></h3>
</div>
<div id="outline-container-org1f978e3" class="outline-3">
<h3 id="org1f978e3">Un terzo modo, che è come ethernet era fatto inizialmente, si ha una struttura a bus lineare, in cui tutti i dispositivi sono collegati in serie. Sia questa che la seconda sono chiamate <b>broadcast</b>.</h3>
</div>
<div id="outline-container-org6d810c1" class="outline-3">
<h3 id="org6d810c1">Il problema delle strutture broadcast è innanzitutto quello di creare l'equivalente semantico di una comunicazione fra due soli dispositivi, e si fa utilizzando header di mittente e destinatario, così che nel secondo driver di IO capiscono se salvano o buttano via i dati.</h3>
</div>
<div id="outline-container-org2881bba" class="outline-3">
<h3 id="org2881bba">Un altro problema è che trasmettere sull'hub o su bus lineare è critico e va quindi garantita la mutua esclusività per l'accesso a canale condiviso: non tutti i dispositivi possono trasmettere nello stesso momento.</h3>
<div class="outline-text-3" id="text-org2881bba">
</div>
<div id="outline-container-org7e3739a" class="outline-4">
<h4 id="org7e3739a">Si può sfruttare un token unico e condiviso dalle stazioni. La struttura è fatta ad anello e chi lo riceve, lo estrae e trasmette. Una volta che la trasmissione torna al primo dispositivo, vuol dire che la comunicazione è arrivata a tutti e cede il token ad un altro.</h4>
<div class="outline-text-4" id="text-org7e3739a">
</div>
<ul class="org-ul">
<li><a id="org86f3a6b"></a>Da notare che bisogna fidarsi che il dispositivo ceda il token. Potrebbe non farlo, ed in quel caso nessun altro parlerebbe<br /></li>
<li><a id="org66887bf"></a>Questa è una soluzione deterministica, perchè in ogni momento so esattamente chi sta parlando.<br /></li>
<li><a id="org0d01533"></a>Questo approccio comporta dei problemi:<br />
<div class="outline-text-5" id="text-org0d01533">
<ul class="org-ul">
<li>il token deve fare il giro di tutto l'anello, ma quest'ultimo ha una dimensione variabile, potenzialmente molto grande.</li>
<li>quando una stazione si aggiunge, bisogna inserirla, sincronizzando gli altri nodi per notificarli dell'inserimento. Questo non può che essere fatto da una stazione master, da cui dipende tutto il sistema.</li>
<li>la stazione master serve anche per generare il token e garantire che sia unico</li>
</ul>
</div>
</li>
</ul>
</div>
<div id="outline-container-org5d8c7ae" class="outline-4">
<h4 id="org5d8c7ae">Ethernet utilizza, invece, una soluzione <b>non deterministica</b>, fuzzy, in cui c'entra molto la probabilità ed in cui le collisioni sono ammesse, chiamato CSMA-CD.</h4>
<div class="outline-text-4" id="text-org5d8c7ae">
</div>
<ul class="org-ul">
<li><a id="org188cff2"></a>Un primo modo, chiamato ALOHA, precedente a quello finale, prevede che nel caso in cui ci sia una collisione, entrambi i mittenti non ricevono alcun ACK e ritrasmettono. Se avessero T uguale, ritrasmetterebbero nello stesso momento, generando una nuova collisione. Viene quindi introdotto un ritardo casuale. Questo diminuisce le probabilità di collisione.<br />
<ul class="org-ul">
<li><a id="org1abad40"></a>Questa soluzione è vincente rispetto la precedente. Questo è un sistema distribuito, in cui un nuovo dispositivo può inserirsi immediatamente e trasmettere in una nuova rete.<br />
<ul class="org-ul">
<li><a id="org3c35324"></a>La prima volta nella storia in cui un approccio probabilistico vince con uno deterministico.<br /></li>
</ul>
</li>
<li><a id="org5dbb5e9"></a>Questa soluzione ha un'efficienza minima, intorno al 18%.<br /></li>
</ul>
</li>
<li><a id="orgdf746f1"></a>L'innovazione adottata per il protocollo di Ethernet è l'operazione di ascolto, chiamata CS, ovvero Carrier Sense. Vedo se il canale è libero e solo in quel caso immette il proprio pacchetto.<br />
<ul class="org-ul">
<li><a id="orgec3f432"></a>Il rischio di collisione avviene nel caso in cui due stazioni facciano Carrier Sense nello stesso momento. Scopriranno che il Carrier si è liberato nello stesso momento e immetteranno i pacchetti.<br />
<ul class="org-ul">
<li><a id="org2eb82aa"></a>Una soluzione per ridurre la probabilità di collisioni di questo tipo, potrebbe essere quella di introdurre un ritardo dal momento in cui viene notata la fine del pacchetto attraverso il Carrier Sense. Dato che la probabilità di questo tipo di collisione è considerata bassa in Ethernet, non viene introdotto un ulteriore ritardo. Si scommette che non avvenga di frequenza.<br />
<ul class="org-ul">
<li><a id="org375f7e2"></a>Applicare il ritardo comporterebbe un protocollo Non-Persistent, ovvero le stazioni non sono competitive.<br /></li>
<li><a id="org5aa08dc"></a>La nostra scelta è 1Persistent, ovvero i pacchetti trasmettono con probabilità 1.<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="org529dc6a"></a>La collisione viene gestita, però, in modo molto più rapido: se una stazione riceve qualcosa di diverso da quello che sta immettendo, c'è una collisione e blocca istantaneamente la trasmissione. Solo a quel punto inizia il timer random<br />
<ul class="org-ul">
<li><a id="orgb4ccbab"></a>BEB (binary exponential backoff) è un modo per calcolare il tempo di ritardo dopo una collisione<br />
<ul class="org-ul">
<li><a id="org8d48079"></a>Ad ogni i-esima collisione, genero un ritardo randomicamente scelto fra 0 e 2<sup>i</sup>-1 * unità di tempo<br />
<ul class="org-ul">
<li><a id="org522b18e"></a>Quindi la prima volta il ritardo può essere di 0 o 1 unità, la seconda 0,1,2,3, la terza tra 0 d e 7 è così via<br /></li>
<li><a id="orga00d375"></a>Il prof dice che 2<sup>i</sup>-1 è l'estremo dell'intervallo e non il numero di scelte.<br /></li>
</ul>
</li>
<li><a id="org4d1622b"></a><span class="todo TODO">TODO</span> controllare cos'è<br /></li>
<li><a id="org02b8bc7"></a>L'unità di tempo viene dallo standard IEEE 802.3 che specifica il CSMA-CD 1Persistente.<br />
<ul class="org-ul">
<li><a id="org6d2aae5"></a>Abbiamo un cavo di 2500 mt, diviso in 5 sezioni di 500mt da 4 repeater. Lunghezza per indice del rame, mi da un tempo di 12.5 microsecondi.<br /></li>
<li><a id="org8ccad2b"></a>Devo garantire che questo tempo, ovvero 2tp = 25 microsecondi, non pesi troppo rispetto al tx.<br /></li>
<li><a id="org725195a"></a>Immaginiamo ci siano A e B, B alla fine del cavo di cui prima. Prima di 25microsecondi, se B facesse Carrier Sense, troverebbe la rete libera e colliderebbe. Lo stesso vale perchè A riconosca la presenza di bit corrotti e quindi la collisione.<br /></li>
<li><a id="org144b8eb"></a>In una rete di questo tipo, per garantire la collision detection, è necessario che il primo trasmettitore trasmetta per un tempo almeno maggiore di 2tp, ovvero il tempo che la trasmissione arrivi a tutti gli altri, e la trasmissione di tutti gli altri ritorni.<br /></li>
<li><a id="org67c6ccd"></a>Si è quindi deciso di settare il parametro 2tp in 51,2 ms, che è il tempo richiesto ad ogni stazione per continuare a trasmettere, in modo da rilevare la collisione, questo diventa il tempo minimo di trasmissione in rete.<br />
<ul class="org-ul">
<li><a id="org77e960d"></a>Se la rete lavora con un clock a 10Mbit, in 51.2microsecondi trasmetto 512 bit, ovvero 64byte<br /></li>
<li><a id="org7d49501"></a>Questo parametro di 51,2 è l'unita di tempo fondamentale, che viene applicata anche per il BEB.<br /></li>
</ul>
</li>
<li><a id="org31b26c1"></a>Lo IEEE 802.11 è lo standard WiFi.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a id="org2e4fe9a"></a>Nel MAC, che è un layer di livello 2, multiple access control, che sarebbe lo stesso standard IEEE802.3, viene definito anche il formato del pacchetto, in cui si usa un header e un padding, che serve per raggiungere la dimensione minima.<br /></li>
<li><a id="org4faf3d5"></a>Il nome è Carrier Sense, Multiple Access, Collision Detection.<br /></li>
<li><a id="org971e6d4"></a>La curva d'efficienza la ottiene nello sweet spot di stazioni ed è intorno al 95%.<br /></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org6356937" class="outline-2">
<h2 id="org6356937">Di solito, alla salita del fronte d'onda, legge il valore in volt, e se è 5 il bit è 1, altrimenti 0</h2>
<div class="outline-text-2" id="text-org6356937">
</div>
<div id="outline-container-orgb0cf1f5" class="outline-3">
<h3 id="orgb0cf1f5">Con ethernet, però, abbiamo vari problemi. Uno è quello di disambiguare sequenze di bit uguali, un'altra è quella di far arrivare il valore in modo chiaro al ricevitore.</h3>
<div class="outline-text-3" id="text-orgb0cf1f5">
</div>
<div id="outline-container-org838dfae" class="outline-4">
<h4 id="org838dfae">Ethernet utilizza quindi la codifica Manchester, che a differenza del solito, legge nel momento centrale del bit, che è il punto meno soggetto a distorsione.</h4>
<div class="outline-text-4" id="text-org838dfae">
</div>
<ul class="org-ul">
<li><a id="org3b59d10"></a>Ciò che viene letto, però, non è il valore assoluto ma la transizione. Se vede che c'è una transizione verso l'alto, abbiamo un uno, altrimenti zero.<br />
<ul class="org-ul">
<li><a id="orgb235702"></a>Questo comporta che in caso di valori uguali consecutivi, bisogna cambiare la tensione appena si capisce che il prossimo bit è uguale, e poi nel momento centrale (quello letto), effettuare la transizione.<br /></li>
<li><a id="org501110a"></a>Questo comporta anche che la trasmissione sia shiftata di mezzo ciclo di clock.<br /></li>
</ul>
</li>
<li><a id="org0b7f8e5"></a>Essendo un sistema a stato IDLE pre-trasmissione, prima che questa inizi, il ricevitore non conosce il clock di trasmissione, perchè i bit in entrata sono tutti uguali.<br />
<ul class="org-ul">
<li><a id="orgd32a65e"></a>La sfida è quella di tenere il clock del ricevitore sincronizzato, magari non fornendgli un clock indipendente, ma incorporando univocamente questa informazione nei dati<br />
<ul class="org-ul">
<li><a id="org4b1bdb0"></a>Un primo problema è che il ricevitore non può a priori sapere se una transizione allo scattare del clock (quindi quella di preparazione), non sia una transizione valida "trasmittiva", ovvero quella mid-clock<br /></li>
</ul>
</li>
<li><a id="orgfa2b0ab"></a>Introduciamo un preambolo, formato da 7 byte in cui i bit 0 e 1 si alternano, ed un ottavo byte così costituito [1010101011], che il ricevitore riceve per sincronizzarsi. Gli ultimi due uno, o in particolare l'ultimo, che prevede una doppia transizione, segnala l'inizio del vero frame.<br /></li>
</ul>
</li>
<li><a id="org47d1377"></a>(non serve guardare la codifica Manchester differenziale)<br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org79cdd2e" class="outline-2">
<h2 id="org79cdd2e">Per stabilire l'utilizzo (efficienza) del mio MAC layer, che presiede la connessione Ethernet, bisogna introdurre al tempo di propagazione, nella formula originale, ovvero tx su tx + 2tp, il contention time medio, ovvero il tempo perso in carrier sense, nel discardare trasmissioni corrotte e nei ritardi. (Bisogna sommare l'inverso (perchè?), e quindi 1/A)</h2>
<div class="outline-text-2" id="text-org79cdd2e">
</div>
<div id="outline-container-org949a6dc" class="outline-3">
<h3 id="org949a6dc">Si dimostra che al tendere delle stazioni K all'infinito, 1/A tende a "e".</h3>
</div>
<div id="outline-container-org9f31a1b" class="outline-3">
<h3 id="org9f31a1b">Inoltre, si ricorda che abbiamo definito tx come dimFrame/velBanda e tp come Lunghezza/velCavo.</h3>
<div class="outline-text-3" id="text-org9f31a1b">
</div>
<div id="outline-container-org1aca4cd" class="outline-4">
<h4 id="org1aca4cd">Allora divido tutto per tx e ottengo \(\frac{1}{1+2 \frac{BL}{CF}e }\). Quindi, all'aumentare della banda e della lunghezza, l'utilizzo diminuisce di tanto.</h4>
<div class="outline-text-4" id="text-org1aca4cd">
</div>
<ul class="org-ul">
<li><a id="orgfbb457a"></a>Sembra inutile aumentare la banda, perchè diminuirebbe l'utilizzo.<br /></li>
<li><a id="orga8004eb"></a>Diventa quindi necessario gestire il problema dell'aumento banda<br />
<ul class="org-ul">
<li><a id="orgc5412ce"></a>Ricordiamo che nelle reti moderne, la struttura è a centro stella passivo, con un hub a cui fanno riferimento vari dispositivi, in una struttura complessa ad albero, in cui i vari hub sono collegati fra loro.<br />
<ul class="org-ul">
<li><a id="org8b4552c"></a>Questa struttura causa problemi quando il numero di dispositivi diventa eccessivo<br /></li>
<li><a id="org96ffaa6"></a>Misurando il tasso di collisione di ritrasmissione, ci si rende conto che la rete è overcrowded<br /></li>
<li><a id="orgcbfa93b"></a>Per ovviare al problema, si fa uso dei <b>bridge</b>.<br />
<ul class="org-ul">
<li><a id="orgf27cf95"></a>Immaginiamo di avere una rete locale composta da 6 stazioni, 3 per hub, su 2 hub collegati.<br />
<ul class="org-ul">
<li><a id="orgb9fa047"></a>Gli hub sono passivi e ogni stazione può trasmettere agli altri, e può anche collidere con essi.<br />
<ul class="org-ul">
<li><a id="orgce63b59"></a>Hub collegati comportano che tutte le stazioni facciano parte dello stesso dominio di collisione, ovvero lo spazio di rete in cui le stazioni competono per l'accesso al canale condiviso di trasmissione<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="orgff55885"></a>Il bridge non è totalmente passivo, ovvero che opera a livello soltanto fisico, ma un apparato intelligente che possiede un buffer e trasmette se utile e necessario secondo certi criteri.<br />
<ul class="org-ul">
<li><a id="org0ddcedf"></a>Se il bridge riceve una trasmissione da parte di una stazione, verso la stazione nello stesso dominio, la scarta, perchè sa che è già arrivata a destinazione<br /></li>
<li><a id="orgc30dbab"></a>Se invece riceve una trasmissione verso un altro dominio a esso collegato, la inoltra verso il nuovo dominio.<br /></li>
<li><a id="orged8109f"></a>Queste operazioni prendono il nome di Store-and-Forward.<br /></li>
<li><a id="org8389157"></a>Un bridge è fatto da tante schede Ethernet (Livelli MAC) quante sono le LAN a esso collegate, con corrispondenti MAC Address per entrambe.<br />
<ul class="org-ul">
<li><a id="org767098a"></a>Quindi si comporta esattamente come una stazione<br /></li>
</ul>
</li>
<li><a id="org0010ef9"></a>Chiaramente, deve contenere anche una tabella con le stazioni e la corrispondente porta attraverso cui è collegato con esse.<br />
<ul class="org-ul">
<li><a id="orgd284594"></a>Per riempire la tabella, si fa in modo che il bridge impari poco alla volta dove si trovano le stazioni. Quando riceve un frame da una porta, salva la stazione nella tabella<br /></li>
<li><a id="orgcb7961f"></a>Se una frame è destinata ad una stazione a cui non è collegata una porta, si fa broadcast.<br />
<ul class="org-ul">
<li><a id="org15121f4"></a>DOMANDA: Quindi ogni volta che trasmetto verso una porta non registrata, occupo tutti i domini di collisione? Se ho un bridge con tante porte, dovrò occuparle tutte, per raggiungerne una sola. E se la porta di destinazione non spedisse mai?<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a id="orgf9a1fc8"></a>Il bridge è il primo strumento di CSMA-CD che opera a <b>livello 2</b><br /></li>
</ul>
</li>
<li><a id="org84fbd8f"></a>Un altro dispositivo è lo <b>switch</b>.<br />
<ul class="org-ul">
<li><a id="orga0959d1"></a>E' simile all'hub, ma siamo a livello 2 e contiene una tabella di store e forward.<br /></li>
<li><a id="org0dc3d07"></a>La differenza con il bridge è che le connessioni fra le stazioni e lo switch sono punto-punto, e quindi il CSMA-CD non è necessario. Lo switch smista le comunicazioni in modo intelligente.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc17ce27" class="outline-2">
<h2 id="orgc17ce27">Per aumentare le prestazioni di Ethernet, potrei scalare il tasso di trasmissione di un ordine di grandezza. Il problema è che il rame non va oltre 25Mbps.</h2>
<div class="outline-text-2" id="text-orgc17ce27">
</div>
<div id="outline-container-org8c4e1f1" class="outline-3">
<h3 id="org8c4e1f1">Una soluzione immediata sarebbe quella di usare 4 fili e dividere un bit in ognuno. In realtà, se ne usano solo 3 per la trasmissione, perchè il 2 è quello usato per CarrierSense e CollisionDetection.</h3>
</div>
<div id="outline-container-org7e91497" class="outline-3">
<h3 id="org7e91497">Come si raggiungono 1000Mbit, con solo 3 fili da 25Mbps? Si usa una codifica diversa, ternaria non binaria, chiamata 8B6T, ovvero "mappo 8 bit Binari su 6 Ternari".</h3>
<div class="outline-text-3" id="text-org7e91497">
</div>
<div id="outline-container-org1bfed1d" class="outline-4">
<h4 id="org1bfed1d">A questo punto abbiamo 100 * 10<sup>6</sup> Mbit *6/8 diviso i 3 fili, ottengo 25 bit ternari per filo, che corrispondono a 33 binari.</h4>
</div>
</div>
</div>
<div id="outline-container-org0b89e4e" class="outline-2">
<h2 id="org0b89e4e">Nell'architettura Ethernet, il primo apparato utilizzato è il repeating hub, passivo, in cui tutte le stazioni contendono per il canale di trasmissione. Gli hub sono collegati da un bridging hub, attivo, che attraverso il principio di Store-and-Forward, separa i domini di collisione dei vari hub. Un bridge ha tante porte ethernet quanti sono i domini collegati. Inoltre, contiene una tabella aggiornata ogni volta che riceve una comunicazione (bridge trasparente). Quando la comunicazione è destinata a una stazione non salvata in tabella, fa flading.</h2>
<div class="outline-text-2" id="text-org0b89e4e">
</div>
<div id="outline-container-org5307182" class="outline-3">
<h3 id="org5307182">flading, broadcast ma senza restituire alla porta da cui è arrivato.</h3>
</div>
<div id="outline-container-org8305a94" class="outline-3">
<h3 id="org8305a94">Un problema è che se un dispositivo, con un certo MAC address, si sposta da un dominio all'altro, la tabella non è più valida. Ogni entrata deve quindi avere un timer, Il flading è quindi parte integrante dell'apparato</h3>
</div>
</div>
<div id="outline-container-org36652b5" class="outline-2">
<h2 id="org36652b5">A livello superiore, c'è uno switch, che funziona come un hub, ma con una memoria ed una cpu, per memorizzare e switchare in modo intelligente. Le connessioni da e per lo switch NON richiedono Carrier Sense, perchè sono punto-punto, in quanto già univocate dal bridge. Il cavo utilizzato è un duplex e può essere anche in fibra. Le porte sono comunque compliant con IEEE nel formato della porta.</h2>
</div>
<div id="outline-container-orgb89f129" class="outline-2">
<h2 id="orgb89f129">Nel CSMA-CD, l'efficienza è \(\frac{1}{1+\frac{2BL}{CF}e}\), quindi se aumento la Bandwidth, devo necessariamente ridurre la lunghezza e aumentare la dimensione del frame.</h2>
<div class="outline-text-2" id="text-orgb89f129">
</div>
<div id="outline-container-org1baa389" class="outline-3">
<h3 id="org1baa389">E' stato deciso, in sede di standard, ogni tratta deve essere grande al massimo 200 metri, quindi 800 metri in tutto al massimo ( per andare sulle 2 tratte e tornare sulle stesse).</h3>
<div class="outline-text-3" id="text-org1baa389">
</div>
<div id="outline-container-org42933ce" class="outline-4">
<h4 id="org42933ce">Su 800 metri, il tempo andata e ritorno è circa 4ms. Con 1Gbit, esce fuori 4000bit, ovvero 500bit, arrotondati a 512B.</h4>
</div>
<div id="outline-container-org413f565" class="outline-4">
<h4 id="org413f565">Se si fosse lasciato il tempo di 51.2 microsecondi, avremmo dovuto mandare 51200 bit per ogni minimo frame e sarebbe stato poco efficiente. Viene quindi ridotto il diametro, e anche la dimensione dei frame.</h4>
</div>
<div id="outline-container-orgf566c10" class="outline-4">
<h4 id="orgf566c10">Per evitare di cambiare anche la porta MAC, che fa il padding di solo 64Byte, il padding viene fatto a livello fisico.</h4>
<div class="outline-text-4" id="text-orgf566c10">
</div>
<ul class="org-ul">
<li><a id="org520a751"></a>In ogni caso, il padding è eccessivo ed è il motivo per cui spopolano gli switch e il Gbit ethernet non ha fatto presa.<br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org24e246f" class="outline-2">
<h2 id="org24e246f">Notiamo che nel Data-Link, a questo punto, non ci sono più collegamenti punto-punto, ma un MAC layer, che controlla l'accesso a un canale condiviso.</h2>
<div class="outline-text-2" id="text-org24e246f">
</div>
<div id="outline-container-orgb7de6e0" class="outline-3">
<h3 id="orgb7de6e0">C'è, però, anche un'interfaccia aggiuntiva, posizionata appena sopra il MAC, ma sempre a livello 2, chiamata <b>Logical Link Control</b>.</h3>
</div>
<div id="outline-container-orgae28138" class="outline-3">
<h3 id="orgae28138">Quello che facciamo con questo sottolivello serve a creare dei canali logici punto-punto fra sè e le altre stazioni.</h3>
<div class="outline-text-3" id="text-orgae28138">
</div>
<div id="outline-container-orgd99e44a" class="outline-4">
<h4 id="orgd99e44a">Quindi, a livello MAC gestisco la situazione Broadcast, e nel Logical Link Control, creo una sovrastruttura logica che modella i collegamenti come punto-punto. In questo modo, dal Logical Link Control in sù, ignoro qualunque ragionamento riguardo il MAC e le sue operazioni.</h4>
<div class="outline-text-4" id="text-orgd99e44a">
</div>
<ul class="org-ul">
<li><a id="orgd74e428"></a>Questi collegamenti logici, possono essere sia best-effort che affidabili, esattamente come fossimo su una rete magliata.<br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org77bff1d" class="outline-2">
<h2 id="org77bff1d">Una VLAN viene utilizzata per introdurre una nuova divisione virtuale fra stazioni. Un motivo per cui viene utilizzata è per aumentare la sicurezza.</h2>
<div class="outline-text-2" id="text-org77bff1d">
</div>
<div id="outline-container-orge2c33c7" class="outline-3">
<h3 id="orge2c33c7">Stazioni che fanno parte di VLAN diverse, non possono comunicare fra loro, anche se fanno parte dello stesso hub. Serve uno switching intelligente per attivare questa funzione, perchè di base le comunicazioni sullo stesso hub girano liberamente</h3>
</div>
<div id="outline-container-org7e1de6f" class="outline-3">
<h3 id="org7e1de6f">Per permettere a macchine appartenenti a VLAN diversi, è necessario utilizzare il routing di livello 3, perchè la separazione introdotta, sebbene logica, è finale.</h3>
<div class="outline-text-3" id="text-org7e1de6f">
</div>
<div id="outline-container-org8b1d767" class="outline-4">
<h4 id="org8b1d767">Gli switch avanzati posseggono una funzione di routing incorporata</h4>
</div>
</div>
<div id="outline-container-orgdc6aa01" class="outline-3">
<h3 id="orgdc6aa01">Le informazioni riguardo le VLAN sono contenute nello switch, che <b>tagga</b> le porte e le frame a esse corrispondenti</h3>
<div class="outline-text-3" id="text-orgdc6aa01">
</div>
<div id="outline-container-orgfab95dd" class="outline-4">
<h4 id="orgfab95dd">Quindi, le stazioni mandano i soliti frame 802.3, e lo switch si occupa di taggarli e smistarli secondo un nuovo standard, chiamato 802.1Q</h4>
<div class="outline-text-4" id="text-orgfab95dd">
</div>
<ul class="org-ul">
<li><a id="orga302fd3"></a>Entrambi i formati, posseggono il DestinationAddress come primo campo. L'1Q, rimpiazza il campo della lunghezza con quello del protocol ID. Quindi, in quel campo, posso aspettarmi sia una lunghezza che l'ID, ed il secondo viene distinto dal fatto che contiene 8100H in hex, ovvero u numero maggiore di 1500 che è la lunghezza massima.<br /></li>
<li><a id="org2ed3205"></a>Nei due byte successivi, si trovano info legate alle VLAN e, in particolare, 12 bit di VLAN identifier.<br /></li>
<li><a id="orgdd80602"></a>Il cavo fra switch, su cui circolano soltanto frame <b>tagged</b>, si chiama <b>trunk</b><br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org6bd004a" class="outline-2">
<h2 id="org6bd004a">Per riassumere i primi 2 livelli, sono entrambi composti da due sottolivelli.</h2>
<div class="outline-text-2" id="text-org6bd004a">
</div>
<div id="outline-container-org0aba66a" class="outline-3">
<h3 id="org0aba66a">Convergence sublayer e Physical-medium dependent layer per il physical layer, il cui primo serve per separare ulteriormente il livello fisico finale, che è fortemente dipendente dall'architettura</h3>
</div>
<div id="outline-container-org70665e6" class="outline-3">
<h3 id="org70665e6">LLC(Logical Link Control) e MAC(Multiple Access Control), il cui primo si occupa di rendere trasparente la gestione complicata del CSMA-CD da parte del MAC, gestendo apparentemente le connessioni come punto-punto.</h3>
</div>
</div>
<div id="outline-container-org45c9f92" class="outline-2">
<h2 id="org45c9f92">Le LAN occupano spazi geografici molto limitati. E' necessario collegare LAN, anche lontane, così che siano tutte raggiungibili. Per farlo, vengono collegate ad uno strato superiore, che sarebbe l'ISP, fino ad arrivare ad un terzo strato che è quello intercontinentale.</h2>
<div class="outline-text-2" id="text-org45c9f92">
</div>
<div id="outline-container-org6954209" class="outline-3">
<h3 id="org6954209">Chiaramente, il MAC address smette di avere valore, su questa scala, e viene introdotto l'IP, che identifica univocamente qualunque stazione appartenente a qualunque LAN.</h3>
</div>
<div id="outline-container-orgf84501b" class="outline-3">
<h3 id="orgf84501b">Nell'andare da una stazione ad un altra, quindi da un livello Application all'altro, attraversiamo un numero indefinito di macchine che operano al massimo a livello 3. Ognuna di esse deve occuparsi dell'Addressing, ovvero come gestire l'univocità dell'IP, ed il routing, ovvero come trovare una strada fra le stazioni in modo efficiente.</h3>
</div>
<div id="outline-container-org1da444c" class="outline-3">
<h3 id="org1da444c">Nel livello 3 non c'è solo un entità, ma 5, di cui analizzeremo due e IP in particolare, con il suo sottomodulo OSPF, per il routing. L'altro è ARP, con cui si mappa/risolve l'IP globale nel MAC.</h3>
</div>
</div>
<div id="outline-container-orgda67ff5" class="outline-2">
<h2 id="orgda67ff5">Nel livello 3 dobbiamo gestire l'indirizzamento e l'instradamento.</h2>
<div class="outline-text-2" id="text-orgda67ff5">
</div>
<div id="outline-container-org50bafa6" class="outline-3">
<h3 id="org50bafa6">Il formato di un pacchetto IP è formato da 5 parole (ovvero 4 byte, 32 bit) ed un ultimo spazio opzionale, utilizzato ad esempio per il source routing.</h3>
<div class="outline-text-3" id="text-org50bafa6">
</div>
<div id="outline-container-orgce08afc" class="outline-4">
<h4 id="orgce08afc">Il primo campo è quello versione, che occupa i primi 4 bit e indica la versione del protocollo, di cui ne esistono due, la v4 e la v6.</h4>
</div>
<div id="outline-container-orgdc7b777" class="outline-4">
<h4 id="orgdc7b777">Dopodichè c'è la header length, che occupa altri 4 bit e specifica quanti byte è lungo l'header. Serve nel caso in cui il campo option venga utilizzato, perchè ha lunghezza variabile.</h4>
</div>
<div id="outline-container-org549abef" class="outline-4">
<h4 id="org549abef">Gli 8 bit successivi sono occupati dal Type Of Service (TOS),</h4>
<div class="outline-text-4" id="text-org549abef">
</div>
<ul class="org-ul">
<li><a id="orgc89354c"></a>E' importantissimo soprattutto oggi, dato che viaggia traffico di tipo diverso (best-effort, audio, video, real time) ed ognuno richiede un servizio diverso.<br />
<ul class="org-ul">
<li><a id="orgc31eeaf"></a>Se arriva un flusso di contenuti real-time, in cui il gitter è importante, questo verrà processato per primo. Lo scheduler sceglie la coda d'uscita in cui imbucare in base a questo parametro, e chi lo decide è il livello superiore.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-org37c9240" class="outline-4">
<h4 id="org37c9240">I successivi 16 bit che completano la parola riguardano la Total Length, che quindi può arrivare a \(2^{16}\).</h4>
</div>
<div id="outline-container-org2da84a2" class="outline-4">
<h4 id="org2da84a2">Nella prossima parola, si inizia con 16 bit per l'ID, seguito da 3 bit, di cui il primo vuoto per futuro uso e due bit chiamati D (Do not fragment) e M (More fragment)</h4>
</div>
<div id="outline-container-org50c95b6" class="outline-4">
<h4 id="org50c95b6">Poi ci sono i restanti 13 bit della parola, che si chiama Fragment Offset</h4>
<div class="outline-text-4" id="text-org50c95b6">
</div>
<ul class="org-ul">
<li><a id="org5774249"></a>Gestisce la frammentazione all'interno del livello 3. Un'unità dati utente non può passare sulla rete nella sua interezza e va frammentata per essere trasmessa. Di solito questa è una funzionalità di livello 4. Questo è un altro tipo di frammentazione.<br />
<ul class="org-ul">
<li><a id="org3fea6a5"></a>Un dato viene prodotto a livello 7 e frammentato in <b>segmenti</b> dal livello 4, che vengono poi singolarmente mandati al livello 3 attraverso il relativo servizio, che lo manda alla rete, che non è un concetto astratto ma una rete di qualche tipo, ad esempio Ethernet, la cui grandezza massima è 512 o ~1500 byte. Quindi il livello 3 deve frammentare a sua volta, che comunica direttamente con il livello 2 per capire la lunghezza massima e predispone sequenze da essa dipendenti.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-org8af348b" class="outline-4">
<h4 id="org8af348b">Nella terza parola, i primi 8 bit sono un timestamp, TTL (Time to live).</h4>
<div class="outline-text-4" id="text-org8af348b">
</div>
<ul class="org-ul">
<li><a id="orge19414d"></a>Ogni pacchetto parte dalla sorgente, che decide quanto tempo può vivere il pacchetto in rete e se arriva alla destinazione con un valore nullo, verrà discardato. Sebbene si parli di Time, di fatto la misura è l'Hop, ovvero quanti step effettua. Se ne effettua troppi, potrebbe essersi trovato in un lungo loop.<br /></li>
</ul>
</div>
<div id="outline-container-org3e15e9a" class="outline-4">
<h4 id="org3e15e9a">Il secondo campo di 8 bit si chiama Protocol selector.</h4>
<div class="outline-text-4" id="text-org3e15e9a">
</div>
<ul class="org-ul">
<li><a id="org49caf05"></a>A livello 4 esistono diversi protocolli, ad esempio TCP ed UDP. Il pacchetto destinazione deve avere un modo per capire quale protocollo la sorgente abbia utilizzato per inviare il pacchetto.<br /></li>
</ul>
</div>
<div id="outline-container-org50421cd" class="outline-4">
<h4 id="org50421cd">I restanti 16 sono di Header Checksum</h4>
<div class="outline-text-4" id="text-org50421cd">
</div>
<ul class="org-ul">
<li><a id="org46ad3b5"></a>Internet è, per definizione, una rete best-effort. Non c'è nessun tipo di affidabilità implementata prima del livello 4. Sull'header, però, si utilizza una checksum in modo da controllare, limitatamente all'header, la validità, in modo da scartare i pacchetti non validi.<br /></li>
</ul>
</div>
<div id="outline-container-org58ab6f6" class="outline-4">
<h4 id="org58ab6f6">Nella quarta e quinta parola troviamo rispettivamente il Source e il Destination address, che quindi sono di 32 bit ognuno.</h4>
</div>
</div>
<div id="outline-container-org5e8aaeb" class="outline-3">
<h3 id="org5e8aaeb">Immaginiamo di avere due stazioni che comunicano, passando attraverso vari gateway, che collegano stazioni attraverso tecnologie diverse.</h3>
<div class="outline-text-3" id="text-org5e8aaeb">
</div>
<div id="outline-container-org2b88605" class="outline-4">
<h4 id="org2b88605">Ad esempio, immaginiamo che la source esca con un ring, con un limite di 4000 byte per frame, passi per due gateway, di cui il secondo è collegato ethernet, con un limite di 1500 byte per frame alla stazione di arrivo.</h4>
<div class="outline-text-4" id="text-org2b88605">
</div>
<ul class="org-ul">
<li><a id="org2d73cd4"></a>In questo caso, devo splittare il pacchetto in un certo modo all'uscita, sfruttando i campi che abbiamo visto prima, ovvero l'ID del pacchetto e il fragment offset (che è un array a scorrimento con info riguardo la posizione del pacchetto mandato).<br /></li>
<li><a id="org9d40d03"></a>Innanzitutto, non posso utilizzare tutti i 4000, perchè 20 servono per l'header.<br /></li>
<li><a id="org2a0aeff"></a>Inoltre, la dimensione massima è a 16 bit, ma l'indice di fragment offset è su 13. Come si potrebbe indicare l'indice successivo a un pacchetto che già occupava la dimensione massima su 16 bit?<br /></li>
<li><a id="org4d980d6"></a>Si decide di utilizzare ogni bit per indicare un ottetto. Questo comporta che ogni frammento deve avere una dimensione in byte che sia un multiplo di 8.<br /></li>
<li><a id="orgae79dfa"></a>Il primo frammento sarebbe quindi di una dimensione uguale al multiplo di 8 appena minore dello spazio rimasto oltre i byte.<br />
<ul class="org-ul">
<li><a id="org2eeb28d"></a>L'ID è assegnato, la lunghezza totale pure. Nel primo frammento il fragment offset sarà a 0, e il bit More fragments a 1. Nel secondo pacchetto, invece, il fragment offset sarà uguale al numero di byte spediti in quello precedente, diviso 8. Così indico la posizione che il nuovo frammento occupa rispetto a quello precedente. Alla fine, il bit M verrà settato a 0 e si passerà al prossimo.<br /></li>
</ul>
</li>
<li><a id="orgf8a6efb"></a>Il riassemblamento viene effettuato soltanto dagli end system, quindi i pacchetti non vengono riassemblati per poi essere di nuovo frammentati per rispettare i nuovi protocolli, ma si lavora sui frammenti già presenti.<br /></li>
<li><a id="org649e85e"></a>In ogni tratta mi occupo di soddifare i requisiti della rete fisica di cui mi sto occupando, ma non ricompongo mai, scompongo soltanto ulteriormente.<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgdbdf437" class="outline-3">
<h3 id="orgdbdf437">L'indirizzamento avviene attraverso l'IP address, che consiste in 4 sequenze di 8 bit, di cui viene rappresentato il valore decimale.</h3>
<div class="outline-text-3" id="text-orgdbdf437">
</div>
<div id="outline-container-org8a501eb" class="outline-4">
<h4 id="org8a501eb">L'indirizzo IP è unico a livello globale. Esiste un organismo internazionale, chiamato ICANN, ovvero "&#x2026; for Name and Numbers" e se voglio assegnare un nome al mio dispositivo, devo chiedere a loro.</h4>
</div>
<div id="outline-container-org8da7c41" class="outline-4">
<h4 id="org8da7c41">Abbiamo 5 modalità di addressing:</h4>
<div class="outline-text-4" id="text-org8da7c41">
<ul class="org-ul">
<li>CLASS based</li>
<li>Subnetting</li>
<li>CIDR (Classless &#x2026;), molto usato</li>
<li>NAT, diffusissimo</li>
<li>IPv6, che riguarda un tipo diverso ai precedenti, ma che usa comunque il NAT ed il subnetting</li>
</ul>
</div>
<ul class="org-ul">
<li><a id="org45bad22"></a>Tutte queste soluzioni sono rivolte a garantire l'unicità degli indirizzi IP<br /></li>
</ul>
</div>
<div id="outline-container-orgb4d7b68" class="outline-4">
<h4 id="orgb4d7b68">Nel CLASS based, esistono 3 classi diverse, che gestiscono trasmissioni Unicast, ovvero punto-punto.</h4>
<div class="outline-text-4" id="text-orgb4d7b68">
</div>
<ul class="org-ul">
<li><a id="orgf4e647d"></a>Esistono anche una classe per Multicast e una Reserved.<br /></li>
<li><a id="org8257f2b"></a>La classe A è caratterizzata dal primo bit settato a quindi il valore del primo byte è da 0 a 127<br /></li>
<li><a id="org73eec65"></a>La classe B ha il primo bit settato ad 1, quindi da 128 a 191<br /></li>
<li><a id="org77e5a7d"></a>La classe C ha i primi due bit, quindi da 192 a 255<br /></li>
<li><a id="org55a8ad1"></a>In ogni classe, una prima sezione riguarda l'ID della rete, mentre la seconda riguarda il singolo Host<br />
<ul class="org-ul">
<li><a id="orgbdaa5d9"></a>Se un router vede che la sezione iniziale è di passaggio, non si preoccupa neanche di controllare l'HostID.<br /></li>
<li><a id="org7e909e4"></a>Più alta è la classe, meno reti univoche esistono, ma hanno più spazio per host.<br /></li>
</ul>
</li>
<li><a id="orge464220"></a>C'è un problema di frammentazione interna: è praticamente impossibile che un certo network ID utilizzi tutti gli Host ID ad esso associati<br /></li>
<li><a id="org7f55a05"></a>Il subnetting riserva, a partire dalla divisione in classi precedente, una parte dell'HostID per creare delle subnet, utili all'amministratore per gestire ed organizzare logicamente le reti.<br />
<ul class="org-ul">
<li><a id="orgf6ddff2"></a>Prendiamo un indirizzo del tipo 130.50.15.6.<br />
<ul class="org-ul">
<li><a id="orgbb5f5ea"></a>Ignoriamo i primi 16 bit, che sono quelli del NetID, abbiamo 15.6, ovvero 00001111 00000110.<br /></li>
<li><a id="org6ac18b3"></a>Come fa il router a selezionare i 6 bit della subnet e i 10 bit dell'host?<br />
<ul class="org-ul">
<li><a id="orgc33e2fd"></a>Bisogna in qualche modo istruire il router in modo che capisca che questo il modo in cui vanno letti e non quello originario, in cui tutti i bit sono Host.<br /></li>
<li><a id="orgf27dc29"></a>Viene quindi introdotta una subnet mask, che filtri via i 6 bit della subnet e lasci tutto il resto, venendo sovrapposta con un AND, dove i 6 bit della subnet, e tutti i bit precedenti, quelli del NetID sono settati a 1, in modo da lasciarli intatti, e il resto a 0, in modo da cancellare il restanti 10 bit dell'host.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org8d00d39" class="outline-2">
<h2 id="org8d00d39">Riguardo l'indirizzamento IP, abbiamo visto metodi per garantire l'unicità dell'indirizzo. Abbiamo visto il subnetting, che va di pari passo con il metodo CLASS based. Subnetting non nasce con l'obiettivo di superare il limite delle classi, ma è trucco organizzativo per inserire un nuovo livello gerarchico per gestire le reti in modo che riflettano di più la struttura.</h2>
<div class="outline-text-2" id="text-org8d00d39">
</div>
<div id="outline-container-org0bbf7ca" class="outline-3">
<h3 id="org0bbf7ca">Gli altri metodi, CIDR e NAT, sono usati per superare il problema della frammentazione interna degli IP e aumentare la longevità di IPv4.</h3>
<div class="outline-text-3" id="text-org0bbf7ca">
</div>
<div id="outline-container-org8262a39" class="outline-4">
<h4 id="org8262a39">Prima o poi, gli indirizzi a 32 bit di v4 finiranno, e saremmo costretti a utilizzare i 128 bit del IPv6.</h4>
</div>
<div id="outline-container-orgaaeeae4" class="outline-4">
<h4 id="orgaaeeae4">CIDR sta per Classless Inter Domain Routing e invece di dividere in classi, lo fa in blocchi autonomi e indipendenti, geografici (europeo, nord-americano, asiatico, ecc.).</h4>
<div class="outline-text-4" id="text-orgaaeeae4">
</div>
<ul class="org-ul">
<li><a id="org49a231a"></a>Per esempio, in Europa gli indirizzi vanno da 194.0.0.0 a 194.255.255.255 e lo stesso per 195. Quindi abbiamo 3 sequenze da 8 bit, quindi ognuna da 256 indirizzi, con un totale di 16,777,216. Questo numero è per ogni sequenza iniziale di bit, quindi, moltiplicata per 2, ci porta ad un totale di 33,554,432 indirizzi per l'europa.<br /></li>
<li><a id="org5ab73c7"></a>Il vantaggio è che ogni operatore può scegliere un numero di subnet o host che preferisce.<br />
<ul class="org-ul">
<li><a id="org42933a7"></a>Fra paginazione e segmentazione, il vantaggio è che la seconda fa perdere frammentazione interna, ma può creare quella esterna.<br />
<ul class="org-ul">
<li><a id="org890eff1"></a>Infatti, nel momento in cui ogni spazio è occupato e uno degli spazi viene deallocato, bisogna trovare qualcuno che abbia bisogno di un numero massimo uguale a quello lasciato, altrimenti non trova posto e quello spazio rimane inallocato.<br /></li>
</ul>
</li>
<li><a id="org3e0212c"></a>Supponiamo che un organizzazione di Milano richieda 2048 indirizzi e gli viene assegnato l'indirizzo 194.24.0.___, fino a quello 194.24.7.___. L'ultima parte è interna e quindi non serve indicarla.<br />
<ul class="org-ul">
<li><a id="org3adaaf5"></a>All'organizzazione viene assegnato l'indirizzo base, ovvero i primi 3 byte. Bisogna però dare al router un altro strumento di filtro, per evitare che vada ad utilizzare indirizzi fuori da questo slot.<br /></li>
</ul>
</li>
<li><a id="org5e7b7e8"></a>Una di roma chiede 2046 indirizzi, servono quindi 16 pagine da 256 indirizzi, allora 4 bit saranno cancellati<br /></li>
<li><a id="orgeed59c5"></a>Ogni router deve quindi far girare tutte le maschere che conosce in AND con l'indirizzo ricevuto, finchè non trova la base dello spazio di indirizzi che è stato assegnato.<br /></li>
<li><a id="orga01375c"></a>Questa soluzione allunga la vita a IPV4, ma non risolve completamente il problema. Fra l'altro, il numero massimo di IP è 30 milioni, molto minore della popolazione europea.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-org8e57fd9" class="outline-4">
<h4 id="org8e57fd9">Il NAT estende ulteriormente la vita di IPv4.</h4>
<div class="outline-text-4" id="text-org8e57fd9">
</div>
<ul class="org-ul">
<li><a id="org3fe63df"></a>Ogni rete privata ha un NAT, che è un router, che fa da "firewall" fra il mondo di indirizzamento pubblico e quello di indirizzamento privato.<br /></li>
<li><a id="orgb93bf64"></a>Vengono riservati gli ip che iniziano con 10, 172 e 192 alle reti private.<br /></li>
<li><a id="org0ff458a"></a>Ogni organizzazione viene raggiunta da un IP unico a livello globale, che poi smisterà il pacchetto agli IP, univoci solo a livello di organizzazione, degli host singoli.<br /></li>
<li><a id="org1caf167"></a>Ovviamente, è necessario che i pacchetti salvino sia l'IP globale che quello locale.<br /></li>
<li><a id="org0e817fb"></a>Bisogna gestire il caso delle requeste da parte degli host locali: questi ultimi sanno dove passare per raggiungere il server, ovvero attraverso il NAT. Il server, invece, riceve una request soltanto dal NAT e risponderà ad esso, ma non ha informazione dell'host locale originario.<br />
<ul class="org-ul">
<li><a id="orgc6aa9d8"></a>Abbiamo bisogno di qualcosa di nuovo per salvare questa informazione, in modo che il NAT riesca ad associare i pacchetti in arrivo con gli specifici host.<br /></li>
<li><a id="org4b07c74"></a>Un metodo per risolvere questo problema è attraverso il concetto di porta: il TCP è un identificatore numerico che vale solo nel sistema operativo, che associa all'interno della macchina il processo alla specifica entità TCP.<br />
<ul class="org-ul">
<li><a id="org1c877c5"></a>Il numero della porta è restituito all'apertura di una socket, come per i file descriptor al momento della open o write in un SO.<br /></li>
<li><a id="org145076e"></a>I server web di tutto il mondo parlano sulla porta 80, well-known-port.<br /></li>
<li><a id="orgd793a35"></a>I server client hanno, invece, un numero di porta effimero assegnato mediante chiamata a primitiva socket e consistente durante la vita della socket.<br /></li>
<li><a id="orge4259ce"></a>Immaginiamo ora che la host machine dietro NAT usi la porta 1500 ed il server la porta 80. Allora, ogni pacchetto conterrà, oltre ai 3 ip coinvolti (host, NAT, server), anche la porta sorgente e quella destinazione, così che la comunicazione avverrà tra le due porte in questione e il NAT avrà modo di associare il pacchetto in arrivo all'host originario.<br /></li>
<li><a id="orgbe0e8b9"></a>A questo punto, la gerarchia ben definita secondo cui ogni livello pensa solo a sè stesso, crolla.<br />
<ul class="org-ul">
<li><a id="orgceca3f1"></a>Infatti, IP porta in giro lo header di TCP, che sta a livello 4 e quindi dovrebbe essere completamente ignorato a livello 3.<br /></li>
<li><a id="org642ab3c"></a>Invece, il router NAT a livello 3, per compiere le sue tipiche funzioni di instradamento nell'inviare il pacchetto alla sua macchina host, deve andare a leggere lo header TCP, in particolare la porta che quello ha assegnato all'host. Lo stesso vale per le comunicazioni in uscita.<br /></li>
<li><a id="org3adce27"></a>Insomma, lo svolgimento del livello 3 quando è coinvolto un NAT, è basato su risultati creati a livello 4.<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="org4f11f2c"></a>Questa soluzione porta ad un problema successivo: cosa accade se a due processi differenti, viene assegnato lo stesso numero di porta dalle primitive socket?<br /></li>
<li><a id="org6e2f4fa"></a>L'unico modo diventa quello di rendere le porte univoche, ed il NAT lo fa utilizzando una numerazione propria e diversa per ogni processo.<br />
<ul class="org-ul">
<li><a id="org7c93f69"></a>Il NAT, quindi, accede allo header di livello 4 non soltanto per leggere, ma anche per sostituire la porta locale con quella NAT.<br /></li>
<li><a id="org4934125"></a>Ovviamente, modifica anche l'IP.<br /></li>
<li><a id="orga666479"></a>Di conseguenza, le reply arriveranno all'IP del NAT e alla specifica porta NAT, che quest'ultimo trasformerà nella porta host corretta.<br /></li>
<li><a id="org258a725"></a>A cosa serve quindi tenere la porta originale? BHO<br /></li>
</ul>
</li>
<li><a id="orgf55b824"></a>Il NAT offre grandi garanzie in termini di sicurezza, perchè le macchine dietro di lui sono assolutamente invisibili ed inaccessibili dall'esterno, infatti fa anche da firewall.<br /></li>
<li><a id="org75247c1"></a>L'ultima questione da risolvere è quella di un server dietro NAT, dato che nessuno conosce la porta che mi porta ad esso.<br />
<ul class="org-ul">
<li><a id="orgb0bb158"></a>Un modo banale è quello di assegnargli un IP pubblico, ma perdendo i vantaggi dovuti all'utilizzo del NAT.<br /></li>
<li><a id="orgd42ead6"></a>Un secondo modo è quello di aprire la porta specifica del server. In questo modo, tutte le richieste verso quella porta vengono routate al server in questione.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf2d0b45" class="outline-2">
<h2 id="orgf2d0b45">Sebbene l'indirizzamento sia parte del livello 3 a livello globale, ogni livello possiede il proprio indirizzo per comunicare con altre macchine.</h2>
<div class="outline-text-2" id="text-orgf2d0b45">
</div>
<div id="outline-container-org9949c36" class="outline-3">
<h3 id="org9949c36">A livello 2, in una rete CSMA-CD l'indirizzo è il MAC</h3>
</div>
<div id="outline-container-orgc24557f" class="outline-3">
<h3 id="orgc24557f">A livello 3, l'indirizzo è quello IP, con tutte le considerazioni fatte in precedenza.</h3>
</div>
<div id="outline-container-orgf878fff" class="outline-3">
<h3 id="orgf878fff">Un problema che dobbiamo risolvere è quello di mappare l'IP al corrispondente MAC.</h3>
<div class="outline-text-3" id="text-orgf878fff">
</div>
<div id="outline-container-orga5ebf2f" class="outline-4">
<h4 id="orga5ebf2f">Infatti, finora non c'è nessun modo per far arrivare un pacchetto a destinazione.</h4>
</div>
</div>
<div id="outline-container-org8fe718b" class="outline-3">
<h3 id="org8fe718b">Immaginiamo che A e B siano sulla stessa rete locale.</h3>
<div class="outline-text-3" id="text-org8fe718b">
</div>
<div id="outline-container-org0256618" class="outline-4">
<h4 id="org0256618">Se la macchina A manda un pacchetto al modulo B, chiede ad ARP di risolvere l'IP in un MAC address, così che possa mandarglielo attraverso il livello 2</h4>
</div>
<div id="outline-container-org3197514" class="outline-4">
<h4 id="org3197514">In pratica l'ARP, per conto di IP, manda ai livelli sottostanti una richiesta, ARPRequest, così che il dispositivo in questione risponda con un ARPReply, rispondendo con il proprio MAC, che ARP fornirà al livello IP della macchina sorgente.</h4>
<div class="outline-text-4" id="text-org3197514">
</div>
<ul class="org-ul">
<li><a id="org21a1def"></a>Le due macchine, nell'esempio, si trovano nella stessa rete. Ovviamente, nella richiesta non si sa chi sia l'host destinazione, quindi è necessario fare una richiesta broadcast. La risposta sarà, invece, punto-punto.<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org006ece3" class="outline-3">
<h3 id="org006ece3">Immaginiamo adesso che siano su macchine diverse.</h3>
<div class="outline-text-3" id="text-org006ece3">
</div>
<div id="outline-container-org3825012" class="outline-4">
<h4 id="org3825012">A manda richiesta a Z, su un'altra rete.</h4>
</div>
<div id="outline-container-org62703d6" class="outline-4">
<h4 id="org62703d6">Il site access gateway leggerà il NETID e vedrà che non appartiene alla rete locale e che quindi va cercato al di fuori. Prenderà lui in carico l'operazione.</h4>
</div>
<div id="outline-container-org6908c02" class="outline-4">
<h4 id="org6908c02">A questo punto, risponderà con il proprio MAC, in modo che A mandi le richieste al gateway.</h4>
</div>
<div id="outline-container-org0c3ea64" class="outline-4">
<h4 id="org0c3ea64">Il gateway aspetterà autonomamente per la ARPReply della macchina remota e salverà il risultato.</h4>
</div>
<div id="outline-container-orgc106fa6" class="outline-4">
<h4 id="orgc106fa6">Questo servizio si chiama ProxyARP.</h4>
</div>
</div>
<div id="outline-container-org27f1974" class="outline-3">
<h3 id="org27f1974">ARP in ogni dispositivo terrà una ARP Cache, in cui salverà tutte le associazioni IP-MAC, così che le volte successive non servirà una nuova richiesta.</h3>
</div>
<div id="outline-container-org47c76d8" class="outline-3">
<h3 id="org47c76d8">Quindi uso ARP per fare una discovery delle macchine che sono raggiungibili in rete.</h3>
</div>
<div id="outline-container-org7362afc" class="outline-3">
<h3 id="org7362afc">Anche in questo caso, abbiamo un livello 3 che per funzionare (anzi, il suo obiettivo) è di livello 2. Deve infatti andare a toccare il MAC, indirizzo di livello 2, ma in questo caso almeno fa una richiesta</h3>
</div>
<div id="outline-container-org5a1fe8f" class="outline-3">
<h3 id="org5a1fe8f">Notiamo che nello header di livello 3, il campo type è usato anche per identificare se la richiesta sia IPv4 o ARP</h3>
</div>
</div>
<div id="outline-container-orga364f3b" class="outline-2">
<h2 id="orga364f3b">Introduciamo il DHCP</h2>
<div class="outline-text-2" id="text-orga364f3b">
</div>
<div id="outline-container-orgfb8a238" class="outline-3">
<h3 id="orgfb8a238">Abbiamo tante macchine collegate ad una LAN, che possono essere nostre oppure di ospiti che arrivano transitoriamente. Come assegniamo l'IP privato alle macchine?</h3>
<div class="outline-text-3" id="text-orgfb8a238">
</div>
<div id="outline-container-org5145849" class="outline-4">
<h4 id="org5145849">La LAN potrebbe essere Wireless, collegata tramite un Access Point ad una Lan fisica, che tramite il suo Access Gateway è collegata alla rete fisica.</h4>
</div>
</div>
<div id="outline-container-org702346e" class="outline-3">
<h3 id="org702346e">Il Gateway riesce a fare Address Resolution e quindi è anche un NAT. Ovvero, riesce a mascherare un indirizzo interno.</h3>
<div class="outline-text-3" id="text-org702346e">
</div>
<div id="outline-container-org8bc15cf" class="outline-4">
<h4 id="org8bc15cf">Ci presenta con un IP pubblico alla rete, ma poi smista alle macchine singole con gli indirizzi privati.</h4>
</div>
</div>
<div id="outline-container-org7ade03f" class="outline-3">
<h3 id="org7ade03f">Questi indirizzi potrebbero esere statici, ma questo è scomodo. (Perchè?).</h3>
</div>
<div id="outline-container-org177e6b8" class="outline-3">
<h3 id="org177e6b8">E' più comodo se al momento della prima connessione alla rete, venga assegnato un IP dinamico al dispositivo, che rimanga fino allo spegnimento.</h3>
</div>
<div id="outline-container-org41645d7" class="outline-3">
<h3 id="org41645d7">Per assegnare l'IP dinamico, usiamo il server DHCP (eventualmente molteplici)</h3>
<div class="outline-text-3" id="text-org41645d7">
</div>
<div id="outline-container-orgd49fe90" class="outline-4">
<h4 id="orgd49fe90">Appena una macchina cliente viene bootata, fa un operazione di Request DHCP al server, che farà a sua volta una Reply.</h4>
</div>
<div id="outline-container-org3f89800" class="outline-4">
<h4 id="org3f89800">La reply assegna un IP privato, valido per tutto il tempo necessario.</h4>
<div class="outline-text-4" id="text-org3f89800">
</div>
<ul class="org-ul">
<li><a id="org471aaa9"></a>Addirittura, un DHCP address ha un TimeToLeave, poi viene buttato e refreshato.<br /></li>
<li><a id="orgc14e941"></a>Al punto che quando arriva un ospite (abilitato ad accedere alla rete), loro parlano con DHCP e diventano a tutti gli effetti parte della rete.<br /></li>
</ul>
</div>
<div id="outline-container-orgd7e28a6" class="outline-4">
<h4 id="orgd7e28a6">La RequestForComment che lo definisce è la 2131.</h4>
</div>
<div id="outline-container-orgd6cfeff" class="outline-4">
<h4 id="orgd6cfeff">Il client triggera la richiesta, che nello specifico si chiama DHCP Discover.</h4>
<div class="outline-text-4" id="text-orgd6cfeff">
</div>
<ul class="org-ul">
<li><a id="orgfdb84bb"></a>Questa discover è un pacchetto IP che viaggia con sorgente 0.0.0.0, perchè non so scriverlo ed è proprio per questo che mando la richiesta.<br /></li>
<li><a id="org86fceb2"></a>La destinazione è 255.255.255.255. Un pacchetto broadcast all'interno della LAN. Non va direttamente al server DHCP. Il motivo è che se io voglio un assegnamento dinamico per ogni macchina, anche non appartenenti alla mia rete, non posso assumere che questi sappiano l'indirizzo del server DHCP.<br /></li>
<li><a id="orgf5fbaee"></a>Inoltre, se io mettessi un singolo IP, perderei la possiblità di avere molteplici DHCP server, utilizi banalmente per ridondanza.<br /></li>
<li><a id="org4943aab"></a>Poi c'è un campo Time To Live,  con un Transaction ID, che viene associato all'indirizzo della macchina.<br />
<ul class="org-ul">
<li><a id="org553e203"></a>Questo serve per associare le request alle response<br /></li>
<li><a id="orgca3592c"></a>Per identificare questo Time To Live con il client della richiesta, non può essere utilizzato l'IP, ma necessariamente il MAC di livello 2.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-orgf03f68d" class="outline-4">
<h4 id="orgf03f68d">Il server riceve la richiesta e reagisce con una DHCP Offer.</h4>
<div class="outline-text-4" id="text-orgf03f68d">
</div>
<ul class="org-ul">
<li><a id="orgfcdd027"></a>Quello che offre il DHCP server è l'IP address.<br /></li>
<li><a id="org5f3e3b9"></a>Sarà sempre un pacchetto con sorgente IP del Server, broadcast e lo stesso transactionID della richiesta.<br />
<ul class="org-ul">
<li><a id="org5efe796"></a>Deve necessariamente essere broadcast.<br /></li>
</ul>
</li>
<li><a id="org62f58e4"></a>Prima di fare la offer, il server fa un check. Il check dell'IP prevede che tramite ICMP il server sia in grado di verificare se per caso quell'IP non sia stato già assegnato a qualcuno per errore.<br />
<ul class="org-ul">
<li><a id="orga63158f"></a>In pratica fa un ping, che prevede un echo se la stazione è raggiungibile. Se l'echo è assente, l'IP non è stato associato a nessuno. Altrimenti l'IP va aggiornato.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-orgcb74896" class="outline-4">
<h4 id="orgcb74896">A questo punto il client ha <b>apparentemente</b> risolto il suo problema.</h4>
<div class="outline-text-4" id="text-orgcb74896">
</div>
<ul class="org-ul">
<li><a id="orgf322ecb"></a>Si può immaginare che il client abbia un timeout in modo che non trascorra troppo prima dell'arrivo di una offer. (Stesso principio dell'ACK).<br /></li>
<li><a id="orgbcb8ce7"></a>Il problema è che un algoritmo di questo tipo funzionerebbe se e solo se ammettesse uno e un solo server DHCP operativo per ogni rete, ma il protocollo è fatto per funzionare con un numero arbitrario di server.<br />
<ul class="org-ul">
<li><a id="org608669c"></a>Infatti, la discover è in broadcast e arriva a tutti i server, che si adopereranno tutti per offrire un IP.<br /></li>
</ul>
</li>
<li><a id="orgb3bfec6"></a>Bisogna garantire che venga accettata l'offerta di un solo server.<br /></li>
</ul>
</div>
<div id="outline-container-orgd8c95be" class="outline-4">
<h4 id="orgd8c95be">Diventa necessaria un ulteriore fase, una commit, chiamata DHCP Request.</h4>
<div class="outline-text-4" id="text-orgd8c95be">
</div>
<ul class="org-ul">
<li><a id="org26dcdc1"></a>Questa viaggia con stesse sorgente e destinazione della discover (0 e 1Broadcast), ma con un ulteriore campo scelta, che contiene un ID del server la cui offerta è stata accettata.<br /></li>
</ul>
</div>
<div id="outline-container-org4781086" class="outline-4">
<h4 id="org4781086">A questo punto, si chiude il commitment con una DHCP Ack, che è una validazione della request. Anche questo è mandato in broadcast secondo IP.</h4>
<div class="outline-text-4" id="text-org4781086">
</div>
<ul class="org-ul">
<li><a id="org524b4ea"></a>Ricordare che tutte queste comunicazioni di risposta da parte del server, utilizzano il MAC di livello 2 e sono quindi Unicast.<br /></li>
</ul>
</div>
<div id="outline-container-org56834c6" class="outline-4">
<h4 id="org56834c6">Questo protocollo è un protocollo a 4 vie, a causa della necessità di selezionare fra i vari server.</h4>
</div>
<div id="outline-container-orgfc04fe1" class="outline-4">
<h4 id="orgfc04fe1">Servono inoltre dei check per verificare la validità degli IP, anche dal punto di vista del client.</h4>
<div class="outline-text-4" id="text-orgfc04fe1">
</div>
<ul class="org-ul">
<li><a id="orgd2b33f5"></a>Viene utilizzato ARP, che è perfetto per questo lavoro, ovvero risolvere un IP in un MAC.<br />
<ul class="org-ul">
<li><a id="org94514a1"></a>Facendo una ARP request con l'IP appena assegnato al server, in caso di risposta positiva si capisce che l'IP è già assegnato.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-orgf269c02" class="outline-4">
<h4 id="orgf269c02">Esistono dei meccanismi di ricovero, per gestire i casi in cui i messaggi vengano persi. Si utilizza ad esempio un timer T, che viene eseguito massimo K volte (numero di retry). Una volta aver provato K volte, si ritorna alle origini e si ricomincia da capo.</h4>
</div>
</div>
</div>
<div id="outline-container-orgb708918" class="outline-2">
<h2 id="orgb708918">L'ICMP utilizzato per il ping e per capire delle statistiche sulla rete, fa uso di uno Header IP ed utilizza un Checksum, oltre che il tipo di richiesta (ce ne sono varie).</h2>
</div>
<div id="outline-container-orge7c1a2a" class="outline-2">
<h2 id="orge7c1a2a">Un importante compito del livello 3 è quello di instradare i pacchetti verso la giusta destinazione. Il grafo della rete è parzialmente connesso e serve un livello superiore a quello del data link che abbia una visione più ampia e riesca a smistare i pacchetti in un modo intelligente ed efficiente</h2>
<div class="outline-text-2" id="text-orge7c1a2a">
</div>
<div id="outline-container-orge2b9391" class="outline-3">
<h3 id="orge2b9391">Immaginiamo di avere due macchine con porte I/O e un forwarder in mezzo, che contiene una tabella e fa un lookup per capire su quale porta trasmettere il messaggio entrato.</h3>
<div class="outline-text-3" id="text-orge2b9391">
</div>
<div id="outline-container-org7142a67" class="outline-4">
<h4 id="org7142a67">A livello 2, questo è fatto dal bridge, che popola e spopola le tabelle periodicamente per lasciar spostare le macchine.</h4>
</div>
<div id="outline-container-org89bdb66" class="outline-4">
<h4 id="org89bdb66">Se saliamo di un piano, quello che cambia radicalmente è che non è più vero che la macchina destinazione sia attaccata al link. La validità di un forwarding livello 2, a livello 3 non è più sufficiente.</h4>
<div class="outline-text-4" id="text-org89bdb66">
</div>
<ul class="org-ul">
<li><a id="org2ca0a3d"></a>Il forwarding deve avere la capacità di scegliere la porta che conduce alla destinazione in futuro, e in un modo oscuro alla singola macchina.<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org6435a20" class="outline-3">
<h3 id="org6435a20">A livello 3, la tabella viene popolata da un secondo processo, che chiamiamo <b>router</b>, che lavora con i suoi pacchetti di controllo, utili soltanto a lui, tramite i quali impara la topologia della rete e popola la tabella in modo da permettere di raggiungere ogni host in un modo efficiente, possibilmente il cammino minimo.</h3>
<div class="outline-text-3" id="text-org6435a20">
</div>
<div id="outline-container-orgc52154f" class="outline-4">
<h4 id="orgc52154f">La cosa interessante è che abbiamo una separazione netta fra tutto ciò che è gestione dei dati utente e la gestione di controllo di tutto ciò che serve alla rete autonomamente perchè funzioni.</h4>
</div>
<div id="outline-container-org2ea2758" class="outline-4">
<h4 id="org2ea2758">Con il routing questa diventa chiara.</h4>
<div class="outline-text-4" id="text-org2ea2758">
</div>
<ul class="org-ul">
<li><a id="org0e36709"></a>Finora i messaggi di controllo e i dati erano mescolati, anche fisicamente.<br /></li>
<li><a id="org1b4ed6c"></a>Adesso, il router lavora in modo assolutamente autonomo.<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org8f6637a" class="outline-3">
<h3 id="org8f6637a">Il router opera attraverso 3 tecniche:</h3>
<div class="outline-text-3" id="text-org8f6637a">
<ul class="org-ul">
<li>Distance vector - RIP, vecchio e residuale</li>
<li>OSPF, link state, più diffuso</li>
<li>BGP, Border Gateway Protocol, evoluzione del distance vector, utilizzato per la comunicazione ad alto livello, intercontinentale</li>
</ul>
</div>
<div id="outline-container-orgfcf33ee" class="outline-4">
<h4 id="orgfcf33ee">Il protocollo con Distance vector opera assegnando due etichette con numero del link e corrispondente peso su ogni arco bidirezionale.</h4>
<div class="outline-text-4" id="text-orgfcf33ee">
</div>
<ul class="org-ul">
<li><a id="orgbb782c3"></a>Ogni nodo produce la tabella delle adiacenze. Questa contiene Router, Link e Cost.<br />
<ul class="org-ul">
<li><a id="org6712195"></a>Sè stesso è raggiungibile da sè stesso (no link) con costo 0.<br /></li>
<li><a id="org6363bd1"></a>Ogni altro router, è raggiungibile attraverso un certo link, con un costo uguale alla somma delle etichette dei pesi di tutti gli archi che vengono attraversati.<br /></li>
</ul>
</li>
<li><a id="orgcdef49c"></a>Con queste costruiamo la conoscenza locale, ovvero tutti i router appena adiacenti attraverso soltanto un filo, insieme al loro costo.<br />
<ul class="org-ul">
<li><a id="org921febf"></a>Ancora non abbiamo una visione topologica della rete. Abbiamo solo una visione delle adiacenze.<br />
<ul class="org-ul">
<li><a id="org964da0e"></a>Un singolo nodo nono ha idea di quali nodi possa raggiungere oltre le adiacenze.<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="org9bdcbf3"></a>Il modo per passare da una conoscenza locale a quella globale sfrutta la comunicazione fra nodi.<br /></li>
<li><a id="org2b9984c"></a>Periodicamente viene trasferito agli altri il distance vector, ovvero l'associazione Router-Costo<br />
<ul class="org-ul">
<li><a id="org0c500a6"></a>Ogni router ha un proprio timer, alla scadenza del quale trasferisce il vettore delle distanze ai suoi vicini.<br /></li>
</ul>
</li>
<li><a id="orga147aeb"></a>Quando un nodo riceve il vettore delle distanze del vicino, aggiorna il proprio vettore con i nuovi nodi raggiungibili attraverso il vicino, la cui distanza è la somma fra il primo nodo è quello appena collegato e quest'ultimo con il nuovo.<br /></li>
<li><a id="org8b2773a"></a>Ogni vettore delle distanze nuovo che arriva, un router calcola anche tutte le nuove distanze per le destinazioni che già conosce, in modo da aggiornare nuove distanze minime.<br /></li>
<li><a id="orga430b65"></a>Il tempo necessario per conoscere tutta la rete è lineare con il suo diametro.<br /></li>
<li><a id="org22111a5"></a>Viene inoltre utilizzato il trigger update con cui i nodi vicini possono richiedere informazioni alla variazione dello stato. Ad esempio usano il trigger update i router appena accesi così chiamano velocemente informazioni nuove.<br /></li>
<li><a id="orgdb108cf"></a>Il problema di questo protocollo è che non c'è modo di aggiornare in caso di peggioramenti e questo causa un malfunzionamento abbastanza grave.<br />
<ul class="org-ul">
<li><a id="orgd2a9752"></a>Immaginiamo che un link su un certo nodo si guasti.<br />
<ul class="org-ul">
<li><a id="org9173550"></a>Il nodo stesso lo riconosce subito e aggiorna la propria tabella con valore <b>infinito</b> per il nodo dietro quel link.<br /></li>
<li><a id="org27831b6"></a>Gli altri nodi però non lo sanno e continuano a mandare su quel link, se la loro tabella dice che è quella la strada minore.<br /></li>
<li><a id="org07dd6d0"></a>Questa situazione finisce soltanto nel momento in cui B propaga il suo distance vector con costo infinito.<br /></li>
<li><a id="org5ee8873"></a>Cosa succede se però nel frattempo un altro nodo, non ancora informato del guasto, manda il proprio distance vector al nodo che ha appena notato il guasto?<br />
<ul class="org-ul">
<li><a id="org9fddf0a"></a>Siano A, B e C i nodi, con A che vuole raggiungere C attraverso B, e il collegamento fra B e C guasto.<br />
<ul class="org-ul">
<li><a id="org6b7b987"></a>Allora la distanza fra A e C è uguale alla distanza fra A e B più quella fra B e C<br /></li>
<li><a id="org050fa46"></a>Il problema è che adesso la distanza fra B e C è infinita, ma quella fra A e C considera ancora il valore da B e C precedente.<br /></li>
<li><a id="orga364059"></a>Allora B aggiorna la sua stessa distanza fra B e C come quella suggerita da A, che però già contiene la distanza B-C non aggiornata, più la distanza fra A e B.<br />
<ul class="org-ul">
<li><a id="org02ae7a1"></a>In pratica, B rimpiazza l'infinito con la distanza B-A più A-B più B-C vecchia.<br /></li>
<li><a id="org1548c17"></a>Alla update successiva, A vede che B ha aumentato la propria distanza di un valore uguale alla distanza A-B e aggiorna il suo valore a quella distanza, più B-A<br />
<ul class="org-ul">
<li><a id="orgb2023e3"></a>Quindi A rimpiazza A-B + old(B-C) con A<br /></li>
<li><a id="orgfb9cae9"></a>Quello che succede è questo (indico la distanza fra i nodi A o B e C):<br />
<div class="outline-text-11" id="text-orgfb9cae9">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">A</td>
<td class="org-left">B</td>
<td class="org-left">stato</td>
</tr>

<tr>
<td class="org-left">[A-B]+[B-C]</td>
<td class="org-left">[B-C]</td>
<td class="org-left">Iniziale</td>
</tr>

<tr>
<td class="org-left">//</td>
<td class="org-left">Inf</td>
<td class="org-left">Collegamento rotto e DVB viene perso</td>
</tr>

<tr>
<td class="org-left">//</td>
<td class="org-left">[B-A]+[A-B]+[B-C]</td>
<td class="org-left">B acquisisce la distanza da A</td>
</tr>

<tr>
<td class="org-left">[A-B]+[B-A]+[A-B]+[B-C]</td>
<td class="org-left">//</td>
<td class="org-left">A acquisisce da B</td>
</tr>

<tr>
<td class="org-left">//</td>
<td class="org-left">[B-A]+"same as top left"</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>
</div>
</li>
</ul>
</li>
<li><a id="org11730ea"></a>Si inizierà un <b>count to infinity</b> in cui ad ogni step la distanza verso quel collegamento aumenta della distanza fra i due nodi in questione.<br /></li>
<li><a id="org1d744b4"></a>Questo accade perchè le distanze di sia A che B verso quello guasto C contengono al loro interno la distanza A-B. Ovvero, B raggiunge C tramite A (o almeno crede di fare così) e A raggiunge C tramite B.Il sistema è innescato da B, che normalmente non dovrebbe aggiornare la propria distanza per includere quella di A, perchè il collegamento diretto con C è banalmente più breve di quello che compie un ciclo tramite A e poi ripercorre il collegamento diretto.<br />
<ul class="org-ul">
<li><a id="org6dd36a5"></a>Quando però il link con C è danneggiato, accade che il ciclo attraverso A più la vecchia distanza B-C è sicuramente più breve dell'infinito e B aggiorna, senza sapere che A fa affidamento su di lui.<br /></li>
<li><a id="orgbe33f40"></a>A aggiorna, senza sapere che B fa affidamento su di lui.<br /></li>
<li><a id="org274f467"></a>MAIN<br />
<div class="outline-text-11" id="text-org274f467">
<p>
Maybe the solution is that the distance vector also contains the link that leads to a node.
If a new value comes from a distance vector, and that value is HIGHER than the one a node already had, but it is on the same link, the node updates it.
</p>

<p>
Yes, exactly! That's the key insight that explains why count to infinity actually occurs. The distance vector protocol also keeps track of the next hop (the link or neighbor through which a destination is reached), not just the distances.
</p>

<p>
So in the A-B-C scenario:
</p>

<p>
Initially A reaches C through B (next hop = B)
When B-C link fails:
    B sets its distance to C as infinity
    When A receives B's update, even though it's a larger value, A MUST accept it because B is its next hop to C
    A can't keep its old shorter value because that path was dependent on going through B
</p>

<p>
This is why it's crucial that nodes update their routes when they receive updates from their next hop neighbor, even if the new distance is larger. The node must trust its next hop's information about destinations reached through that path.
</p>

<p>
This is also why solutions like split horizon work - they prevent nodes from advertising routes back through the path they learned them from, breaking this cycle of increasing distances.
</p>

<p>
Your observation about the importance of the link/next hop information is spot-on and explains the actual mechanism behind count to infinity much more accurately than the oversimplified "only accept shorter paths" explanation.
SPIEGAZIONE DEL PERCHÈ UN NODO ACCETTA UN VALORE PIÙ ALTO
</p>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li><a id="orgc48b234"></a>Le due cause del problema sono il fatto che l'informazione dello specifico nodo utilizzato per raggiungere una destinazione è persa, e che i disstance vector viaggiano in modo asincrono e possono anche essere smarriti.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a id="org3c678f4"></a>Il count to infinity da luogo al bouncing effect, in cui i pacchetti fra i nodi A e B dell'esempio precedente rimangono bloccati rimbalzando fra gli stessi.<br /></li>
<li><a id="org751747c"></a>Una soluzione al <b>count to infinity</b> è lo <b>split horizon</b><br />
<ul class="org-ul">
<li><a id="org14c2c42"></a>Il distance vector riporterà costo infinito per il link corrispondente a quello utilizzato per inviare lo stesso distance vector.<br />
<ul class="org-ul">
<li><a id="org2ed3cb0"></a>Di conseguenza, quando l'infinito inizia a propagarsi,<br /></li>
<li><a id="org2a5a4ad"></a>Con questo trucco, il distance vector non potrà contenere loop perchè un nodo non sceglierà mai di utilizzare il link che conduce ad un loop.<br /></li>
<li><a id="orgf1cead1"></a>Esiste un caso in cui il problema del count to infinity avviene anche in questo caso.<br />
<ul class="org-ul">
<li><a id="org00a2151"></a>In particolare, lo split horizon non aiuta nel caso in cui ci siano più di due router coinvolti. Infatti, in questo caso, il nodo appena adiacente a quello su cui è avvenuto il guasto non direbbe a questùltimo di conoscere la strada, ma la direbbe ad un nodo ancora successivo e collegato al primo, su cui è avvenuto il guasto. il terzo nodo della catena avviserebbe il primo di conoscere una strada, la quale sebbene non passi per il link diretto con il nodo che ha un link guasto, passa per un ciclo che eventualmente arriverà a quel nodo. La conseguenza è la stessa.<br />
<div class="outline-text-8" id="text-org00a2151">
<pre class="example" id="org8d4e74a">
Consider three routers A, B, and C in a loop
If the link between A and destination D fails
Router A marks D as unreachable (16)
However, B might still tell C it can reach D
C might then tell A it can reach D
A might then choose this alternative path, not knowing it's part of a loop
The metric will keep increasing until it reaches infinity
</pre>
</div>
</li>
<li><a id="org1caefb4"></a>Si può dunque dire che lo split horizon abbia un orizzonte di risoluzione di massimo 2 nodi, oltre i quali il problema è irrisolvibile.<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="org519ea00"></a>I difetti sono che: 1 passo solo il peso ma non il percorso seguito ,2 non ho la topologia magliata, ma conosco solo i miei vicini,3 la propagazione è asincrona e potrei perdere qualche informazione, ovvero le tabele non sempre divergono.<br /></li>
<li><a id="orgb1d49a3"></a>Quindi le tre tecniche usate per migliorare l'efficienza di questa tecnica sono le seguenti:<br />
<div class="outline-text-6" id="text-orgb1d49a3">
<ul class="org-ul">
<li>Triggered update</li>
<li>Split horizon</li>
<li>Ogni tempo T flusho le tabelle e risolvo tutte le situazioni difficili che si erano create.</li>
<li>L'infinito è appena maggiore di 16</li>
<li>Storm di update
<ul class="org-ul">
<li>Quando c'è un guasto, tutti i nodi coinvolti farebbero update, con seguente congestione. Viene quindi introdotto un random fra 1 e 5 secondi, così da ridurre la storm ma aumentando la probabilità di count to infinity</li>
</ul></li>
</ul>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org521936a" class="outline-2">
<h2 id="org521936a">Ci rifacciamo alla stessa struttura riguardante il routing, con un router che contiene un forwarder con porte IO di ingresso ed uscita e che opera su una tabella di routing, facendo un lookup e stabilendo la corretta porta di output. Chi scrive sulla tabella è il router, che ha i propri pacchetti di controllo e opera come un processo totalmente asincrono ed indipendente.</h2>
<div class="outline-text-2" id="text-org521936a">
</div>
<div id="outline-container-org51cd9b2" class="outline-3">
<h3 id="org51cd9b2">Il router è attivato periodicamente, mentre il forwarder è attivato alla presenza di un pacchetto in coda di input.</h3>
</div>
<div id="outline-container-org571f68f" class="outline-3">
<h3 id="org571f68f">Vogliamo sviluppare una soluzione alternativa in cui oltre al peso e alla destinazione del cammino, si dice anche il link che si vuole utilizzare</h3>
</div>
<div id="outline-container-org697fcc3" class="outline-3">
<h3 id="org697fcc3">La gran parte delle reti fondamentali di internet, ovvero quelle intermedie fra LAN, utilizza un protocollo chiamato OSPF Link State</h3>
<div class="outline-text-3" id="text-org697fcc3">
</div>
<div id="outline-container-org47992c6" class="outline-4">
<h4 id="org47992c6">Voglio costruirmi il grafo della connettività, con i costi di ogni arco, dopo aver scambiato abbastanza informazioni fra nodi.</h4>
</div>
<div id="outline-container-org00d24d9" class="outline-4">
<h4 id="org00d24d9">Ogni nodo manda la distanza sui suoi link a TUTTI gli altri nodi, quindi esistono N(N-1) messaggi di controllo</h4>
<div class="outline-text-4" id="text-org00d24d9">
</div>
<ul class="org-ul">
<li><a id="org62d2487"></a>Questa strategia si chiama FLOODING.<br />
<ul class="org-ul">
<li><a id="org2513b82"></a>Ogni link state viene mandato su tutte le porte IO diverse da quella di arrivo.<br /></li>
</ul>
</li>
<li><a id="orgb686f93"></a>Il link state di uno specifico nodo continuerebbe a girare all'infinito. Allora viene introdotto un buffer che tiene l'ultimo state link e informazioni aggiuntive tipo header, contenenti l'indirizzo del mittente, un numero di sequenza associato allo specifico mittente, un TTL, ovvero un numero massimo di hops che possono essere effettuati e alla fine l'informazione vera e propria<br />
<ul class="org-ul">
<li><a id="orgce69f40"></a>Ogni LS inviato nel flooding prevede anche un ACK<br />
<ul class="org-ul">
<li><a id="orgdd911be"></a>Questo comporta che nella rete sia occupata da tanto traffico di controllo di livello 2<br /></li>
</ul>
</li>
<li><a id="org59b5af2"></a>Per calcolare le distanze, si usa ICMP con il ping, calcolando la distanza con un cronometro fra l'invio ed il ritorno di un pacchetto.<br /></li>
</ul>
</li>
<li><a id="orgb54fcef"></a>Le cose positive del link state sono che si conosce la topologia della rete nella sua interezza, così che attraverso Dijkstra si stabiliscano tutti i cammini minimi.<br /></li>
<li><a id="org2f8763a"></a>L'implementazione dei LinkState viene effettuata da OSPF, ovvero open shortest path first.<br />
<ul class="org-ul">
<li><a id="org3d37b34"></a>Il problema è che questo calcolo andrebbe fatto da ogni nodo nella rete, con un certo carico computazionale.<br /></li>
<li><a id="org3ad704b"></a>La routing table conterrà la destinazione da raggiungere, il link attraverso cui si raggiunge e il costo, costruito tramite Dijkstra.<br /></li>
<li><a id="orgb3d40a2"></a>Questo protocollo è MULTIPATH, ovvero salva i casi in cui due path diverse abbiano lo stesso peso, in modo da fare load balancing.<br /></li>
<li><a id="org3229627"></a>Addirittura posso obbligare un pacchetto a passare attraverso uno specifico nodo, imbullonandolo nello header.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-orgb8fd215" class="outline-4">
<h4 id="orgb8fd215">Adesso immaginiamo di avere una topologia di nodi con due nodi, R1 ed R3, connessi ad una rete (ad esempio lan, ma qualunque) con netID rispettivamente 1 e 3, che contengono al loro interno uno degli host H1 e H3.</h4>
<div class="outline-text-4" id="text-orgb8fd215">
</div>
<ul class="org-ul">
<li><a id="orgae5799e"></a>Ogni nodo contiene anche una tabella di adiacenze, in cui ad ogni nodo è associato il link che serve per raggiungerlo<br /></li>
<li><a id="org436c465"></a>Queste reti si chiamano stub, ovvero reti foglia, e contengono una tabella a loro volta, in cui è salvata la coppia netID-nodo a cui è collegata.<br />
<ul class="org-ul">
<li><a id="orga7092cc"></a><span class="todo TODO">TODO</span> Capire chi salva quali tabelle e in particolare chi tiene la netId table<br /></li>
<li><a id="orgde00a4f"></a>Ad esempio, nella rete con netId 1 c'è scritto che la 1 è raggiungibile direttamente e la 3 attraverso il nodo R3.<br /></li>
<li><a id="orgeeb48da"></a>Quando H1 manda un pacchetto a H3, traduce H3 in R3. Il router R1 manda verso R1 mandando sul router successivo secondo la sua routing table, in particolare sul link associato a quel router.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-org8131ac2" class="outline-4">
<h4 id="org8131ac2">OSPF ruota sicuramente sulla area 0, ovvero il backbone dello Autonomous System. All'area 0 sono collegate sotto-aree che per comunicare da loro devono necessariamente passare attraverso l'area 0. L'area 0 contiene dei border-router attraverso cui passa TUTTO il traffico, intra area ed extra area.</h4>
</div>
<div id="outline-container-org6f08b51" class="outline-4">
<h4 id="org6f08b51">Per mettere in comunicazione AS diversi, serve avere dei link che li collegano e i router fra essi utilizzano un altro protocollo, BGP.</h4>
</div>
</div>
<div id="outline-container-org3e58627" class="outline-3">
<h3 id="org3e58627">Per migliorare la efficienza e generare le tabelle di routing vengono messe in atto delle tecniche avanzate, fra cui centralizzare il calcolo dei cammini minimi. Un router specifico, chiamato Designated Router, che calcola i cammini minimi per tutte i nodi e gli rimanda le tabelle già calcolate.</h3>
<div class="outline-text-3" id="text-org3e58627">
</div>
<div id="outline-container-org60d766f" class="outline-4">
<h4 id="org60d766f">Si riduce un po' il traffico, ma si ha lo svantaggio di congestionare i link verso lo stesso, su cui convergono le comunicazioni.</h4>
</div>
<div id="outline-container-org666388c" class="outline-4">
<h4 id="org666388c">Ormai tutte le reti lo usano.</h4>
</div>
<div id="outline-container-org24a0f73" class="outline-4">
<h4 id="org24a0f73">Lo spunto di eleggere un designated router è stato preso tanto bene che invece di eleggere uno dei router, si è deciso di portarlo in cloud, inventando il Software Designed Network SDN.</h4>
<div class="outline-text-4" id="text-org24a0f73">
</div>
<ul class="org-ul">
<li><a id="org52c3684"></a>Nella gran parte dei casi quel router si trova su cloud.<br /></li>
<li><a id="org60621d3"></a>Tutto ciò è possibile perchè noi fin dall'inizio abbiamo stabilito che il piano di controllo, routing, è separato dal piano di dati, forwarding.<br /></li>
<li><a id="orge8e6619"></a>Esiste un protocollo, Open Flow, che regola le comunicazioni con il Designated Router, anche cercando di risolvere problemi di sicurezza.<br /></li>
<li><a id="orgaaf4d60"></a>A questo punto il flooding non esiste più, ma avviene una comunicazione punto punto con l'SDN o Designated Router.<br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org61b258a" class="outline-2">
<h2 id="org61b258a">Supponiamo di avere due macchina che ha uno strato applicativo, seguito da TCP, IP ecc&#x2026;, attaccata ad una rete IP.</h2>
<div class="outline-text-2" id="text-org61b258a">
</div>
<div id="outline-container-org04fc82a" class="outline-3">
<h3 id="org04fc82a">Ora immaginiamo che una macchina in mezzo a queste macchine ci sia una rete non IP.</h3>
</div>
<div id="outline-container-org187735f" class="outline-3">
<h3 id="org187735f">La macchina centrale deve avere IP per riuscire a prendere i pacchetti e poi l'altro network per processarli correttamente. Poi andranno reinviati in IP</h3>
</div>
<div id="outline-container-org52f3f9c" class="outline-3">
<h3 id="org52f3f9c">Il TUNNELLING è il modo di gestire lo header durante il passaggio in quella macchina</h3>
</div>
<div id="outline-container-org5c344b4" class="outline-3">
<h3 id="org5c344b4">La soluzione banale è che l'intero pacchetto, compreso header, viene incapsulato e lo header dell'altro protocollo viene semplicemente aggiunto, per poi essere rimosso dopo</h3>
</div>
</div>
<div id="outline-container-orge6504bb" class="outline-2">
<h2 id="orge6504bb">TRANSPORT LAYER NUOVE LEZIONI</h2>
</div>
<div id="outline-container-org8d7cb01" class="outline-2">
<h2 id="org8d7cb01">Transport layer è il primo livello ad essere end-to-end, ovvero che comunica fra due macchine ed astrae ai livelli superiori la rete sottostante (la nasconde).</h2>
<div class="outline-text-2" id="text-org8d7cb01">
</div>
<div id="outline-container-org673fe20" class="outline-3">
<h3 id="org673fe20">Offre dei servizi che abbiamo già visto nel data-link.</h3>
</div>
<div id="outline-container-orgcf600e8" class="outline-3">
<h3 id="orgcf600e8">Varie funzionalità possono essere attivate o disattivate.</h3>
</div>
<div id="outline-container-orgb0d486e" class="outline-3">
<h3 id="orgb0d486e">TCP e UDP sono ortogonali fra loro. La prima offre disponibilità, mentre la seconda è best-effort e non aggiunge nulla ai livelli superiori.</h3>
</div>
<div id="outline-container-orgc1e4ed4" class="outline-3">
<h3 id="orgc1e4ed4">A livello data-link, tra due porte di rete abbiamo una trasmissione può essere affidabile, avere controllo degli errori ecc.</h3>
<div class="outline-text-3" id="text-orgc1e4ed4">
</div>
<div id="outline-container-org843e1e9" class="outline-4">
<h4 id="org843e1e9">Quello che non è considerato a livello data-link è se qualcosa va perso a livello network.</h4>
<div class="outline-text-4" id="text-org843e1e9">
</div>
<ul class="org-ul">
<li><a id="org5d451ca"></a>Un esempio è che abbiamo il nostro host con il suo livello IP.<br />
<ul class="org-ul">
<li><a id="orgb57fa8f"></a>Poi abbiamo tutti questi router intermedi con i loro livelli IP e un protocollo che li leghi (non ci interessa quale).<br /></li>
<li><a id="org5bd2100"></a>In ogni nodo ci sono delle code di ricezione \(RX\) e di trasmissione \(RT\) che hanno una capacità limitata.<br /></li>
<li><a id="org637c8d4"></a>Nonostante possiamo dare affidabilità al data-link, a questo livello IP, se il RT è in overflow, scarta un pacchetto e questo viene perso del tutto.<br />
<ul class="org-ul">
<li><a id="org2613df1"></a>Nonostante ci sia una somma di link affidabili, questa non garantisca che tutta la comunicazione end-to-end sia affidabile.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgfc4bf2e" class="outline-3">
<h3 id="orgfc4bf2e">In Transport viene riimplementata l'affidabilità in modo che quando un segmento venga perso, venga gestita la ritrasmissione.</h3>
<div class="outline-text-3" id="text-orgfc4bf2e">
</div>
<div id="outline-container-org1785644" class="outline-4">
<h4 id="org1785644">La trasmissione su cavo è molto affidabile e quindi l'affidabilità a livello data link è passata in secondo piano e diventa più importante quella su tratte più lunghe, con tutta la rete in mezzo, che coinvolgono i router di livello 3.</h4>
</div>
</div>
<div id="outline-container-org3ff757c" class="outline-3">
<h3 id="org3ff757c">Le unità base di comunicazione a livello 4 sono chiamate <b>messaggi</b> o <b>segmenti</b>.</h3>
</div>
<div id="outline-container-orga1e150e" class="outline-3">
<h3 id="orga1e150e">Il livello di trasporto ha anche un suo indirizzamento (naming) utilizzando le porte, che servono per identificare l'applicazione che sta utilizzando il collegamento di livello 4.</h3>
<div class="outline-text-3" id="text-orga1e150e">
</div>
<div id="outline-container-org3316c32" class="outline-4">
<h4 id="org3316c32">Mentre l'indirizzo IP serve per identificare l'host di rete</h4>
</div>
<div id="outline-container-org4b5328b" class="outline-4">
<h4 id="org4b5328b">Immaginiamo di avere un client ed un server con TCP o UDP a livello 4, IP sotto e poi una rete completamente trasparente.</h4>
<div class="outline-text-4" id="text-org4b5328b">
</div>
<ul class="org-ul">
<li><a id="org34ba9c5"></a>Abbiamo poi delle applicazioni che comunicano, ad esempio app client e web server con db.<br /></li>
<li><a id="org02b0203"></a>Immaginiamo arrivi un pacchetto IP a livello server.<br />
<ul class="org-ul">
<li><a id="orgc4fd6f1"></a>Il server legge il suo header e con il suo destination address sa che è destinato a lui.<br /></li>
<li><a id="org9de0a64"></a>Nello campo "protocol" ci sarà scritto se il pacchetto è da mandare ad IP o UDP.<br /></li>
<li><a id="org552cb0a"></a>Le applicazioni ascoltano su una specifica porta (80 per http ecc.)<br /></li>
<li><a id="orgc63f64a"></a>TCP si chiede: a quale di queste operazioni appartiene questo segmento? in modo da smistarlo correttamente.<br />
<ul class="org-ul">
<li><a id="org1cae5e6"></a>Quindi l'IP address identifica tutto l'host, il PROTOCOL indica il protocollo di transport e la porta(?) indica l'applicazione specifica che usa i dati.<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="org62bd0f8"></a>Anche dal lato client, si parte dall'Application layer e si sceglie il corretto protocollo (TCP/UDP) da utilizzare.<br />
<ul class="org-ul">
<li><a id="org641514f"></a>Quindi l'IP e il protocollo da utilizzare sono informazioni necessarie per aprire la comunicazione.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-orgee3f750" class="outline-4">
<h4 id="orgee3f750">A livello di Trasporto si usano le socket.</h4>
<div class="outline-text-4" id="text-orgee3f750">
</div>
<ul class="org-ul">
<li><a id="org243e1e1"></a>Una socket è fatta così (stessa dell'immagine sul libro):<br />
<ul class="org-ul">
<li><a id="org18aa68d"></a>Abbiamo un ClientAP e un ServerAP (access point), che noi richiediamo semplicemente e sono offerte dal sistema operativo.<br /></li>
<li><a id="orgafbf90d"></a>Fra i due AP abbiamo una transport entity<br /></li>
<li><a id="org44e582a"></a>Ogni applicazione contiene due buffer che sono RecevingBuffer e SendingBuffer.<br /></li>
<li><a id="orgcfeea9f"></a>Le socket berkeley sono lo standard de facto, di Unix, che non è altro che un descrittore di file su cui si può effettuare scrittura e lettura.<br />
<ul class="org-ul">
<li><a id="orgdfe56b9"></a>Una write scrive sull'SB e la read sull'RB<br /></li>
</ul>
</li>
<li><a id="org692d2fd"></a>Poi abbiamo un istanza del protocollo TCP che se vede che va tutto bene (poi vedremo cosa vuol dire), prende carico dei dati e li trasmette in rete.<br /></li>
<li><a id="orgc59cef1"></a>C'è poi un altro livello di buffer, uno per ingresso e uno per uscita, aree di memoria temporanee che TCP riserva per tenere temporaneamente i pezzi di unità di informazione che devono essere ancora trasmessi.<br />
<ul class="org-ul">
<li><a id="org0ed97de"></a>TCP lavora a stream di byte e c'è un ordinamento assoluto di essi e va garantito che il ricevitore le riceva nello stesso ordine.<br /></li>
<li><a id="org0f19573"></a>Immaginiamo ad esempio di inviare 1, 2 e 3 e che 2 venga perso.<br /></li>
<li><a id="org270d3f6"></a>Dopo aver ricevuto il 3, il TCP lato client si rende conto che manca qualcosa.<br /></li>
<li><a id="org85fb560"></a>Il blocchetto 3 rimane temporaneamente in buffer e quando il blocchetto 2 arriva a destinazione, verrà sbloccato anche il successivo.<br /></li>
<li><a id="orgcee4ad9"></a>Il buffer tcp d'uscita serve invece per tenere gli stream da mandare fino alla ricezione di un ACK.<br /></li>
</ul>
</li>
<li><a id="orga59baaa"></a>Adesso, la velocità di lettura e scrittura sono diverse fra loro, diventa necessario mettere un buffer al centro.<br />
<ul class="org-ul">
<li><a id="org6f196a5"></a>Se una macchina genera in modo troppo veloce e l'altra troppo lenta, chiederà di rallentare la trasmissione.<br /></li>
<li><a id="orgb0a291d"></a>Siamo a livello kernel e non abbiamo tanta memoria.<br />
<ul class="org-ul">
<li><a id="orga9f07af"></a>Se non mettessimo un limite alla memoria, i buffer si saturerebbero e non rispetteremmo le specifiche di TCP che ci offre la totale affidabilità nella trasmissione.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a id="org94ca9da"></a>Con le socket si interagisce in questo modo, ovvero le API da utilizzare sono:<br />
<ul class="org-ul">
<li><a id="orgf279639"></a>Abbiamo ancora i due access point client e server che si interfacciano con il TCP/UDP.<br />
<ul class="org-ul">
<li><a id="org721f420"></a>Il livello 7 (application) è implementato nello user space.<br /></li>
<li><a id="org024f6eb"></a>Il livello 4 è implementato nel kernel, quindi nel sistema operativo.<br /></li>
<li><a id="org8cd5cb3"></a>Il livello 3 anche<br /></li>
<li><a id="orgfc64562"></a>Il livello 2 sulla scheda di rete, quindi a livello firmware<br /></li>
<li><a id="org9868db9"></a>Il livello 1 è il cavo.<br /></li>
</ul>
</li>
<li><a id="orgcb2a3b8"></a>Nel server, ci sono:<br />
<ul class="org-ul">
<li><a id="orgba6e0a6"></a>Una prima chiamata, bidirezionale, è <code>socket()</code>. Questa restituisce un descrittore di file aperto e bidirezionale, ovvero su cui si può leggere e scrivere.<br /></li>
<li><a id="orge5169a5"></a>Poi c'è l'operazione di <code>bind()</code> a cui passiamo un indirizzo IP e una porta, che lega la socket a un indirizzo IP (0.0.0.0 se ascolti su tutti gli IP della macchina). O conosciamo l'IP o utilizziamo un indirizzo DNS e la porta o la sappiamo già o è una porta well-known, come 80 o 8080 per HTTP, 443 e 8443 per HTTPS, ssh sulla 22, DNS sulla 53UDP.<br /></li>
<li><a id="orgafaa47e"></a>Poi abbiamo <code>listen()</code> che dice alla socket di mettersi in ascolto sull'indirizzo indicato al <code>bind()</code>. Crea inoltre una coda di richieste.<br />
<ul class="org-ul">
<li><a id="org90b57a7"></a>Anche qua, questa coda è finita e se arriva un bombardamento di richieste ovviamente il buffer si riempie e le successive richieste non saranno più gestite.<br /></li>
</ul>
</li>
<li><a id="orga5c720b"></a>L'ultima chiamata è la <code>accept()</code>. Questa si blocca in attesa di una richiesta. Quindi è una richiesta bloccante. Aspetta che qualcuno arrivi per aprire una connessione.<br /></li>
<li><a id="org7345301"></a>A questo punto, TCP non è ancora intervenuto ma ha stabilito tutte le parti necessarie per ottenere una comunicazione<br /></li>
</ul>
</li>
<li><a id="orgbdcb1d5"></a>Nel client ci sono:<br />
<ul class="org-ul">
<li><a id="orgb6fabc7"></a><code>socket</code> come prima<br /></li>
<li><a id="orgcbcc3d1"></a><code>connect()</code>, bloccante, in cui, come nella <code>bind()</code> specifichiamo un IP e una porta per recapitare correttamente un messaggio.<br />
<ul class="org-ul">
<li><a id="org6d60f99"></a>Questa connect scatena un'apertura di connessione, (o il recapito di un messaggio in UDP), che sblocca il server attraverso la unlock, fa una <code>fork</code> che da luogo ad una nuova <code>socket()</code>, che effettuerà una nuova <code>bind()</code>.<br /></li>
<li><a id="orgf79b75a"></a>Solo a questo punto viene tirata su la struttura del TCP con i 4 buffer.<br /></li>
<li><a id="orgfb707a7"></a>Quando viene effettuata la prima chiamata <code>socket</code> nel server, viene creata solo la coda di richieste.<br /></li>
<li><a id="org96bb201"></a>Solo la seconda chiamata tira su tutto il sistema TCP indicato prima<br /></li>
<li><a id="orgdfb3fd4"></a>La porta della sorgente è scelta randomicamente.<br /></li>
</ul>
</li>
<li><a id="org382ae99"></a>Alla ricezione dell'ok della socket pronta dall'altra parte, si sblocca anche il client e da lì in poi la comunicazione è aperta e si possono utilizzare le system call tipiche dei file, ovvero <code>send()</code> e <code>receive()</code><br /></li>
</ul>
</li>
<li><a id="orgd20684a"></a>Quando voglio chiudere, una delle due chiama una <code>close()</code><br />
<ul class="org-ul">
<li><a id="orgd098b9b"></a>Questa chiusura coinvolge anche l'entità TCP, ma finora abbiamo soltanto osservato TCP dall'esterno.<br /></li>
</ul>
</li>
<li><a id="org18cbc45"></a>Con la quintupla [protocol, ipsrc, ipdst, portsrc, portdst] posso identificare la singola comunicazione che è stata tirata su dopo la serie di procedure appena indicata.<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-orgda566c2" class="outline-4">
<h4 id="orgda566c2">Il TCP garantisce che la comunicazione sia <b>affidabile</b> e <b>ordinata</b>.</h4>
<div class="outline-text-4" id="text-orgda566c2">
</div>
<ul class="org-ul">
<li><a id="org7b5e0d7"></a>Opera inoltre un controllo di flusso, ovvero un controllo orizzontale, con un app sorgente che scrive e una dest che legge, entrambe ad un certo rate, in modo che non ci sia overflow.<br />
<ul class="org-ul">
<li><a id="org5860c9f"></a>Questo avviene basandosi sul rate minore.<br /></li>
</ul>
</li>
<li><a id="org50be9c2"></a>Opera poi un controllo errori.<br />
<ul class="org-ul">
<li><a id="org8d8d649"></a>Mentre UDP avverte in caso di errori, TCP si occupa anche di risolverli, gestendo la ritrasmissione.<br /></li>
</ul>
</li>
<li><a id="org97dad25"></a>Opera poi un controllo di congestione, questa volta verticale.<br />
<ul class="org-ul">
<li><a id="org9387240"></a>E' vero che TCP nasconde la rete sottostante, ma sa che c'è una rete e sa che questa è potenzialmente inaffidabile.<br /></li>
<li><a id="orgdd88e1a"></a>Sa che se vengono immessi troppi pacchetti su una rete, questa possa essere congestionata.<br /></li>
<li><a id="org823693e"></a>TCP prova ad intuire la congestione della rete e prevenire la perdita di pacchetti della rete, diminuendo il rate di trasmissione di questi ultimi.<br /></li>
</ul>
</li>
<li><a id="orgee82799"></a>Inoltre, è orientata allo stream.<br />
<ul class="org-ul">
<li><a id="org7a5de0a"></a>Il concetto su cui lavora è dello stream di byte, che devono arrivare tutti.<br /></li>
</ul>
</li>
<li><a id="orgd50c75a"></a>Poi, è orientato alla connessione.<br />
<ul class="org-ul">
<li><a id="orge2eff4d"></a>Prima di utilizzare le socket, leggervi e scrivervi, dobbiamo instaurare una connessione, aprendola, che mantiene un certo stato.<br />
<ul class="org-ul">
<li><a id="org27c3bd6"></a>Il drawback è che è necessario tenere lo stato e tutte le info per la connessione in memoria nel kernel, e dev'essere occupato durante tutta la comunicazione.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-orge947154" class="outline-4">
<h4 id="orge947154">Lo header TCP è rappresentato in pagine larghe 32 bit.</h4>
<div class="outline-text-4" id="text-orge947154">
</div>
<ul class="org-ul">
<li><a id="org76bf5cb"></a>Alla prima riga abbiamo 16 bit per porta sorgente e 16 per la destinazione<br /></li>
<li><a id="orgf0afb24"></a>Alla seconda riga abbiamo i 32 bit per il numero di sequenza<br />
<ul class="org-ul">
<li><a id="org747c794"></a>Il numero di sequenza indica il primo byte della lunghezza variabile di byte che compone il segmento.<br /></li>
<li><a id="orged02b86"></a>Viene inizializzato al momento dell'istanziamento della connessione.<br /></li>
</ul>
</li>
<li><a id="org08c1cc6"></a>Poi abbiamo il campo ACK number, strettamente legato al precedente.<br />
<ul class="org-ul">
<li><a id="orgee4819f"></a>Identifica il numero di byte che la destinazione di questa connessione ha correttamente ricevuto e qual è l'indice del prossimo byte che mi aspetto.<br /></li>
<li><a id="org49a31ff"></a>I due campi superiori vengono utilizzati per gestire i casi in cui ci sia una perdita di segmenti e gestire correttamente la trasmissione.<br /></li>
</ul>
</li>
<li><a id="org0ef0379"></a>Nella terza pagina abbiamo:<br />
<ul class="org-ul">
<li><a id="org9520cf5"></a>Poi c'è il campo TCP Header Length da 4 bit<br />
<ul class="org-ul">
<li><a id="org5ebff1f"></a>La dimensione dell'header è variabile, sebbene esista una lunghezza solitamente usata.<br /></li>
</ul>
</li>
<li><a id="org76b9fb9"></a>Poi 4 bit non utilizzati<br /></li>
<li><a id="org6433595"></a>Poi c'è una serie di 8 bit di controllo<br />
<ul class="org-ul">
<li><a id="org2c0a26e"></a>Prima il CWR, Congestion Window Reduced, che serve alla rete congestionata per notificare la situazione<br /></li>
<li><a id="org79c3be1"></a>Poi lo ECE, &#x2026;. echo.<br />
<ul class="org-ul">
<li><a id="org326c0c9"></a>Solo i due superiori sono presenti sul Tanenbaum ma non sull'Halsall<br /></li>
</ul>
</li>
<li><a id="org9c95613"></a>Poi c'è un bit URGent, per indicare che certi dati sono urgenti e devono essere processati ASAP, superando l'ordinamento solito.<br /></li>
<li><a id="orgaf72fbe"></a>Poi c'è il campo ACK<br /></li>
<li><a id="orge07d802"></a>Poi PUSH, che serve per mandaare via i dati contenuti nel buffer della socket.<br />
<ul class="org-ul">
<li><a id="org411c30e"></a>Ad esempio, immaginiamo che stiamo mandando dei dati e scrivendo nel SendingBuffer.<br /></li>
<li><a id="orgc65a1c2"></a>Il TCP riempie un segmento di una certa dimensione e poi lo manda quando ha una certa dimensione.<br /></li>
<li><a id="orgbc842b6"></a>In alcuni casi, può essere necessario che tutti i dati vengano salvati immediatamente<br /></li>
<li><a id="org0f429c1"></a>La differenza con lo urgent è che in questo caso il valore viene mandato da solo ma rispettando l'ordine.<br /></li>
</ul>
</li>
<li><a id="org0411d2b"></a>Poi ci sono RST, SYN e FIN che non ho ascoltato. Reset, sincronizzazione e chiudi connessione.<br /></li>
</ul>
</li>
<li><a id="org9480db1"></a>I restanti 16 bit di Window Size indicano lo spazio ancora disponibile nel ricevitore.<br />
<ul class="org-ul">
<li><a id="org6502ded"></a>Chi sta trasmettendo, leggendo questo campo può capire se l'altra macchina sostiene il rate o deve rallentare.<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="org10d8efa"></a>Nella quarta pagina:<br />
<ul class="org-ul">
<li><a id="org35d352b"></a>Un checksum a 16 bit, che poi vedremo come viene calcolato, che ci permette di capire se tutto è corretto e viene collegato sulla base dello pseudoheader e tiene anche conto della conformità del payload (controllo degli errori)<br />
<ul class="org-ul">
<li><a id="orgf49d5cd"></a>Lo pseudoheader è una versione ridotta dello header.<br /></li>
</ul>
</li>
<li><a id="orgdae663c"></a>Poi uno Urgent Pointer, che viene letto se e solo se il frame urgent è a 1, altrimenti non ce ne frega perchè viene trascurato.<br />
<ul class="org-ul">
<li><a id="org23a50bf"></a>Indica l'offset all'interno del campo data oltre il quale i dati sono urgent.<br /></li>
<li><a id="org770fe13"></a>Per convenzione, i dati urgent vengono messi alla fine del segmento e quindi non spazio per la fine della parte urgente.<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="org52d6922"></a>Dopodichè abbiamo le options, parole di 16 bit di cui può esserci un numero variabile.<br /></li>
<li><a id="org9caf375"></a>Dopo le n options, c'è il payload.<br /></li>
</ul>
</div>
<div id="outline-container-orgcdcabee" class="outline-4">
<h4 id="orgcdcabee">Come si diceva, TCP è orientato alla connessione.</h4>
<div class="outline-text-4" id="text-orgcdcabee">
</div>
<ul class="org-ul">
<li><a id="orgd47deb9"></a>La connessione è bidirezionale, ma noi analizzeremo solo un lato della connessione, perchè analizzare entrambe sarebbe molto confuso.<br />
<ul class="org-ul">
<li><a id="orgde663ed"></a>Ognuno trasmette e riceve in modo di indipendente. Quindi la sequence e lo ACK sono relativi solo ad una direzione della connessione.<br /></li>
</ul>
</li>
<li><a id="org7e5328b"></a>All'apertura della connessione, da entrambe le macchine viene generato un sequence number ISN casuale, per ragioni di sicurezza<br />
<ul class="org-ul">
<li><a id="orgd1f11fc"></a>Altrimenti si potrebbe indovinare un numero ed inserirsi nella connessione<br /></li>
<li><a id="orgdf4eea3"></a>I due flussi, e quindi i due numeri di sequenza, sono indipendenti.<br /></li>
</ul>
</li>
<li><a id="org25d5c9b"></a>A chiede di aprire una connessione e manda un segmento con il frame SYN = 1 e il Seq = X (quello generato casualmente da A).<br /></li>
<li><a id="org188a1ca"></a>B riceve il segmento e ne manda uno di risposta in cui SYN = 1, ACK = 1, Seq = Y (quello generato casualmente da B) e Ack = x + 1.<br />
<ul class="org-ul">
<li><a id="org6da68f9"></a>Il bit di ACK attivato indica che il valore in Ack è significativo è può essere letto.<br /></li>
<li><a id="orgf4e9bf2"></a>Lo ack a x+1 indica che si è pronti ad andare avanti con la trasmissione. Il primo segmento parte da x ed è lungo 1, quindi il prossimo che sono pronto ad ascoltare è il successivo.<br /></li>
</ul>
</li>
<li><a id="org7cd6b7d"></a>A riceve il segmento e risponde con ACK=1 e Ack = y+1<br /></li>
<li><a id="orgebe0dde"></a>In tutti i 3 segmenti superiori, il valore del resto dello header e payload non importano.<br /></li>
<li><a id="org05282f0"></a>La procedura prende il nome di three-way handshake.<br /></li>
<li><a id="orgb85415a"></a>Gestione casi delicati<br />
<ul class="org-ul">
<li><a id="orgffdc987"></a>Viene introdotto un Timer, RTO, che gestisce il caso in cui uno fra i primi due segmenti di handshake vengano persi.<br />
<ul class="org-ul">
<li><a id="org630fbf2"></a>Come nel data link, se il timer scade perchè uno qualunque dei primi frame è scomparso, si prova ad aprire nuovamente la connessione.<br /></li>
</ul>
</li>
<li><a id="orga65ec54"></a>Il timer gestisce anche i casi in cui l'handshake di risposta ci impieghi troppo ad arrivare ( o si può dire che dopo il tempo \(T\) si assuma che la connessione è persa e bisogna gestire il caso in cui la risposta invece arrivi)<br />
<ul class="org-ul">
<li><a id="org520315e"></a>Ogni nuova riapertura aggiorna il SEQ casuale<br /></li>
<li><a id="orgf4f0f08"></a>Se arriva una risposta per un apertura precedente, è facile dal numero di sequenza capire che non sia la risposta corretta<br /></li>
<li><a id="orgcd8fe18"></a>In tal caso, si manda un messaggio con RST e si chiude la connessione.<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="orgc6dcbbf"></a>Utilizzando lo stesso concetto di base del port scanning, si può fare SYN FLOOD.<br />
<ul class="org-ul">
<li><a id="org0ae9f3e"></a>Mando tanti messaggi di SYN sulle varie porte.<br /></li>
<li><a id="orge3e9c05"></a>Il server mi risponde genuinamente e attende per la mia 3 risposta, finale, di handshake.<br /></li>
<li><a id="org13ee720"></a>Io non rispondo e il server deve allocare risorse per tanti syn aperti contemporaneamente.<br /></li>
<li><a id="org619af67"></a>Se invece rispondo con un RST, non effettuo un attacco e non peso sulle risorse, ma analizzo soltanto le porte aperte.<br />
<div class="outline-text-6" id="text-org619af67">
<p>
lesgoski
</p>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org789ff9e" class="outline-2">
<h2 id="org789ff9e">Quindi siamo arrivati al SYN che uno manda per aprire la connessione, con un numero di sequenza generato in numero casuale. Il canale è bidirezionale e quindi avviene tutto nello stesso modo in entrambi gli host.</h2>
<div class="outline-text-2" id="text-org789ff9e">
</div>
<div id="outline-container-org5ac5acf" class="outline-3">
<h3 id="org5ac5acf">Il SYN parte a 1, in risposta il SYN è a uno e anche l'ACK, che indica che il campo Ack è significativo e tale campo è numDiSequenza +1, per indicare che quello è il prossimo bit che si è pronti a ricevere.</h3>
<div class="outline-text-3" id="text-org5ac5acf">
</div>
<div id="outline-container-org1725f4a" class="outline-4">
<h4 id="org1725f4a">Ovviamente manda anche il proprio numero di sequenza.</h4>
</div>
</div>
<div id="outline-container-orgc2b1f8f" class="outline-3">
<h3 id="orgc2b1f8f">Se tutto va a buon fine, la terza risposta dal sender è uguale alla seconda dal receiver e da lì in poi la connessione è aperta.</h3>
</div>
<div id="outline-container-orgdda5b9e" class="outline-3">
<h3 id="orgdda5b9e">C'è un timer che garantisce che se l'ACK viene perso, o impiega troppo tempo ad arrivare, venga mandato un messaggio con RESET a 1 che annulla l'handshake, che va rieffettuato</h3>
<div class="outline-text-3" id="text-orgdda5b9e">
<pre class="example" id="orgf237db3">
Let me explain why starting sequence numbers in the Transport layer are random:

    Security: Random initial sequence numbers help prevent TCP sequence prediction attacks. If sequence numbers were predictable, attackers could potentially hijack TCP connections by guessing the next sequence number.

    Connection Uniqueness: Random sequence numbers reduce the likelihood of old segments from previous connections being mistakenly accepted as valid in new connections between the same endpoints.

    Prevents Segment Mix-up: If multiple connections are established between the same hosts, random sequence numbers help ensure segments from different connections don't get mixed up.

    Protection against Spoofing: Random initial sequence numbers make it harder for attackers to inject fake segments into an existing connection since they would need to guess the correct sequence number.

    Avoids Overlap: In case of delayed segments from previous connections, random sequence numbers help prevent confusion between old and new data streams.

This randomization is a crucial security measure in modern TCP implementations and helps maintain the integrity and reliability of network communications.
</pre>
</div>
</div>
<div id="outline-container-orgbf4586b" class="outline-3">
<h3 id="orgbf4586b">In ogni header è indicato il Max Segment Size, che indica la dimensione massima di segmento che l'host può gestire senza andare in overflow.</h3>
<div class="outline-text-3" id="text-orgbf4586b">
</div>
<div id="outline-container-orgd78dc40" class="outline-4">
<h4 id="orgd78dc40">La dimensione Standard, quando il campo è vuoto, il segmento è di 536 byte.</h4>
</div>
</div>
<div id="outline-container-orgb287bbb" class="outline-3">
<h3 id="orgb287bbb">L'obiettivo di TCP è trasferire i dati nel miglior modo, garantendo affidabilità, gest.errori, ordine ecc., e anche farlo in modo efficiente, evitando un overhead eccessivo</h3>
</div>
<div id="outline-container-orgd8f2ed5" class="outline-3">
<h3 id="orgd8f2ed5">Il motivo per cui viene scelta 536 byte è che siamo sicuri che il livello IP non frammenterà tale segmento in più pacchetti.</h3>
<div class="outline-text-3" id="text-orgd8f2ed5">
</div>
<div id="outline-container-org942fbbe" class="outline-4">
<h4 id="org942fbbe">Per ogni frammentazione effettuata dall'IP, serve copiare sia header TCP che IP, introducendo overhead.</h4>
</div>
<div id="outline-container-orgef443cc" class="outline-4">
<h4 id="orgef443cc">Inoltre, essendo la rete best-effort, quanti più sotto-segmenti vengono mandati quanto più è probabile che avvengano dei problemi che dovranno essere poi gestiti</h4>
</div>
</div>
<div id="outline-container-org97fa749" class="outline-3">
<h3 id="org97fa749">Immaginiamo di avere una connessione A-B in TCP, necessariamente bidirezionale.</h3>
<div class="outline-text-3" id="text-org97fa749">
</div>
<div id="outline-container-orge644438" class="outline-4">
<h4 id="orge644438">Dato che noi analizziamo solo i casi "unidirezionali", noi valutiamo solo SendingBuffer e TcpSendingBuffer nel sender, e i corrispondenti ma per il receiver nel receiver.</h4>
</div>
<div id="outline-container-org3eefcf8" class="outline-4">
<h4 id="org3eefcf8">Assumiamo che la segment size sia 500.</h4>
</div>
<div id="outline-container-org2b1cccc" class="outline-4">
<h4 id="org2b1cccc">L'applicazione lato sender scrive 2000 byte nell'SB della socket esposto.</h4>
</div>
<div id="outline-container-org508f3e4" class="outline-4">
<h4 id="org508f3e4">Ovviamente, va eseguita una frammentazione a livello trasporto.</h4>
<div class="outline-text-4" id="text-org508f3e4">
</div>
<ul class="org-ul">
<li><a id="org563bb06"></a>Assumiamo per ora che non avvengano problemi nella trasmissione.<br /></li>
</ul>
</div>
<div id="outline-container-org02f0f24" class="outline-4">
<h4 id="org02f0f24">Nel sending buffer della TCP, nascosto al livello applicazione, vengono copiati e segmentati opportunamente i byte del buffer superiore.</h4>
</div>
<div id="outline-container-orgb707ed8" class="outline-4">
<h4 id="orgb707ed8">Nello header è presente l'informazione SEQ=X. Il payload sarà dal byte X a quello X + 499</h4>
<div class="outline-text-4" id="text-orgb707ed8">
</div>
<ul class="org-ul">
<li><a id="org27e890b"></a>X è in realtà X+1 se la connessione è appena stata instaurata, ma per semplicità si considera X il valore corrente.<br /></li>
</ul>
</div>
<div id="outline-container-orgb281d46" class="outline-4">
<h4 id="orgb281d46">Nel frattempo, il receiver si aspettava il Sequence Number = X e così si accerta che l'ordine sia corretto.</h4>
</div>
<div id="outline-container-org8c02c5d" class="outline-4">
<h4 id="org8c02c5d">I dati arrivano nel buffer inferiore, ma dato che l'ordine è corretto, vengono subito copiati nel buffer superiore.</h4>
</div>
<div id="outline-container-org4574c99" class="outline-4">
<h4 id="org4574c99">Lo header risposta del receiving buffer contiene il campo ACK a 1 e quello Ack a X + 500, che è il primo byte successivo a quello ricevuto.</h4>
<div class="outline-text-4" id="text-org4574c99">
</div>
<ul class="org-ul">
<li><a id="orgc60b1f9"></a>Implicitamente vuol dire che il segmento precedente è correttamente ricevuto.<br /></li>
</ul>
</div>
<div id="outline-container-org50f5227" class="outline-4">
<h4 id="org50f5227">Il sender elimina dal buffer del TCP il segmento corrispondente.</h4>
</div>
<div id="outline-container-org062816f" class="outline-4">
<h4 id="org062816f">Allora, il prossimo segmento mandato è quello che parte da X+500 e questo valore è nel SEQ dello header.</h4>
</div>
<div id="outline-container-org37c127b" class="outline-4">
<h4 id="org37c127b">Anche questo pacchetto è in ordine e quindi va subito spostato nel buffer superiore.</h4>
<div class="outline-text-4" id="text-org37c127b">
</div>
<ul class="org-ul">
<li><a id="org2c05c64"></a>Il TCP tiene tutti i segmenti non in ordine nel buffer inferiore.<br /></li>
<li><a id="orge5c2474"></a>Ogni segmento correttamente ricevuto, ma successivo ad un segmento non ricevuto, rimane nel buffer inferiore.<br /></li>
</ul>
</div>
<div id="outline-container-org29fb1a4" class="outline-4">
<h4 id="org29fb1a4">Analogamente al messaggio precedente, il receiver risponde con un Ack = X+1000.</h4>
<div class="outline-text-4" id="text-org29fb1a4">
</div>
<ul class="org-ul">
<li><a id="org2d47e16"></a>Anche adesso, il sender si libera del segmento.<br /></li>
</ul>
</div>
<div id="outline-container-org8c845de" class="outline-4">
<h4 id="org8c845de">Procedo così fino allo svuotamento del buffer di invio.</h4>
</div>
</div>
<div id="outline-container-org7d8160e" class="outline-3">
<h3 id="org7d8160e">Nella configurazione precedente, c'è un problema nel caso in cui ho bisogno di (real-time?) ad esempio ssh su una console remota.</h3>
<div class="outline-text-3" id="text-org7d8160e">
</div>
<div id="outline-container-org736a6a7" class="outline-4">
<h4 id="org736a6a7">Voglio che i dati vengano processati byte per byte</h4>
</div>
<div id="outline-container-orgd5747e3" class="outline-4">
<h4 id="orgd5747e3">Allora uso la flag PUSH, in modo che TCP spedisca il singolo byte, senza arrivare ad una dimensione del segmento di 500 byte come prima</h4>
</div>
<div id="outline-container-orgb5242e6" class="outline-4">
<h4 id="orgb5242e6">Quando PUSH viene usata, il receiver manda un regolare ACK, con Ack X+1</h4>
</div>
<div id="outline-container-org201f848" class="outline-4">
<h4 id="org201f848">In questo caso, però, viene fatta una eco dello stesso byte, questa volta</h4>
</div>
<div id="outline-container-org57d9e51" class="outline-4">
<h4 id="org57d9e51">Il motivo per cui viene fatta la eco è che il sender prende input a tastiera ma non mostra direttamente a schermo, perchè non è sicuro che dall'altra parte sia correttamente ricevuto. Solo quando si è sicuri che dall'altra parte sia stato ricevuto, viene stampato a tastiera</h4>
<div class="outline-text-4" id="text-org57d9e51">
<pre class="example" id="orga736ee3">
Let me explain why TCP echoes bytes with the PUSH flag:

    Data Acknowledgment vs Echo:

    The ACK simply acknowledges receipt of data
    The echo (sending the same byte back) serves a different purpose: it confirms the connection is still alive and functioning in both directions

    Key Benefits of Echoing:

    Tests bi-directional data flow
    Helps detect half-open connections
    Provides an additional validation mechanism beyond simple acknowledgment
    Useful for interactive applications where immediate response is needed

    Relationship to PUSH Flag:

    The PUSH flag indicates that data should be delivered to the application immediately
    Echoing PUSH-flagged bytes ensures the urgent nature of the data is maintained in both directions
    This is particularly important for interactive protocols like Telnet where character-by-character feedback is needed

The echo mechanism complements ACKs rather than duplicating them - ACKs confirm receipt, while echoes validate the full duplex nature of the connection and maintain interactive responsiveness.
</pre>
</div>
</div>
</div>
<div id="outline-container-org6ac355d" class="outline-3">
<h3 id="org6ac355d">Per garantire&#x2026;(?) viene introdotto il delay acknowledgment.</h3>
<div class="outline-text-3" id="text-org6ac355d">
</div>
<div id="outline-container-orgb2fdadf" class="outline-4">
<h4 id="orgb2fdadf">La questione è che TCP ignora l'obiettivo delle applicazioni, ma loro lo sanno e potrebbero voler inserire più informazioni nello header.</h4>
</div>
<div id="outline-container-org69595ee" class="outline-4">
<h4 id="org69595ee">Immaginiamo una situazione come prima: si riceve un byte pushato.</h4>
</div>
<div id="outline-container-orga9226a7" class="outline-4">
<h4 id="orga9226a7">Il receiver, però, non risponde subito con un Ack, ma aspetta un tempo (standard 200ms).</h4>
</div>
<div id="outline-container-org59ab2ea" class="outline-4">
<h4 id="org59ab2ea">Se in quel tempo arriva qualcosa nel buffer di invio del ricevitore, quei dati vengono incorporati nel messaggio di Ack.</h4>
<div class="outline-text-4" id="text-org59ab2ea">
</div>
<ul class="org-ul">
<li><a id="org33a19d1"></a>In questo caso, sia sequence che ack number sono considerati. Seq è quello che ti do, ack quello che prendo.<br />
<ul class="org-ul">
<li><a id="org24a6506"></a>Prima invece, il campo sequence non era mai impostato<br /></li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-org70d296c" class="outline-4">
<h4 id="org70d296c">In questo caso, quando la eco viene aggiunta nel buffer di invio della ricezione, viene inserita nello stesso frame di Ack. Così ri risparmia un messaggio TCP.</h4>
<div class="outline-text-4" id="text-org70d296c">
<pre class="example" id="org44c9e2d">
Let me explain a common TCP optimization technique from computer networking. This technique is called "Delayed Acknowledgment" or "Delayed ACK."

The Delayed ACK technique involves:

    Deliberately waiting for a short period (typically around 200ms) before sending an ACK
    During this wait period, if the receiving host has data to send back to the sender, it can combine (piggyback) the ACK with this outgoing data
    The wait period also allows the receiver to potentially combine multiple ACKs into a single response if more segments arrive during the delay

This technique helps improve network efficiency by:

    Reducing protocol overhead
    Minimizing the number of small packets on the network
    Taking advantage of bi-directional data flow
    Optimizing bandwidth usage by combining ACKs with data when possible

However, Delayed ACK is not used in all cases - for example, every second full-sized segment must be acknowledged immediately to maintain TCP's flow control mechanisms.
</pre>
</div>
<ul class="org-ul">
<li><a id="org4253012"></a>Il prossimo messaggio del sender sarà sia un ACK della echo che un send del byte successivo.<br /></li>
</ul>
</div>
<div id="outline-container-org6f22efe" class="outline-4">
<h4 id="org6f22efe">Questa soluzione è efficiente dal punto di vista di rete, ma inefficiente dal punto di vista della user-experience.</h4>
<div class="outline-text-4" id="text-org6f22efe">
</div>
<ul class="org-ul">
<li><a id="org04cacab"></a>Per trovare un compromesso fra rete e user-experience, si utilizza la tecnica del <b>NAGLE</b>.<br />
<ul class="org-ul">
<li><a id="org0cfc173"></a>Ho un sender con una serie di segmenti composti da un singolo byte da pushare.<br /></li>
<li><a id="orgf4e9290"></a>Come prima, mando un segmento con il byte, il receiver lo riceve e aspetta 200ms.<br />
<ul class="org-ul">
<li><a id="org59001ca"></a>L'applicazione riceve il byte e fa la ACK + echo, con SEQ = Y, PUSH attivato, ACK attivato e Ack = X + 1<br /></li>
</ul>
</li>
<li><a id="org5285630"></a>I successivi byte vengono impacchettati in un singolo segmento e mandati tutti insieme. Il receiver risponde con l'ack.<br />
<ul class="org-ul">
<li><a id="orgddd97d6"></a><span class="todo TODO">TODO</span> Capire se viene effettuata la echo dei byte in blocco e se viene fatta byte per byte o cumulativa.<br />
<div class="outline-text-7" id="text-orgddd97d6">
<pre class="example" id="orgae038d0">
No, when using Nagle's algorithm, the block of bytes in the second segment is not echoed, and the ACK does not contain an echo of the whole block. Here's why:

    First byte behavior:

    The first byte is sent immediately (Nagle allows this)
    This byte gets acknowledged and echoed (typical for interactive data)

    Block of bytes behavior:

    The subsequent block is sent as a single segment due to Nagle's algorithm
    The receiver only sends an ACK for this data
    The block is NOT echoed back

The reason for this difference is:

    Single byte echoing is typically used for interactive traffic (like telnet) where immediate feedback is needed
    Larger blocks of data don't need character-by-character echo feedback
    Echoing large blocks would be inefficient and isn't necessary for bulk data transfer
    The ACK alone is sufficient to confirm receipt of the block

This behavior helps optimize network performance by:

    Reducing unnecessary network traffic
    Preventing excessive echoing of bulk data
    Maintaining interactivity where needed (single bytes)
    Providing reliable delivery confirmation through ACKs
</pre>

<pre class="example" id="org532071f">
The echo of the first byte in Nagle's algorithm serves these specific purposes:

    Connection Validation:

    The echo of the first byte confirms that the connection is fully functional in both directions
    It quickly verifies that the remote end is responsive and processing data

    Interactive Feedback:

    For interactive applications (like telnet or ssh), the first byte often represents a keystroke
    Users need immediate feedback for this first input to confirm their interaction
    The echo provides visual confirmation that the connection is working

    Fast Start Verification:

    Rather than waiting for the full data transfer to verify connection quality
    The single byte echo serves as a quick initial test of the connection

    Protocol Efficiency:

    Only echoing the first byte (not the subsequent block) is a compromise between:
        Providing necessary interactive feedback
        Avoiding unnecessary network overhead for bulk data
    After the initial verification, regular ACKs are sufficient for bulk data transfer

This selective echoing behavior combines the benefits of interactive responsiveness for the initial byte with efficient bulk transfer for subsequent data.
</pre>
</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-org407a920" class="outline-4">
<h4 id="org407a920"></h4>
</div>
</div>
<div id="outline-container-orgee2f73a" class="outline-3">
<h3 id="orgee2f73a">In caso di errori, è lo stesso TCP che se ne accorge e cerca di sanarlo.</h3>
<div class="outline-text-3" id="text-orgee2f73a">
</div>
<div id="outline-container-org16e9401" class="outline-4">
<h4 id="org16e9401">TCP è orientato allo stream.</h4>
<div class="outline-text-4" id="text-org16e9401">
</div>
<ul class="org-ul">
<li><a id="orgb6be6d5"></a>Abbiamo già visto che a livello 2 ogni pacchetto è identificato da un numero che viene utilizzato per riconoscere i frame su cui avviene l'errore.<br /></li>
<li><a id="org49e182d"></a>In TCP l'idea del sequence number è che, conoscendo la dimensione del file \(N\), il segmento va da \(X\) a \(X+N\).<br /></li>
<li><a id="org9c9aad1"></a>Ci interessa capire fino a che punto dello stream è stato ricevuto tutto correttamente.<br />
<ul class="org-ul">
<li><a id="org8b05dac"></a>Ovvero, l'indice \(K<N\) fino a cui è assicurata la comunicazione avvenuta correttamente.<br /></li>
</ul>
</li>
<li><a id="org8b22112"></a>Quindi il sequence number sommato al payload, mi da il nuovo numero di sequenza.<br /></li>
<li><a id="orgb6ce1e6"></a>Immaginiamo di avere una situazione in cui l'app sender debba spedire 2400 byte con una dimensione del segmento di 500.<br /></li>
<li><a id="org387a4bd"></a>Il primo segmento viene spedito con SEQ=X.<br /></li>
<li><a id="org290e9cb"></a>Il secondo viene spedito senza aspettare l'ACK, con SEQ=X+500<br /></li>
<li><a id="orgd043f23"></a>Si immagini adesso che il secondo segmento venga perso.<br /></li>
<li><a id="orgab6a20b"></a>Nel frattempo, il receiver risponde con un ACK per il primo segmento, ovvero con Ack X + 500 e dato che il segmento è nell'ordine corretto, questo viene spedito al buffer superiore.<br /></li>
<li><a id="orge6daf61"></a>Quando il secondo segmento è spedito ma non è stato ricevuto l'ack corrispondente, il segmento è ancora nel sending buffer del tcp del sender.<br /></li>
<li><a id="org567735a"></a>Comunque non aspetto l'ACK del secondo, perchè essendoci la rete per mezzo, non posso sapere se arriverà a breve o non arriverà.<br /></li>
<li><a id="org737de88"></a>Quindi mando il terzo, con SEQ=X+1000.<br /></li>
<li><a id="orgfc6870f"></a>Quando il receiver riceve questo segmento, lo mette nel suo buffer, ma risponde con lo stesso ACK di prima.<br />
<ul class="org-ul">
<li><a id="org131478f"></a>Ovvero, si intende che sebbene qualcosa sia ricevuto, non "riempie lo spazio" di ciò che non era stato ricevuto.<br /></li>
</ul>
</li>
<li><a id="org26d289b"></a>La questione è che ogni segmento attiva un timer. Finchè il timer non scade, TCP prosegue con <b>tutti</b> i segmenti successivi in buffer d'invio.<br /></li>
<li><a id="org841c569"></a>Quando il timer scade, soltanto quello specifico segmento viene inviato.<br /></li>
<li><a id="orga48438f"></a>A questo punto, il ricevitore si renderà conto che quel segmento, il secondo in questo caso, va posizionato prima dei successivi, che già possiede nel buffer. Allora tutti quelli successivi saranno sbloccati ed il prossimo ACK li includerà. Si parla quindi di ACK cumulativo.<br /></li>
<li><a id="org842f7ac"></a>Questa roba si chiama <b>fast retransmit</b>, ovvero la ritrasmissione di un singolo segmento.<br /></li>
<li><a id="org50406e4"></a>Il timer è pensato per considerare il caso di perdita, anche abbastanza inusuale, sovradimensionato.<br /></li>
<li><a id="org8884fae"></a>Si usa però anche una strategia del triplo ACK: al terzo ACK uguale ricevuto, viene inviato il segmento corrispondente.<br /></li>
<li><a id="orge90b011"></a>Usando queste due strategie, si limita il danno sull'efficienza del timeout e si rende più veloce l'invio dei segmenti precedenti.<br />
<ul class="org-ul">
<li><a id="org5923146"></a>Ad esempio, si fa in modo che tutti i segmenti in coda nel buffer a cui serve quello perso per sbloccarsi, debbano aspettare al massimo T ma spesso anche di meno, così da ridurre lo spazio di memoria occupato.<br /></li>
</ul>
</li>
<li><a id="org581cdce"></a>Il timer è anche molto utile per gli ultimi (?)2 segmenti, dopo i quali non esistono 3 ack che facciano partire la ritrasmissione.<br />
<ul class="org-ul">
<li><a id="org061c953"></a><span class="todo TODO">TODO</span> Per quanti segmenti vale questa proprietà<br /></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5bb05e1" class="outline-2">
<h2 id="org5bb05e1">Negle ha un utilità quando vogliamo garantire un utilizzo efficiente della rete.</h2>
<div class="outline-text-2" id="text-org5bb05e1">
</div>
<div id="outline-container-org8f8d57e" class="outline-3">
<h3 id="org8f8d57e">Lo si usa al posto di mandare ogni carattere da solo, con un overhead altissimo dovuto allo header IP e TCP.</h3>
<div class="outline-text-3" id="text-org8f8d57e">
</div>
<div id="outline-container-orgcbf8cf5" class="outline-4">
<h4 id="orgcbf8cf5">Per mandare un byte, mi servono 4 messaggi.</h4>
</div>
<div id="outline-container-org47acb6b" class="outline-4">
<h4 id="org47acb6b">Si usa il delay per diminuire i messaggi che vengono mandati, ma si paga troppo tempo per l'attesa del delay ogni volta, con piggy bagging in cui nei dati da comunicare si inserisce anche l'ack cumulativo</h4>
</div>
<div id="outline-container-org39fb0dc" class="outline-4">
<h4 id="org39fb0dc">Un compromesso e il nagle</h4>
</div>
</div>
<div id="outline-container-orgbe3283e" class="outline-3">
<h3 id="orgbe3283e">Il Nagle viene in supporto quando abbiamo un quantitativo di dati dall'applicazione, ovvero nel SB (superiore) che è minore alla maximum segment size.</h3>
<div class="outline-text-3" id="text-orgbe3283e">
</div>
<div id="outline-container-orga6c4c17" class="outline-4">
<h4 id="orga6c4c17">Nagle innanzitutto guarda il TCP Sending Buffer (quello inferiore). Se è vuoto vuol dire che non sto aspettando nessun ACK.</h4>
<div class="outline-text-4" id="text-orga6c4c17">
</div>
<ul class="org-ul">
<li><a id="org43eb45d"></a>In questo caso, invio direttamente il contenuto dell'SB, nonostante sia inferiore.<br /></li>
</ul>
</div>
<div id="outline-container-orgf9ef4af" class="outline-4">
<h4 id="orgf9ef4af">Se invece ci sono altri segmenti nel buffer inferiore, lo accoda.</h4>
</div>
<div id="outline-container-orgd141bc7" class="outline-4">
<h4 id="orgd141bc7">Uno dei lati negativi di Nagle è che sebbene utilizzi bene la rete, ovvero limitando l'overhead, (QUAL è L'ASPETTO NEGATIVO)?</h4>
</div>
</div>
<div id="outline-container-org6b18eb6" class="outline-3">
<h3 id="org6b18eb6">Un altro aspetto è che tcp è orientato allo stream e ragiona in base ai bit.</h3>
<div class="outline-text-3" id="text-org6b18eb6">
</div>
<div id="outline-container-org3d8908a" class="outline-4">
<h4 id="org3d8908a">Una sequenza di dati presente nel sending buffer non dev'essere multiplo della max segment size. Il TCP suddivide in blocchetti della dimensione corretta.</h4>
<div class="outline-text-4" id="text-org3d8908a">
</div>
<ul class="org-ul">
<li><a id="org20b4dcc"></a>Se un ultimo blocchetto non raggiunge la max segment size, sta all'applicazione decidere se mandarlo subito o se aspettare nuovi dati, la cui prima parte verrà aggiunta all'ultimo segmento e mandata tutto insieme.<br /></li>
</ul>
</div>
<div id="outline-container-org385f1d6" class="outline-4">
<h4 id="org385f1d6">Quindi si parla di segmento numero n come divisione logica, ma tutto è relativo al byte di inizio sequenza.</h4>
</div>
<div id="outline-container-orgb15e7e1" class="outline-4">
<h4 id="orgb15e7e1">Il principio è che si occupa il meno possibile. L'eventuale padding è fatto ai livelli inferiori.</h4>
</div>
</div>
<div id="outline-container-org76901b1" class="outline-3">
<h3 id="org76901b1">Quando TCP invia un pacchetto ad IP, quest'ultimo, conoscendo perfettamente la max transfer unit del suo livello 2, frammenta ulteriormente se necessario.</h3>
<div class="outline-text-3" id="text-org76901b1">
</div>
<div id="outline-container-org72c941f" class="outline-4">
<h4 id="org72c941f">IP stesso riassemblerà poi la serie di pacchetti e la fornirà a tcp</h4>
</div>
<div id="outline-container-orgf7476f5" class="outline-4">
<h4 id="orgf7476f5">Se non ci riesce, a TCP non arriverà assolutamente nulla.</h4>
<div class="outline-text-4" id="text-orgf7476f5">
</div>
<ul class="org-ul">
<li><a id="org9e7d78a"></a>Inoltre, solo il primo pacchetto avrà lo header tcp.<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org8fcad55" class="outline-3">
<h3 id="org8fcad55">Come abbiamo già visto, il round trip time è il tempo necessario perchè un segmento venga inviato ed ackAto.</h3>
<div class="outline-text-3" id="text-org8fcad55">
</div>
<div id="outline-container-org57ee5ee" class="outline-4">
<h4 id="org57ee5ee">Possiamo però anche inviare più segmenti nello stesso momento.</h4>
</div>
<div id="outline-container-org4e1963c" class="outline-4">
<h4 id="org4e1963c">Ogni segmento fa partire un timer, che dev'essere dimensionato correttamente e quindi non può essere statico.</h4>
</div>
<div id="outline-container-orgc16ac5a" class="outline-4">
<h4 id="orgc16ac5a">Esiste uno standard che ci spiega come calcolarlo</h4>
<div class="outline-text-4" id="text-orgc16ac5a">
</div>
<ul class="org-ul">
<li><a id="org68164c6"></a>Diciamo che il round trip time in media impieghi 30 ms<br /></li>
<li><a id="orge059274"></a>La stima viene fatta considerandolo come un outlier della distribuzione.<br />
<ul class="org-ul">
<li><a id="orgca46d94"></a>Tipicamente si dice che un valore di +3sigma, quindi media più 4 deviazioni standard ci da una stima di un caso molto raro di outlier.<br /></li>
<li><a id="org4669a94"></a>Quindi dobbiamo sapere la media e la deviazione standard in base ai dati del round trip time.<br />
<ul class="org-ul">
<li><a id="orgadc1de0"></a>INSERIRE FORMULA<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org031bb7f" class="outline-3">
<h3 id="org031bb7f">Il controllo di flusso viene messo in atto quando il produttore produce molto più velocemente del ricevente.</h3>
<div class="outline-text-3" id="text-org031bb7f">
</div>
<div id="outline-container-org2192ebc" class="outline-4">
<h4 id="org2192ebc">Infatti, il buffer di ricezione andrebbe poi in overflow.</h4>
<div class="outline-text-4" id="text-org2192ebc">
</div>
<ul class="org-ul">
<li><a id="org796d3fd"></a>Immaginiamo di avere una situazione in cui il sending buffer è di 3000 e il receiving 2000. (mss sempre 500 (ma standard 512)).<br />
<ul class="org-ul">
<li><a id="orgd10b92d"></a>L'informazione della dimensione dell'altro è nota ad entrambi.<br /></li>
<li><a id="org6130e63"></a>Una volta che il sender ha mandato 2000 bit (in 4 tranche perchè la finestra è di 500), il receiving manda non solo un ACK per controllo errori, ma anche un WIN=0, per il controllo di flusso, che indica che lo spazio è finito.<br /></li>
<li><a id="orgcb650ab"></a>Quando avrà poi letto 1000 byte, manderà un ACK con lo stesso byte atteso del precedente, ma una window size di 1000.<br /></li>
</ul>
</li>
<li><a id="org2d9a6fb"></a>Il problema è che se il secondo ack di riapertura viene perso, il sender rimarrebbe bloccato per sempre, ovvero si avrebbe un deadlock.<br />
<ul class="org-ul">
<li><a id="org29cd829"></a>Allo scadere di un Persist Timer nel receiver, viene mandato un segmento speciale vuoto, ovvero senza dati, a cui il receiver risponde con un reinvio dell'ack con nuova finestra.<br />
<ul class="org-ul">
<li><a id="org03099b0"></a>Se anche quel nuovo ack è perso, allo scadere di un nuovo timer la connessione sarebbe chiusa.<br /></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div id="outline-container-org77c131c" class="outline-4">
<h4 id="org77c131c">Il problema della silly window syndrome accade quando il receiver riempie la propria window e continua a notificare la nuova disponibilità ma per una quantità di byte minima.</h4>
<div class="outline-text-4" id="text-org77c131c">
</div>
<ul class="org-ul">
<li><a id="org45b7d6e"></a>La soluzione è l'algoritmo di Clark, in cui l'aggiornamento della windows dev'essere almeno grande come la MSS o come la metà del buffer.<br /></li>
</ul>
</div>
<div id="outline-container-orgcab06bd" class="outline-4">
<h4 id="orgcab06bd">La rete ignora completamente il controllo di flusso.</h4>
</div>
</div>
</div>
<div id="outline-container-orga251260" class="outline-2">
<h2 id="orga251260"><span class="todo TODO">TODO</span> Riempire con ultime 2 lezioni di livello 4</h2>
</div>
<div id="outline-container-orgadebd5c" class="outline-2">
<h2 id="orgadebd5c">Iniziamo il livello applicazione parlando del DNS, ovvero il Domain Name System.</h2>
<div class="outline-text-2" id="text-orgadebd5c">
</div>
<div id="outline-container-org76fab46" class="outline-3">
<h3 id="org76fab46">E' un sistema che permette di rendere più semplice raggiungere un host</h3>
<div class="outline-text-3" id="text-org76fab46">
</div>
<div id="outline-container-orgfb45920" class="outline-4">
<h4 id="orgfb45920">Normalmente si usa un IP per raggiungere un host, ma è praticamente impossibile ricordare un IP.</h4>
</div>
</div>
<div id="outline-container-org42eaae4" class="outline-3">
<h3 id="org42eaae4">Funziona associando un nome (dominio) all'ip di uno specifico host.</h3>
<div class="outline-text-3" id="text-org42eaae4">
</div>
<div id="outline-container-org099be27" class="outline-4">
<h4 id="org099be27">Permette anche di recuperare altre informazioni</h4>
</div>
</div>
<div id="outline-container-orgb8aebe0" class="outline-3">
<h3 id="orgb8aebe0">L'idea è quella di disaccoppiare il modo in cui un essere umano raggiunga un certo servizio.</h3>
<div class="outline-text-3" id="text-orgb8aebe0">
</div>
<div id="outline-container-org3eccfb4" class="outline-4">
<h4 id="org3eccfb4">Ad esempio il servizio potrebbe cambiare indirizzo ip in modo trasparente agli utenti.</h4>
<div class="outline-text-4" id="text-org3eccfb4">
</div>
<ul class="org-ul">
<li><a id="org0273a3d"></a>Questo è utilizzato anche per il load balancing, così che il traffico venga diviso su diversi server.<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgde325ea" class="outline-3">
<h3 id="orgde325ea">Il fully qualified domain name (FQDN) contiene un punto alla fine che indica il root domain</h3>
</div>
<div id="outline-container-orgf2b9605" class="outline-3">
<h3 id="orgf2b9605">Il modo in cui avviene la risoluzione del FQDN fra due macchine, ovvero fra un host che richiede e il server che risponde, è sostituendo ad ogni punto il numero di caratteri che seguono quel punto prima di quello successivo, esempio 2DI5UNIMI2IT0.</h3>
</div>
<div id="outline-container-org4724f81" class="outline-3">
<h3 id="org4724f81">Una query DNS contiene uno header, il FQDN specifico, il tipo di query(A, AAAA, Mx), la classe (che indica la rete su cui si vuole risolvere, che di fatto è sempre internet)</h3>
<div class="outline-text-3" id="text-org4724f81">
</div>
<div id="outline-container-org9a9a73f" class="outline-4">
<h4 id="org9a9a73f">Il tipo può essere2 A per IPv4, AAAA per IPv6, MX per posta, CNAME (canonical name) che è un altro nome per lo stesso sito</h4>
</div>
</div>
<div id="outline-container-orge544d47" class="outline-3">
<h3 id="orge544d47">La risposta ricopia i dati e inserisce l'indirizzo nell'ultimo campo.</h3>
</div>
<div id="outline-container-org91dd862" class="outline-3">
<h3 id="org91dd862">Un record DNS in cache può essere associato ad uno specifico TTL, dopo il quale il record scade e la prossima richiesta effettuata da qualunque client dovrà essere risoluta di nuovo</h3>
<div class="outline-text-3" id="text-org91dd862">
</div>
<div id="outline-container-org194e3ec" class="outline-4">
<h4 id="org194e3ec"><span class="todo TODO">TODO</span> Capire funzionamento in caso di record scaduto</h4>
</div>
</div>
<div id="outline-container-orgc750b61" class="outline-3">
<h3 id="orgc750b61">Il resolving DNS avviene con un client che chiede la risoluzione di uno specifico FQDN al resolver all'interno della stessa macchina.</h3>
<div class="outline-text-3" id="text-orgc750b61">
</div>
<div id="outline-container-org476d13d" class="outline-4">
<h4 id="org476d13d">Il resolver usa UDP perchè non gli serve instaurare la connessione e parla con il Local DNS, che viene impostato in fase di configurazione.</h4>
</div>
</div>
<div id="outline-container-org5ba88f0" class="outline-3">
<h3 id="org5ba88f0">A livello globale ci sono dei root DNS servers che contengono soltanto i domini di primo livello, con gli IP corrispondenti dei NameServer.</h3>
<div class="outline-text-3" id="text-org5ba88f0">
</div>
<div id="outline-container-orge949334" class="outline-4">
<h4 id="orge949334">Usiamo questi se non sappiamo come raggiungere il dominio di primo livello, che di solito però conosciamo già perchè rimane in cache</h4>
</div>
<div id="outline-container-org96bc3f5" class="outline-4">
<h4 id="org96bc3f5">Sul libro sono indicati due approcci, uno iterativo e uno ricorsivo, ma gli esempi sono tutti iterativi.</h4>
<div class="outline-text-4" id="text-org96bc3f5">
</div>
<ul class="org-ul">
<li><a id="org71076b8"></a>L'approccio ricorsivo funziona con il resolver che manda una query al local dns e quest'ultimo risponde con l'indirizzo già pronto.<br />
<ul class="org-ul">
<li><a id="org61a8a4f"></a>Non è implementata nei server per questioni di scalabilità.<br /></li>
<li><a id="orgc65f6f8"></a>Il problema è che sebbene sia molto comoda per il client, il resolver dovrebbe mantenere tantissime informazioni di stato in attesa dei passi successivi.<br /></li>
</ul>
</li>
<li><a id="org10501e4"></a>L'approccio iterativo si applica dal local dns in poi, mentre fra resolver e local dns rimane ricorsivo, ovvero il local dns mantiene lo stato della richiesta fino all'invio della risposta al resolver.<br />
<ul class="org-ul">
<li><a id="org4c46456"></a>Il client continua a ricevere una risposta valida già pronta.<br /></li>
<li><a id="orga5b172e"></a>Il local DNS, però, gestisce in modo iterativo.<br />
<ul class="org-ul">
<li><a id="orgc4cb70f"></a>Manda l'intero dominio al root, che conosce però solo l'IP di primo livello e risponde con un informazione parziale, ovvero con l'indirizzo del NS di primo livello.<br /></li>
<li><a id="org286c63a"></a>Una volta conosciuto quello di primo livello, si chiede al corrispondente NameServer di risolvere la parte rimanente del dominio.<br />
<ul class="org-ul">
<li><a id="orgc57b08b"></a>Questo risponde con l'indirizzo del DNS Server del secondo livello.<br /></li>
</ul>
</li>
<li><a id="org393833c"></a>Se il dominio era composto da tre livelli, il DNS server di secondo livello risponde con l'IP specifico<br /></li>
</ul>
</li>
</ul>
</li>
<li><a id="orgbd5f03d"></a>Anche l'approccio iterativo richidede un overhead per il primo step, che viene attenuato dall'utilizzo della cache.<br />
<ul class="org-ul">
<li><a id="orgcb31a75"></a>In questo modo, la prossima volta che verrà richiesto un dominio di terzo livello appartenente allo stesso secondo livello, la richiesta verrà effettuata direttamente al Name Server di secondo livello.<br /></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2024-12-18 Wed 14:55</p>
</div>
</body>
</html>
