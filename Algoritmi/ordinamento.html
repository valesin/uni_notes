<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it">
<head>
<!-- 2025-02-02 Sun 11:41 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Ordinamento</title>
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" onerror="this.onerror=null;this.href='local.css';" />
<script>
    window.MathJax = {
      tex: {
        ams: { multlineWidth: '85%' },
        {packages: {'[+]': ['mathtools']}},
        tags: 'ams',
        tagSide: 'right',
        tagIndent: '.8em'
      },
      chtml: {
        scale: 1.0,
        displayAlign: 'center',
        displayIndent: '0em'
      },
      svg: {
        scale: 1.0,
        displayAlign: 'center',
        displayIndent: '0em'
      },
      output: {
        font: 'mathjax-modern',
        displayOverflow: 'scale'
      },
      loader: {
        load: ['[tex]/mathtools']
      },
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Ordinamento</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org3dce731">Algoritmi di ordinamento</a>
<ul>
<li><a href="#org4dd5cf1">Introduzione</a>
<ul>
<li><a href="#orgdc60eb3">Stabilità</a></li>
<li><a href="#orgabb06be">Complessità</a>
<ul>
<li><a href="#orgb8775a0">Spazio</a></li>
<li><a href="#org8f958b2">Tempo</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org239c7ef">Algoritmi elementari</a>
<ul>
<li><a href="#orgf463ca1">SelectionSort</a>
<ul>
<li><a href="#org1f44e12">Analisi</a></li>
</ul>
</li>
<li><a href="#org0d48e4e">InsertionSort</a>
<ul>
<li><a href="#org1766505">Alternativa</a></li>
<li><a href="#orgb8c4d4e">Analisi</a></li>
</ul>
</li>
<li><a href="#org5f2feea">BubbleSort</a>
<ul>
<li><a href="#org1e0de30">Miglioramento</a></li>
<li><a href="#orgf7517d1">Analisi</a>
<ul>
<li><a href="#orge402ab8">Caso peggiore</a></li>
<li><a href="#org8bc03bc">Caso migliore</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org0523c0c">Algoritmi avanzati</a>
<ul>
<li><a href="#org2647b29">MergeSort</a>
<ul>
<li><a href="#orgbeb8d55">Merge</a>
<ul>
<li><a href="#org83e90ea">Analisi</a></li>
</ul>
</li>
<li><a href="#org49ea165">Sort</a>
<ul>
<li><a href="#orgbab3d8d">Analisi tempo</a>
<ul>
<li><a href="#orged5da4a">Nota</a></li>
</ul>
</li>
<li><a href="#org2222d0a">Analizi spazio</a></li>
<li><a href="#org2a83963">Implementazione quasi in loco</a>
<ul>
<li><a href="#org00c55b9">Analisi spazio</a></li>
</ul>
</li>
<li><a href="#org66e4548">Stabilità</a></li>
</ul>
</li>
<li><a href="#org4f042ed"><span class="todo TODO">TODO</span> Analisi spazio e implementazione in loco</a></li>
</ul>
</li>
<li><a href="#orgf10cf75">QuickSort</a>
<ul>
<li>
<ul>
<li><a href="#orgb77816e">Partizionamento</a></li>
<li><a href="#org82ee2d1">Unione</a></li>
<li><a href="#orgdd5f87a">Analisi tempo</a>
<ul>
<li><a href="#org53297de">Caso peggiore</a></li>
<li><a href="#orgca62797">Caso migliore</a></li>
<li><a href="#org70b0370">Caso medio</a></li>
<li><a href="#org5e30da0">Osservazioni</a></li>
</ul>
</li>
<li><a href="#org91d66b4">Analisi spazio</a></li>
<li><a href="#orgafa76a0">Ottimizzazioni</a>
<ul>
<li><a href="#orgab9c6cd">Spiegazione più breve</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgfa47e47"><span class="todo TODO">TODO</span> Completare analisi</a></li>
</ul>
</li>
<li><a href="#orgd9d8553">HeapSort</a>
<ul>
<li><a href="#orgedb6997">Struttura "heap"</a>
<ul>
<li><a href="#orgb2042d4">Estrazione del minimo e risistema</a></li>
<li><a href="#orgccf392c">Creazione Heap</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgda75395">Algoritmi senza confronti</a>
<ul>
<li><a href="#orga89850b">BucketSort</a>
<ul>
<li><a href="#orgfb487d9">Differenza con integersort</a></li>
</ul>
</li>
<li><a href="#org9358443">RadixSort</a></li>
<li><a href="#org6ea68c1">Riassunto</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org73a9288">Limite inferiore ai metodi basati sui confronti&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ATTACH">ATTACH</span></span></a></li>
<li><a href="#org7a9f6f6">Riassunto ordinamento basato su confronti</a></li>
</ul>
</div>
</div>
<div id="outline-container-org3dce731" class="outline-2">
<h2 id="org3dce731">Algoritmi di ordinamento</h2>
<div class="outline-text-2" id="text-org3dce731">
</div>
<div id="outline-container-org4dd5cf1" class="outline-3">
<h3 id="org4dd5cf1">Introduzione</h3>
<div class="outline-text-3" id="text-org4dd5cf1">
<p>
In questo corso si tratta soltanto di ordinamento interno, non di quello esterno, in cui i dati vengono prelevati in blocchi dalla memoria di massa.
</p>

<p>
Si ordinano array di strutture complesse, in cui uno dei campi viene scelto come chiave per l'ordinamento ed una relazione di ordine viene definita su di esso.
</p>

<p>
Durante il corso, si utilizzeranno degli array di interi, per semplificare il ragionamento, che viene poi facilmente espanso al caso generale.
</p>
</div>
<div id="outline-container-orgdc60eb3" class="outline-4">
<h4 id="orgdc60eb3">Stabilità</h4>
<div class="outline-text-4" id="text-orgdc60eb3">
<p>
Un algoritmo si dice <b>stabile</b> quando, dati due record con la medesima chiave, l'ordine in cui essi si trovano nell'array ordinato è lo stesso in cui si trovavano in quello iniziale.
</p>
</div>
</div>
<div id="outline-container-orgabb06be" class="outline-4">
<h4 id="orgabb06be">Complessità</h4>
<div class="outline-text-4" id="text-orgabb06be">
<p>
Si studieranno principalmente algoritmi di ordinamento basati su confronti da chiavi. Si valuteranno la complessità in termini di <b>tempo</b> e <b>spazio</b>.
</p>
</div>
<div id="outline-container-orgb8775a0" class="outline-5">
<h5 id="orgb8775a0">Spazio</h5>
<div class="outline-text-5" id="text-orgb8775a0">
<p>
Lo spazio ulteriore a quello necessario per l'array.
</p>
</div>
</div>
<div id="outline-container-org8f958b2" class="outline-5">
<h5 id="org8f958b2">Tempo</h5>
<div class="outline-text-5" id="text-org8f958b2">
<p>
Si utilizza il numero di confronti come criterio. Infatti, questi sono le operazioni più costose. Se ciascun confronto viene effettuato in tempo costante, il numero di confronti fornisce una stima del tempo di calcolo. Infatti, in base al criterio di costo uniforme, può essere poi molitplicato per il tempo necessario per un singolo confronto (es. O(1) per interi, O(s) per stringhe di lunghezza s) per ottenere una stima del tempo totale.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org239c7ef" class="outline-3">
<h3 id="org239c7ef">Algoritmi elementari</h3>
<div class="outline-text-3" id="text-org239c7ef">
<p>
I seguenti algoritmi sono eseguiti in tempo O(n<sup>2</sup>). La loro implementazione è semplice, ma l'efficienza limitata. Agiscono tutti <i>in loco</i>, ovvero non necessitano di strutture ausiliare.
I primi due algo lavorano in modo incrementale. Una parte è ordinata, l'altra no e fra la seconda selezioniamo il posto corretto per aggiungervi un nuovo elemento.
Il bubblesort invece, scambia a coppie e si ferma quando non c'è più modo di scambiare.
</p>
</div>
<div id="outline-container-orgf463ca1" class="outline-4">
<h4 id="orgf463ca1">SelectionSort</h4>
<div class="outline-text-4" id="text-orgf463ca1">
<pre class="example" id="org04b1701">
ALGORITMO selectionSort (Array A[0..N-1])
    FOR k &lt;- 0 to n-2 DO
        m &lt;- k                            //posizione del minimo
        FOR j &lt;- k+1 to n-1 DO
            IF A[j] &lt; A[m] THEN m &lt;- j
            ENDIF
        ENDFOR
        scambia A[m] con A[k]             //sistema il minimo in posizione k
    ENDFOR
</pre>

<div class="org-src-container">
<pre class="src src-go"><span style="color: #a020f0;">package</span> main

<span style="color: #a020f0;">import</span> <span style="color: #8b2252;">"fmt"</span>

<span style="color: #a020f0;">func</span> <span style="color: #0000ff;">selectionSort</span>(<span style="color: #a0522d;">A</span> *[]<span style="color: #228b22;">int</span>) {
        <span style="color: #a0522d;">n</span> := <span style="color: #483d8b;">len</span>(*A)
        <span style="color: #a020f0;">for</span> <span style="color: #a0522d;">k</span> := 0; k &lt;= n-2; k++ {
                <span style="color: #a0522d;">m</span> := k
                <span style="color: #a020f0;">for</span> <span style="color: #a0522d;">j</span> := k + 1; j &lt;= n-1; j++ {
                        <span style="color: #a020f0;">if</span> (*A)[j] &lt; (*A)[m] {
                                m = j
                        }
                }
                (*A)[k], (*A)[m] = (*A)[m], (*A)[k]
        }
}

<span style="color: #a020f0;">func</span> <span style="color: #0000ff;">main</span>() {
        <span style="color: #a020f0;">var</span> <span style="color: #a0522d;">A</span> = &amp;[]<span style="color: #228b22;">int</span>{2, 4, 3, 8, 7, 5, 1, 6}
        fmt.<span style="color: #0000ff;">Println</span>(*A)
        <span style="color: #0000ff;">selectionSort</span>(A)
        fmt.<span style="color: #0000ff;">Println</span>(*A)
}
</pre>
</div>

<pre class="example">
[2 4 3 8 7 5 1 6]
[1 2 3 4 5 6 7 8]
</pre>



<p>
Ad ogni passo viene selezionato l'elemento che dev'essere inserito in posizione \(k\), posizione dalla quale non verrà più spostato. 
</p>

<p>
Prima di ogni passo \(k\), i primi \(k\) elementi si trovano nella posizione corretta.
</p>

<p>
Alla fine del passo, un elemento verrà aggiunto in posizione \(k\), portando gli elementi ordinati a \(k+1\).
</p>

<p>
Al passo \(n-1\), i primi \(n-1\) elementi sono ordinati e ne manca \(1\) da ordinare. L'ultimo passo, quindi, è superfluo e ci fermiamo alla posizione \(n-2\).
</p>

<p>
Se il criterio con cui si vuole ordinare l'array è crescente, l'elemento scelto è il minore.
</p>

<p>
Quindi, scansioniamo l'array partendo da sinistra, sostituendo ogni elemento incontrato con quello che dovrebbe trovarsi lì, ovvero il minimo dei successivi.
</p>

<p>
Per trovare il minimo, scansioniamo l'array partendo dall'elemento appena dopo l'indice attuale, ovvero l'indice che vogliamo aggiustare.
</p>

<p>
Arrivati alla fine, scambiamo il minimo con l'elemento attuale e andiamo avanti.
</p>

<p>
L'ultimo elemento non viene controllato, perchè si trova automaticamente nella sua posizione. Infatti, dovrei trovare il minimo fra un solo elemento e poi spostare l'elemento trovato nell'unica posizione disponibile, che è quella in cui si trova già.
</p>

<p>
<b>Non è stabile</b>, perchè l'elemento che viene scambiato con il minimo perde la propria posizione iniziale relativa ai suoi equivalenti.
</p>

<p>
Un esempio è l'array \([10_{1},\;10_{2},\;5] \rightarrow [5,\;10_{2}\;10_{1}]\).
</p>
</div>
<div id="outline-container-org1f44e12" class="outline-5">
<h5 id="org1f44e12">Analisi</h5>
<div class="outline-text-5" id="text-org1f44e12">
<p>
Per la stima del tempo, notare che alla \(k\) -esima iterazione, sono stati effettuati \(n-k-1\) confronti.
</p>

<p>
Dato che il numero di iterazioni è \(n-2\), il numero totale di confronti è \(\sum_{k=0}^{n-2} (n-k-1)\), che con un cambio di variabile \((n-k-1) = i+1\), diventa &sum;<sub>1</sub><sup>n-1</sup> i$, che per la formula di gauss e risostituendo il valore iniziale, diventa \(\frac{(n-1)(n)}{2}\), quindi \(\Theta(n^2)\)
</p>

<p>
Lo spazio è costante perchè si opera <b>in loco</b>.
</p>
</div>
</div>
</div>
<div id="outline-container-org0d48e4e" class="outline-4">
<h4 id="org0d48e4e">InsertionSort</h4>
<div class="outline-text-4" id="text-org0d48e4e">
<pre class="example" id="orgcb328be">
ALGORITMO insertionSort(Array A[0..N-1])
    FOR k -&gt; 1 TO N-1 DO
        x &lt;- A[k]                       // copia l'elemento da inserire
        j &lt;- k-1
        WHILE j &gt;= 0 &amp;&amp; x &lt; A[j] DO
            A[j+1] = A[j]               // shifta verso destra
            j = j-1
        A[j+1] = x
</pre>

<div class="org-src-container">
<pre class="src src-go"><span style="color: #a020f0;">package</span> main

<span style="color: #a020f0;">import</span> <span style="color: #8b2252;">"fmt"</span>

<span style="color: #a020f0;">func</span> <span style="color: #0000ff;">insertionSort</span>(<span style="color: #a0522d;">A</span> *[]<span style="color: #228b22;">int</span>)  {
        <span style="color: #a0522d;">N</span>:= <span style="color: #483d8b;">len</span>(*A)
        <span style="color: #a020f0;">for</span> <span style="color: #a0522d;">k</span>:=1; k&lt;N; k++{
                <span style="color: #a0522d;">x</span>:=(*A)[k]
                <span style="color: #a0522d;">j</span> := k-1
                <span style="color: #a020f0;">for</span> ;j&gt;=0 &amp;&amp; x &lt; (*A)[j];{
                        (*A)[j+1] = (*A)[j]
                        j--
                }
                (*A)[j+1] = x
        }
}

<span style="color: #a020f0;">func</span> <span style="color: #0000ff;">main</span>() {
        <span style="color: #a020f0;">var</span> <span style="color: #a0522d;">A</span> = &amp;[]<span style="color: #228b22;">int</span>{2, 4, 3, 8, 7, 5, 1, 6}
        fmt.<span style="color: #0000ff;">Println</span>(*A)
        <span style="color: #0000ff;">insertionSort</span>(A)
        fmt.<span style="color: #0000ff;">Println</span>(*A)
}

</pre>
</div>

<pre class="example">
[2 4 3 8 7 5 1 6]
[1 2 3 4 5 6 7 8]
</pre>


<p>
Prima del passo principale, i primi \(k\) elementi formano un <b>sotto-array ordinato</b>.
</p>

<p>
Il passo consiste nel prendere l'elemento successivo, in posizione \(k\) ed inserirlo nella posizione corretta relativamente al sotto-array iniziale.
</p>

<p>
Per farlo, si scansiona il sotto-array <b>da destra verso sinistra</b>, scambiando di volta in volta ogni elemento con il successivo, finchè si arriva ad un elemento minore di quello da inserire.
</p>

<p>
A questo punto, oltre ad aver trovato la posizione finale dell'elemento, si è anche realizzato lo shift verso destra di tutte le posizioni successive e basta copiare l'elemento da inserire nella posizione trovata.
</p>

<p>
Abbiamo quindi due cicli:
</p>
<ul class="org-ul">
<li>quello <b>esterno</b>, da <b>sinistra verso destra</b>, che trova l'elemento da inserire nel sotto-array precedente;</li>
<li>quello <b>interno</b>, da <b>destra verso sinistra</b>, che trova la posizione corretta dell'elemento da inserire e shifta gli elementi maggiori.</li>
</ul>

<p>
E' stabile.
</p>
</div>
<div id="outline-container-org1766505" class="outline-5">
<h5 id="org1766505">Alternativa</h5>
<div class="outline-text-5" id="text-org1766505">
<p>
Un algoritmo in cui il ciclo interno operasse da sinistra verso destra, darebbe luogo allo stesso risultato ma sarebbe meno efficiente.
</p>

<p>
In questo caso, dopo aver trovato la posizione corretta, ovvero quella appena precedente al primo elemento maggiore incontrato, bisognerebbe effettuare lo shift di tutti gli elementi verso destra, che comporta una nuovo accesso a memoria per ogni elemento.
</p>

<p>
Questa versione effettua tanti accessi a memoria (in lettura) in più quanti sono i confronti che effettua.
</p>

<p>
La versione tradizionale ottimizza questo aspetto effettuando una sola lettura, il cui valore viene utilizzato sia per il confronto che per lo shift.
</p>
</div>
</div>
<div id="outline-container-orgb8c4d4e" class="outline-5">
<h5 id="orgb8c4d4e">Analisi</h5>
<div class="outline-text-5" id="text-orgb8c4d4e">
<p>
\(sum_{k=1}^{k} i\), che per la formula di gauss è \(\frac{(n-1)(n)}{2}\).
</p>

<p>
<b>Spazio costante</b> perchè opera in loco.
</p>
</div>
</div>
</div>
<div id="outline-container-org5f2feea" class="outline-4">
<h4 id="org5f2feea">BubbleSort</h4>
<div class="outline-text-4" id="text-org5f2feea">
<pre class="example" id="org8ce5cde">
ALGORITMO bubbleSort(Array A[0..n-1)
k &lt;- 1                            //contatore della scansione
scambiato &lt;- false
    DO
        FOR j&lt;-1 TO n-k DO
        IF A[j] &lt; A[j-1] THEN
            scambia(A[j], A[j-1])
            scambiato &lt;- true
    k &lt;- k+1                      //aggiorno il contatore
    WHILE scambiato &amp;&amp; k &lt; n      //mi fermo quando ho effettuato n-1 scansioni
</pre>

<div class="org-src-container">
<pre class="src src-go"><span style="color: #a020f0;">package</span> main

<span style="color: #a020f0;">import</span> <span style="color: #8b2252;">"fmt"</span>

<span style="color: #a020f0;">func</span> <span style="color: #0000ff;">bubbleSort</span>(<span style="color: #a0522d;">A</span> *[]<span style="color: #228b22;">int</span>) {
        <span style="color: #a0522d;">n</span> := <span style="color: #483d8b;">len</span>(*A)
        <span style="color: #a0522d;">k</span> := 1
        <span style="color: #a020f0;">for</span> {
                <span style="color: #a0522d;">scambiato</span> := <span style="color: #008b8b;">false</span>
                <span style="color: #a020f0;">for</span> <span style="color: #a0522d;">j</span>:=1;j&lt;=n-k;j++{
                        <span style="color: #a020f0;">if</span> (*A)[j] &lt; (*A)[j-1] {
                                (*A)[j], (*A)[j-1] = (*A)[j-1], (*A)[j]
                                scambiato = <span style="color: #008b8b;">true</span>
                        }
                }

                <span style="color: #a020f0;">if</span> !scambiato &amp;&amp; k &gt; n-1 {
                        <span style="color: #a020f0;">break</span>
                }

                k++
        }

}

<span style="color: #a020f0;">func</span> <span style="color: #0000ff;">main</span>() {
        <span style="color: #a020f0;">var</span> <span style="color: #a0522d;">A</span> = &amp;[]<span style="color: #228b22;">int</span>{2, 4, 3, 8, 7, 5, 1, 6}
        fmt.<span style="color: #0000ff;">Println</span>(*A)
        <span style="color: #0000ff;">bubbleSort</span>(A)
        fmt.<span style="color: #0000ff;">Println</span>(*A)
}

</pre>
</div>

<pre class="example">
[2 4 3 8 7 5 1 6]
[1 2 3 4 5 6 7 8]
</pre>



<p>
Questo algoritmo esamina ripetutamente gli elementi a coppie, da sinistra verso destra, e scambia gli elementi se non sono nell'ordine giusto.
</p>

<p>
Se durante una scansione non viene scambiata alcuna coppia, l'array è ordinato e l'algoritmo termina.
</p>

<p>
Ogni serie di scambi (ciclo esterno) porta l'elemento maggiore fra quelli non ordinati a raggiungere la sua posizione finale.
Dopo \(k\) serie, gli ultimi \(k\) elementi sono ordinati.
</p>

<p>
Di conseguenza, il ciclo interno può fermarsi alla posizione \(n-k\).
</p>

<p>
Inoltre, alla $n-1$-esima iterazione, gli ultimi \(n-1\) elementi sono ordinati e di conseguenza anche il primo. Posso quindi fermarmi alla $n-1$-esima iterazione, anche se sono stati effettuati scambi in essa.
</p>
</div>
<div id="outline-container-org1e0de30" class="outline-5">
<h5 id="org1e0de30">Miglioramento</h5>
<div class="outline-text-5" id="text-org1e0de30">
<pre class="example" id="orgb5813a1">
ALGORITMO bubbleSort(Array A[0..n-1])
    primoInOrdine &lt;- n
    DO
        ultimoScambio &lt;- 0
        FOR j=1 TO primoInOrdine-1 DO
            IF A[j] &lt; A[j-1] THEN
                scambia A[j-1] con A[j])
                ultimoScambio = j
            primoInOrdine &lt;- t

    WHILE primoInOrdine &gt; 0
</pre>

<p>
Un miglioramento proposto da <b>Knuth</b> affina la scelta dell'estremo destro oltre cui l'array è sicuramente ordinato.
Infatti, una serie di scambi può portare anche più di un un elemento a raggiungere la propria posizione finale.
In particolare, se l'ultimo scambio è stato fra l'elemento in posizione \(j-1\) e quello in posizione \(j\), allora l'elemento che, dopo lo scambio, si trova in posizione \(j\), si trova nella sua posizione finale, infatti:
</p>

<ul class="org-ul">
<li>è impossibile che \(A_{j+1} < A_{j}\), altrimenti sarebbe stato effettuato un nuovo scambio e quello \([j-1 \leftrightarrow j]\) non sarebbe stato l'ultimo;</li>

<li>non può esserci un elemento \(A_{x} < A_{j}\) fra gli elementi ancora successivi, perchè in quel caso \(A_{x}\) sarebbe appena stato spostato indietro e, come prima, ci sarebbe stato uno scambio successivo a \([j-1 \leftrightarrow j]\)</li>
</ul>
</div>
</div>
<div id="outline-container-orgf7517d1" class="outline-5">
<h5 id="orgf7517d1">Analisi</h5>
<div class="outline-text-5" id="text-orgf7517d1">
</div>
<div id="outline-container-orge402ab8" class="outline-6">
<h6 id="orge402ab8">Caso peggiore</h6>
<div class="outline-text-6" id="text-orge402ab8">
<p>
Con un minimo alla fine dell'array, nella versione non migliorata da Knuth, ogni iterazione \(k\) del ciclo esterno dà luogo a \(n-k\) confronti. Dato che \(k\) va da \(1\) a \(n-1\), si ottiene
\[ \sum_{k=1}^{n-1} n-k \; =\; \sum_{k=1}^{n-1} n - \sum_{k=1}^{n-1} k \; = \; n(n-1) - \frac{n(n-1)}{2} \; = \; \frac{n(n-1)}{2} \; = \; O(n^{2})\].
</p>
</div>
</div>
<div id="outline-container-org8bc03bc" class="outline-6">
<h6 id="org8bc03bc">Caso migliore</h6>
<div class="outline-text-6" id="text-org8bc03bc">
<p>
Array già ordinato, \(n-1\) confronti
</p>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-org0523c0c" class="outline-3">
<h3 id="org0523c0c">Algoritmi avanzati</h3>
<div class="outline-text-3" id="text-org0523c0c">
<p>
I seguenti algoritmi sono eseguiti in un tempo \(O(n\log n)\), che è il limite inferiore di confronti necessari per ordinare un array di interi.
Solo lo HeapSort è in loco, mentre il QuickSort e il MergeSort utilizzano strutture aggiuntive per la ricorsione o per un array aggiuntivo.
</p>
</div>
<div id="outline-container-org2647b29" class="outline-4">
<h4 id="org2647b29">MergeSort</h4>
<div class="outline-text-4" id="text-org2647b29">
<p>
Il MergeSort si basa sullo scomporre il problema dell'ordinamento di un array all'ordinamento delle due metà ed alla loro fusione (<i>merge</i>).
</p>
</div>
<div id="outline-container-orgbeb8d55" class="outline-5">
<h5 id="orgbeb8d55">Merge</h5>
<div class="outline-text-5" id="text-orgbeb8d55">
<p>
Da due array <b>già ordinati</b> \(B\) e \(C\) si vuole ottenere un array \(X\) che contenga tutti gli elementi di \(B\) e \(C\), correttamente ordinati, sfruttando il fatto che i due array iniziali siano già ordinati.
</p>

<p>
Dato che i due array sono già ordinati, ad ogni passo \(k\), il minimo di \(X\) è necessariamente fra quello di \(B\) e quello di \(C\).
Scorro entrambi gli array partendo da sinistra, confrontando i loro minimi e spostando il minore fra essi in posizione \(k-1\) di \(X\).
Svuotato uno degli array, gli elementi dell'altro sono maggiori di ogni altro elemento in \(X\) e vanno quindi posizionati per occupare le posizioni rimanenti.
</p>

<p>
Questa tecnica è usata anche per fondere memorie esterne.
</p>
</div>
<div id="outline-container-org83e90ea" class="outline-6">
<h6 id="org83e90ea">Analisi</h6>
<div class="outline-text-6" id="text-org83e90ea">
<p>
Il caso peggiore avviene quando all'iterazione \(n+m-2\) la lunghezza di entrambi gli array è \(1\).
Questo accade quando entrambi gli ultimi elementi sono più grandi di ogni altro elemento dell'altro array, escluso l'ultimo.
Ovvero nelle situazioni di questo tipo:
\[A = [e_{1},\cdots,e_{x},a]\quad b = [f_{1},\cdots,f_{x},b] \quad\quad a>f_{n},\;b>e_{n},\quad 1\leq n\leq x \]
</p>

<p>
Alcuni esempi diversi fra loro sono:
</p>
<ul class="org-ul">
<li>\([1..50]\quad[1..50]\).</li>
<li>\([2,4,6,8]\quad[1,3,5,7]\)</li>
<li>\([1..10]\quad[100]\)</li>
</ul>

<p>
Il numero di confronti in tali casi è \(n-1\), perchè ogni elemento verrà confrontato con quello dell'altro array, finchè non si arriva al punto in cui un array è vuoto e l'altro contiene un solo elemento, che è il massimo e va semplicemente copiato nell'ultima posizione dell'array risultante.
</p>
</div>
</div>
</div>
<div id="outline-container-org49ea165" class="outline-5">
<h5 id="org49ea165">Sort</h5>
<div class="outline-text-5" id="text-org49ea165">
<pre class="example" id="orgbaf81fd">
ALGORITMO mergeSort(Array A[0..n-1])
    IF n&gt;1 THEN
        m = n/2
        B &lt;-A[0..m-1]
        C &lt;-A[m..n-1]
        mergeSort(B)
        mergeSort(C)
        A &lt;- merge(B,C)
</pre>
<p>
L'ordinamento di un array consiste nel dividere l'array da ordinare in due sottoarray di dimensione \(\lceil \frac{n}{2}\rceil\) e \(\lfloor \frac{n}{2}\rfloor\), ordinarli mediante chiamata ricorsiva e poi unirli con l'algoritmo <code>merge</code>.
</p>
</div>
<div id="outline-container-orgbab3d8d" class="outline-6">
<h6 id="orgbab3d8d">Analisi tempo</h6>
<div class="outline-text-6" id="text-orgbab3d8d">
<p>
Ogni chiamata ricorsiva dell'algoritmo viene eseguita su un input che è la metà di quello originario.
</p>

<p>
Quando l'input raggiunge la dimensione di \(1\), non viene eseguita alcuna operazione.
</p>

<p>
Il numero di confronti richiesto dal MergeSort su un input \(n\), indicato con \(C(n)\), è quindi
\[C(n) = C(\lfloor\frac {n}{2}\rfloor + C(\lceil\frac{n}{2}\rceil) + n - 1\]
</p>

<p>
Per semplificare i calcoli, supponiamo \(n\) pari ed otteniamo \(C(n) = 2C(\frac {n}{2}) + n - 1\)
</p>

<p>
Usando il metodo di sostituzione:
</p>

<p>
<b><b>Step 1: Dividi entrambi i lati per \(n\)</b></b>
</p>

<p>
\[ \dfrac{C(n)}{n} = \dfrac{2C\left(\dfrac{n}{2}\right)}{n} + \dfrac{n-1}{n} \]
</p>

<p>
<b><b>Step 2: Muovi il \(2\) al denominatore</b></b>
</p>

<p>
\[ \dfrac{C(n)}{n} = \dfrac{C\left(\dfrac{n}{2}\right)}{\dfrac{n}{2}} + 1 - \dfrac{1}{n} \]
</p>

<p>
<b><b>Step 3: Sostituisci con una nuova funzione</b></b>
</p>

<p>
\[ f(n) = \dfrac{C(n)}{n} \]
</p>

<p>
Quindi la nuova equazione diventa:
</p>

<p>
\[ f(n) = f\left(\dfrac{n}{2}\right) + 1 - \dfrac{1}{n} \]
</p>

<p>
<b><b>Step 4: Espandi ricorsivamente</b></b>
</p>

\begin{align*}
f(n) &= f\left(\dfrac{n}{2}\right) + 1 - \dfrac{1}{n} \\
&= \left[f\left(\dfrac{n}{4}\right) + 1 - \dfrac{2}{n}\right] + 1 - \dfrac{1}{n} \\
&= f\left(\dfrac{n}{4}\right) + 2 - \dfrac{3}{n} \\
&= f\left(\dfrac{n}{2^i}\right) + i - \frac{\sum_{k=0}^{i}2^{k}}{n}
\end{align*}


<p>
Notare che \(\sum_{k=0}^{i}2^{k} = \dfrac{2^i-1}{n}\)
</p>

<p>
<b><b>Step 5: Trova il caso in cui la ricorsione si ferma</b></b>
</p>

<p>
Quando \[ \dfrac{n}{2^i} = 1 \]
Allora \[ n = 2^i \]
Quindi \[ i = \log_2 n \]
</p>

<p>
<b><b>Step 6: Sostituisci il valore trovato</b></b>
</p>

<p>
\[ f(n) = f(1) + \log_2 n - \dfrac{n-1}{n} \]
</p>

<p>
<b><b>Step 7: Risolvi per C(n)</b></b>
</p>

<p>
Dato che \[ f(n) = \dfrac{C(n)}{n} \]
</p>

<p>
Moltiplica entrambi i lati per \(n\):
</p>

<p>
\[ C(n) = n \cdot f(1) + n\log_2 n - (n-1) \]
\[ C(n) = n\log_2 n + O(n) \]
</p>

<p>
Infine:
</p>

<p>
\[ C(n) = O(n\log n) \]
</p>
</div>
<div id="outline-container-orged5da4a" class="outline-7">
<h7 id="orged5da4a">Nota</h7>
<div class="outline-text-7" id="text-orged5da4a">
<p>
Perchè divido per \(n\) e muovo il \(2\) al denominatore?
</p>


<blockquote>
<p>
Dividing by n in the recurrence relation is not strictly necessary, but it's a helpful technique for several intuitive reasons:
</p>

<ol class="org-ol">
<li><b><b>Pattern Recognition:</b></b>
When we divide by n, we get:
\[ \frac{C(n)}{n} = \frac{C(n/2)}{n/2} + 1 - \frac{1}{n} \]
This transformation helps us see a clearer pattern. By defining f(n) = C(n)/n, we get:
\[ f(n) = f(n/2) + 1 - \frac{1}{n} \]
This is much simpler to work with than the original equation.</li>

<li><b><b>Telescoping Series:</b></b>
The division by n transforms the recurrence into a form that resembles a telescoping series. When we expand it:
\[ f(n) = f(n/2) + 1 - \frac{1}{n} \]
\[ f(n/2) = f(n/4) + 1 - \frac{2}{n} \]
\[ f(n/4) = f(n/8) + 1 - \frac{4}{n} \]
Each step adds a constant term (1) and a decreasing fraction, making the pattern easier to spot and sum.</li>

<li><b><b>Normalization:</b></b>
By dividing by n, we're essentially "normalizing" the cost at each level relative to the input size. This helps us see how the cost per element changes as we go deeper in the recursion.</li>

<li><b><b>Mathematical Intuition:</b></b>
Without division by n, we would need to track larger terms and their relationships. The division helps reduce the complexity of each term, making the mathematical manipulation more manageable.</li>
</ol>
</blockquote>
</div>
</div>
</div>
<div id="outline-container-org2222d0a" class="outline-6">
<h6 id="org2222d0a">Analizi spazio</h6>
<div class="outline-text-6" id="text-org2222d0a">
<p>
Sia \(H(n)\) l'altezza massima dello stack di ricorsione, ovvero quanti record di attivazione possono esistere allo stesso momento, in funzione di \(n\)?
Se \(n=1\), \(H(n)=1\), ovvero l'unica chiamata che termina subito con il caso base.
Se \(n>1\), allora avrò una chiamata iniziale, più \(\max (H(\lfloor\frac {n}{2}\rfloor), H(\lceil\frac{n}{2}\rceil)\) chiamate nello stesso momento.
Questo perchè tutte le chiamate ricorsive su uno dei lati vengono esaurite prima di passare al lato successivo.
Per \(n\) potenza di \(2\), si ottiene \(H(n)=1+\log_{2} n\). In generale, \(H(n) = \Theta(\log n)\).
</p>
</div>
</div>
<div id="outline-container-org2a83963" class="outline-6">
<h6 id="org2a83963">Implementazione quasi in loco</h6>
<div class="outline-text-6" id="text-org2a83963">
<pre class="example" id="org72aead4">
ALGORITMO mergeSort(array A[0...n-1])
    Sia X[0...n-1] un array
    mergeSort(A,0,n,X)

PROCEDURA mergeSort(array A, indice i, indice f, array X)
    IF f-1 &gt; 1 THEN
        m &lt;- (i+f)/2
        mergeSort(A, i, m, X)
        mergeSort(A, m, f, X)
        merge(A,i,m,f,X)

PROCEDURA merge(array A, indice i, indice m, indice f, array X)
    i1 &lt;- i
    i2 &lt;- m
    k &lt;- 0
    WHILE i1 &lt; m AND i2 &lt; f DO
        IF A[i1] &lt;= A[i2] THEN
            X[k] &lt;- A[i1]
            i1 &lt;- i1 + 1
        ELSE
            X[k] &lt;- A[i2]
            i2 &lt;- i2 + 1
        k &lt;- k + 1
    IF i1 &lt; m THEN
        FOR j &lt;- i1 to m-1 DO
            X[k] &lt;- A[j]
            k &lt;- k + 1
    ELSE
        FOR j &lt;- i2 TO f-1 DO
            X[k] &lt;- A[j]
            k &lt;- k + 1
    FOR k &lt;- 0 TO f - i - 1 DO
        A[i + k] &lt;- X[k]
</pre>
<p>
L'implementazione precedente occupa tanto spazio inutile. Ogni chiamata ricorsiva che rimane aperta, mantiene in memoria il contenuto dell'array in cui quella precedente viene divisa.
Se si riesce a ottimizzare quella parte, si potrebbe risparmiare una gran parte di memoria.
Si ovvierà a questo problema giocando con gli indici.
Otterrò una procedura che prende in input non soltanto l'array, ma gli indici di partenza ed arrivo.
La lunghezza dell'array diventa uguale alla differenza fra l'indice di arrivo e quello di partenza, e dividendo per due si ottiene l'indice di mezzo (al netto della parte decimale).
Una volta fissato <code>m</code>, non ho più bisogno di copiare il contenuto degli array parziali in una nuova porzione di memoria, quindi salto i due assegnamenti e passo direttamente alla chiamata ricorsiva.
La prima chiamata opera sull'array da <code>i</code> a <code>m</code>, mentre la seconda da <code>m</code> a <code>f</code>.
L'algoritmo che viene chiamato all'inizio è un "wrapper" in cui gli indici sono quello iniziale e finale.
Dopodichè, va modificato anche l'algoritmo di <code>merge</code> per operare su uno stesso array.
Prima lavorava su due array diversi, salvando il contenuto ordinato in un nuovo array.
Adesso continuo ad avere un array ulteriore di supporto in cui ordinare gli elementi, ma ricopierò poi il contenuto di questi elementi nell'array originale.
Notare che l'array di supporto per il <code>merge</code> viene dichiarato in precedenza, nella funzione wrapper. Per una questione di chiarezza, sarebbe meglio non fare così, cosicchè non sarebbe necessario passare l'array ogni volta. Nonostante ciò, è più efficiente dichiararlo all'esterno, al posto di istanziarne uno nuovo ad ogni chiamata di <code>merge</code>.
L'analisi del tempo è assolutamente la stessa.
</p>
</div>
<div id="outline-container-org00c55b9" class="outline-7">
<h7 id="org00c55b9">Analisi spazio</h7>
<div class="outline-text-7" id="text-org00c55b9">
<p>
Adesso utilizzo un array dimensionato su quello iniziale, quindi \(\Theta(n)\).
L'altezza dello stack di ricorsione è la stessa di prima, ma la dimensione dei record è costante. L'occupazione di memoria è quindi \(\Theta(\log n)\). Fra i due prevale \(\Theta(n)\).
</p>
</div>
</div>
</div>
<div id="outline-container-org66e4548" class="outline-6">
<h6 id="org66e4548">Stabilità</h6>
<div class="outline-text-6" id="text-org66e4548">
<p>
Nel <code>merge</code> mi capita di confrontare elementi uguali. Eppure, viene usato il \(\leq\), quindi nel caso in cui l'elemento del primo array sia uguale, viene scelto quello. Quindi è <b>stabile</b>. Nel caso in cui togliessi l'uguale e usassi il semplice \(<\), perderebbe la stabilità.
</p>
</div>
</div>
</div>
<div id="outline-container-org4f042ed" class="outline-5">
<h5 id="org4f042ed"><span class="todo TODO">TODO</span> Analisi spazio e implementazione in loco</h5>
</div>
</div>
<div id="outline-container-orgf10cf75" class="outline-4">
<h4 id="orgf10cf75">QuickSort</h4>
<div class="outline-text-4" id="text-orgf10cf75">
<p>
Il criterio è di selezionare un elemento arbitrario, <b>perno</b> o <b>pivot</b>, e partizionare il vettore in due sotto-vettori i cui elementi sono minori e maggiori del perno, posizionandoci in mezzo quest'ultimo.
</p>

<p>
Non è necessario che i sotto-vettori siano
Dato che dopo il passo generico, il perno è ordinato, basta ordinare le due partizioni, utilizzando la stessa procedura, fin quando la lunghezza dell'array diventa \(1\).
</p>

<pre class="example" id="orga256b08">
ALGORITMO quickSort(Array A)
IF lunghezza A&gt;1 THEN
    scegli un elemento x di A
    B &lt;- {y \in A} | y &lt;= x}
    C &lt;- {y \in A} | y &gt; x}
    quickSort(B)
    quickSort(C)
    A &lt;- concatenazione di B,x,C
</pre>
</div>
<div id="outline-container-orgb77816e" class="outline-6">
<h6 id="orgb77816e">Partizionamento</h6>
<div class="outline-text-6" id="text-orgb77816e">
<pre class="example" id="org7dbcc34">
ALGORITMO partiziona(Array A, indice i, indice f) -&gt; indice
perno &lt;- A[i]
dx &lt;- f
sx &lt;- i
WHILE sx &lt; dx DO
   DO dx &lt;- dx - 1 WHILE A[dx] &gt;  perno          ;; in questo caso non posso sforare, perchè prima o poi raggiungerò il perno
   DO sx &lt;- sx + 1 WHILE sx &lt; dx AND A[sx] &lt;= perno  ;; in questo caso posso sforare, quindi devo anche fare un controllo
   IF sx &lt; dx THEN
      scambia A[sx] con A[dx]
scambia A[i] con A[dx]
RETURN dx
</pre>

<p>
Il partizionamento potrebbe essere effettuato banalmente utilizzando due vettori aggiuntivi per inserirvi gli elementi in base al loro ordine rispetto al perno.
</p>

<p>
Per ottenere una maggiore efficienza, il mio algoritmo <code>partiziona</code> sposta gli elementi all'interno dello specifico array in modo che prima del perno ci siano gli elementi minori e dopo quelli maggiori.
</p>

<p>
Non è necessario che gli elementi nelle partizioni siano ordinati.
</p>

<p>
Alla fine, l'algoritmo restituisce la posizione del perno, che si trova nella sua posizione definitiva, in modo da poter distinguere le due partizioni.
</p>

<p>
L'elemento scelto come perno è il primo, sebbene un euristica più avanzata potrebbe essere utilizzata in casi specifici.
</p>

<p>
Il metodo attraverso cui si trovano gli elementi da spostare è il seguente:
</p>
<ul class="org-ul">
<li>scansioniamo l'array da destra verso sinistra fino al primo elemento maggiore o uguale al perno</li>
<li>scansioniamo l'array da sinistra verso destra fino al primo elemento minore del perno</li>
</ul>

<p>
Se un elemento è attraversato dalla scansione, si trova nella partizione corretta, ovvero è maggiore del perno se attraversato dalla scansione destra (o minore se da quella sinistra).
</p>

<p>
Di conseguenza, quando le due scansioni si incontrano, gli elementi sono tutti partizionati, in quanto sono stati attraversati tutti da una delle due scansioni.
</p>

<p>
Se invece le scansioni si arrestano prima, gli elementi di arresto si trovano nella partizione sbagliata e vanno scambiati fra loro.
</p>

<p>
Il controllo della sovrapposizione delle scansioni viene effettuato 3 volte, per evitare confronti inutili:
</p>
<ul class="org-ul">
<li>il confronto nel <code>WHILE</code> esterno serve affinchè il ciclo <b>non venga ripetuto</b> quando la sovrapposizione è già avvenuta. In tal caso, le scansioni hanno già percorso quanti più elementi possibile e non si muoverebbero ulteriormente.</li>
<li>il confronto nel <code>WHILE</code> interno fa sì che si <b>eviti un confronto inutile</b> nel caso in cui la <b>sovrapposizione sia già avvenuta</b>: se un elemento è stato già attraversato (superato) dalla scansione destra, è maggiore del perno ed è quindi superfluo che si controlli che sia minore.</li>
<li>il confronto nell'<code>IF</code> è necessario e la sua assenza comporterebbe uno scambio anche quando le scansioni si sono già incontrate, con un confronto inutile, o peggio quando sono già sovrapposte, scambiando gli estremi delle due partizioni <b>in modo scorretto</b>.</li>
</ul>

<p>
In un array già ordinato, <code>dx</code> si arresterebbe al perno e <code>sx</code> si sposterebbe all'elemento appena successivo.
La sovrapposizione è già avvenuta e quindi l'algoritmo termina, restituendo l'indice del primo elemento in quanto è quello già ordinato; quindi, la partizione destra corrisponderebbe al resto del vettore e quella sinistra sarebbe vuota.
</p>

<p>
Nel confronto, utilizzo la relazione di ordine strettamente crescente per la scansione destra e la relazione di ordine non strettamente crescente per la scansione sinistra.
</p>

<p>
Questo è necessario affinchè l'indice della scansione destro sia limitato a sinistra dal perno. Se includessi il caso di uguaglianza, il perno verrebbe scavalcato e l'indice si troverebbe fuori dall'array.
</p>

<p>
La scansione sinistra, invece, potrebbe scavalcare l'ultima posizione ed è quindi limitata dall'indice della scansione destra, che è al massimo uguale proprio all'ultima posizione.
</p>

<p>
La posizione finale degli indici può essere uguale, oppure tale che <code>dx​==sx-1</code>
</p>

<p>
Infatti, <code>sx</code> si ferma quando un incremento lo porta allo stesso indice <code>dx</code>.
</p>

<p>
Quando, però, all'inizio della scansione di <code>sx</code>, <code>dx</code> si trova già allo stesso indice, <code>sx</code> incrementerà una volta prima di fermarsi, terminando nell'indice successivo. Questo è il caso dell'array già ordinato.
</p>
</div>
</div>
<div id="outline-container-org82ee2d1" class="outline-6">
<h6 id="org82ee2d1">Unione</h6>
<div class="outline-text-6" id="text-org82ee2d1">
<pre class="example" id="org78991c4">
PROCEDURA quickSort_inner(Array A, indice i, indice f)
IF f-i&gt;1 THEN
    m &lt;- partiziona(A,i,f)
    quickSort(A,i,m)
    quickSort(A, m+1, f)   // il perno è già apposto, quindi non ci interessa

ALGORITMO quickSort(Array A[0..n-1])
quickSort_inner(A,0,n)
</pre>
</div>
</div>
<div id="outline-container-orgdd5f87a" class="outline-6">
<h6 id="orgdd5f87a">Analisi tempo</h6>
<div class="outline-text-6" id="text-orgdd5f87a">
<p>
Negli algoritmi analizzati in precedenza, si conosceva esattamente la dimensione dell'input delle chiamate ricorsive.
In questo caso, invece, essa dipende dalla scelta del perno.
Sia \(C(n)\) il numero di confronti su un array di lunghezza \(n\) e \(k\) il numero di elementi in una delle partizioni, allora
\[
C(n) = \begin{cases}
0& \leq 1 \\
C_{\text{part}}(n) + C(k)  + C(n-k-1)&\text{altrimenti}
\end{cases}
\]
</p>
</div>
<div id="outline-container-org53297de" class="outline-7">
<h7 id="org53297de">Caso peggiore</h7>
<div class="outline-text-7" id="text-org53297de">
<p>
Il caso peggiore è quello in cui la <b>somma</b> fra i due termini <b>massimizza il risultato</b>.
</p>

<p>
\[C_{w}(n)=n+\max (C_{w}(k)+C_{w}(n-k-1)|k=0..n-1)\]
</p>

<p>
Si può dimostrare che il massimo si ottiene quando la <b>partizione è completamente sbilanciata</b>, ovvero \(k=0\) o \(k=n-1\).
</p>

<p>
L'intuizione è che se divido il problema in uno di dimensione \(1\) e l'altro di dimensione \(n-1\), allora ho ridotto poco la dimensione del problema e non ho ottenuto alcun beneficio dalla tecnica <i>divide et impera</i>.
Infatti, otterrei nel caso ricorrente 
Quindi risolvendo l'equazione di ricorrenza otterrei \(\sum_{i=2}^{n} i = \frac{n(n+1)}{2} -1 = \Theta(n^{2})\), molto sconveniente, perchè il codice è molto complicato, mentre il risultato è lo stesso degli algoritmi elementari, con in più lo stack di ricorrenza. Inoltre, su un array già parzialmente ordinato, fa tanti confronti.
Un numero abbastanza preciso è \(\approx \frac{n^{2}}{2}\).
</p>
</div>
</div>
<div id="outline-container-orgca62797" class="outline-7">
<h7 id="orgca62797">Caso migliore</h7>
<div class="outline-text-7" id="text-orgca62797">
<p>
Voglio trovare la coppia che minimizza la somma \(C_{w}(k)+C_{w}(n-k-1)\).
Si dimostra che il minimo si ottenga con \(k = \frac{n}{2}\) per \(n\) pari, o l'arrotondamento di quella cifra per \(n\) dispari.
</p>
</div>
</div>
<div id="outline-container-org70b0370" class="outline-7">
<h7 id="org70b0370">Caso medio</h7>
<div class="outline-text-7" id="text-org70b0370">
<p>
Prendo la somma dei tempi di tutti i casi possibili e poi la divido per il numero di casi, ovvero una semplice media.
\(C(n) = 0\) se \(n\leq 1\)
\(C(n) =\frac{\sum_{n=0}^{n-1} (n + C(k) + C(n-k-1)}{n}\)
Divido la frazione nei fattori del numeratore, e ottengo che la sommatoria su n è uguale ad \(n\), e gli altri due fattori sono uguali.
Otteniamo una certa equazione, che non dimostriamo come è ottenuta, ma dimostriamo per induzione che sia corretta.
Dimostriamo che \(C(n) \leq 2n \log n\), per \(n\geq 1\)
Caso base \(n=1\): C(1) = 0, sostituisco ed è giusto
Induzione: \(C(n) = n + \frac{2}{n} sum_{i=2}^{n-1}C(i)\leq n + \frac{2}{n} sum_{i=2}^{n-1}C(i) 21\log i\)
</p>

<p>
Alla fine ottengo che il caso medio è minore di \(2n \log n\), che è uguale a \(1.39 n\log_{2} n\). Quindi il caso medio è molto vicino al caso migliore. Questo vuol dire che il caso peggiore succede molto raramente.
Una tecnica che viene usata per aumentare il caso medio, è quella che prima di partizionare randomizza l'ordine. Infatti, il caso peggiore è quello in cui l'array sia già ordinato e il primo elemento sia il minore. Così facendo, diminuisce la probabilità che lo sia.
Altrimenti scegliamo come perno un elemento a caso, lo scambiamo con il primo e poi operiamo l'array.n
</p>
</div>
</div>
<div id="outline-container-org5e30da0" class="outline-7">
<h7 id="org5e30da0">Osservazioni</h7>
<div class="outline-text-7" id="text-org5e30da0">
<p>
Non è stabile, esiste una versione che lo renda stabile ma aumentando la costante.
</p>
</div>
</div>
</div>
<div id="outline-container-org91d66b4" class="outline-6">
<h6 id="org91d66b4">Analisi spazio</h6>
<div class="outline-text-6" id="text-org91d66b4">
<p>
Nel caso di una suddivisione bilanciata, ottengo un'altezza \(\approx \log_{2} n\), simile al MergeSort. Infatti, uno dei lati conterrà la metà dell'input, che a sua volta chiamerà metà dell'input, e così via.
Nel caso di una suddivisione sbilanciata, apro una chiamata ricorsiva per ogni elemento, quindi avrò un'altezza lineare.
</p>
</div>
</div>
<div id="outline-container-orgafa76a0" class="outline-6">
<h6 id="orgafa76a0">Ottimizzazioni</h6>
<div class="outline-text-6" id="text-orgafa76a0">
<p>
Notare che la seconda chiamata ricorsiva è in coda. Posso, dunque ottimizzare questa parte. Cancello la seconda chiamata ricorsiva, trasformo l'IF in un WHILE.
In questo caso mi libero di una delle parti in cui lo stack di attivazione cresce. Trasformando la chiamata ricorsiva destra in un iterazione, risolvo i casi in cui il perno è il minore ( o maggiore? ), perchè in quel caso la parte sinistra non cresceva, mentre la destra sì.
Dato che posso invertire l'ordine delle chiamate ricorsive, posso fare la stessa cosa al contrario, ovvero ricorrere sulla parte destra.
Ognuna ha un caso critico. Posso scrivere una procedura che scelga quale delle due usare secondo un criterio.
</p>
<pre class="example" id="org58956c5">
PROCEDURA quickSort(Array A, indice i, indice f)
WHILE f-i&gt;1 DO
    m &lt;- partiziona(A,i,f)
    IF  m-i &lt; f-m THEN
        quickSort(A,i,m)
        i &lt;- m+1
    ELSE
        quickSort(A,m+1,f)
        f&lt;- m
</pre>
<p>
Il criterio è che io so che la chiamata ricorsiva che crescerà di più è quella più lunga. Quindi faccio la chiamata ricorsiva su quella più breve.
Di quanto migliora? Prima la lunghezza arrivava ad \(n\), perchè nel caso peggiore facevo chiamate sull'intero array ogni volta, ovvero eliminavo un caso da ogni chiamata ricorsiva e mi calcolavo gli altri n-1.
Adesso, sono sicuro che ogni volta faccio ricorsione sulla parte minore. Nel caso in cui il perno sia perfettamente centrato, lavoro su chiamate ricorsive sulla metà degli elementi, quindi con un altezza logaritmica. Entrambe le scelte avrebbero lo stesso risultato, ovvero uguale all'algoritmo senza opportunistica.
Nel caso in cui le partizioni siano sbilanciate, sceglierò sempre quella minore, quindi la ricorsione sarà sempre minore di quella del caso precedente. Quindi lo spazio occupato da questa versione rispetto alla precedente, rimane uguale nel caso migliore e diminuisce nel caso peggiore. (Il vantaggio è ridotto per il fatto che il caso peggiore avviene raramente, ma è comunque un vantaggio).
</p>
</div>
<div id="outline-container-orgab9c6cd" class="outline-7">
<h7 id="orgab9c6cd">Spiegazione più breve</h7>
<div class="outline-text-7" id="text-orgab9c6cd">
<p>
Trasformo il secondo <code>sort</code> ricorsivo in coda in un'iterazione.
</p>

<p>
Inoltre, applico l'iterazione sulla partizione con input minore.
</p>

<p>
L'<code>IF</code> diventa <code>WHILE</code>, perchè le chiamate rimangono aperte dopo la chiamata ricorsiva.
</p>

<p>
In questo modo, la ricorsione viene sempre effettuata solo sulla parte con input minore, quindi minore o uguale a \(\frac{n}{2}\).
</p>

<p>
Il caso peggiore del numero di chiamate ricorsive nello stesso momento diventa nel caso in cui tutte le partizioni siano bilanciate, perchè ogni chiamata sarebbe di dimensione \(\frac{n}{2}\), con un altezza logaritmica.
</p>

<p>
Tutti gli altri casi sono migliori di questo.
</p>

<p>
Quindi l'altezza totale diventa \(O(\log n)\).
</p>
</div>
</div>
</div>
<div id="outline-container-orgfa47e47" class="outline-5">
<h5 id="orgfa47e47"><span class="todo TODO">TODO</span> Completare analisi</h5>
</div>
</div>
<div id="outline-container-orgd9d8553" class="outline-4">
<h4 id="orgd9d8553">HeapSort</h4>
<div class="outline-text-4" id="text-orgd9d8553">
</div>
<div id="outline-container-orgedb6997" class="outline-5">
<h5 id="orgedb6997">Struttura "heap"</h5>
<div class="outline-text-5" id="text-orgedb6997">
<p>
Uno <b>heap</b> è un <b>albero binario quasi completo</b>, ovvero pieno fino almeno al livello \(h-1\), in cui la chiave contenuta in ogni nodo è maggiore o uguale a quelle contenute nei due figli.
</p>

<p>
Di conseguenza, la radice dell'albero conterrà l'elemento con chiave maggiore fra tutti i nodi.
</p>
</div>
<div id="outline-container-orgb2042d4" class="outline-6">
<h6 id="orgb2042d4">Estrazione del minimo e risistema</h6>
<div class="outline-text-6" id="text-orgb2042d4">
<p>
Il <b>massimo di uno heap</b> può essere prelevato e dev'essere sostituito in modo da mantenere le condizioni di numero e ordine relativo dei nodi.
</p>

<p>
Per fare ciò, viene sostituito con l'ultima foglia, che viene poi fatta discendere fino ad occupare un posto adeguato.
</p>

<pre class="example" id="orged7fcde">
PROCEDURA risistema(heap H)
    v &lt;- H
    x &lt;- v.chiave
    y &lt;- v.altri campi
    daCollocare &lt;- true
    DO
        IF v è una foglia THEN
            daCollocare &lt;- false
        ELSE
            u &lt;- figlio di v di valore massimo
            IF u.chiave &gt; x THEN
                v-chiave &lt;- u.chiave
                v.altri campi &lt;- u.altricampi
                v &lt;- u
            ELSE
                daCollocare &lt;- false
    WHILE da Collocare
    v.chiave &lt;- x
    v.altri campi &lt;- y
</pre>

<p>
Il ciclo di questo algoritmo effettua due confronti ad ogni iterazione:
</p>
<ul class="org-ul">
<li>uno fra i due figli, per trovare il maggiore;</li>
<li>uno fra la radice e il figlio maggiore, per stabilire se scambiarli o meno.</li>
</ul>

<p>
Inoltre, esso si arresta arrivati ad una foglia, ovvero al livello \(h\) o \(h-1\).
</p>

<p>
Di conseguenza, il numero di confronti è \(2h\) o \(2(h-1)\), quindi \(\Theta(h)\) nel caso peggiore.
</p>
</div>
</div>
<div id="outline-container-orgccf392c" class="outline-6">
<h6 id="orgccf392c">Creazione Heap</h6>
<div class="outline-text-6" id="text-orgccf392c">
<p>
È possibile creare uno heap in modo ricorsivo o iterativo. Fra i due approcci, scegliamo quello iterativo, perchè occupa spazio costante e non logaritmico nel caso peggiore.
</p>

<pre class="example" id="org96bf9e0">
PROCEDURA creaHeap (albero binario T)
    h &lt;- altezza di T
    FOR p &lt;- h DOWNTO 0 DO
        FOREACH nodo x di profondità p DO
            risistema(sottoalbero T_x di radice x)
</pre>

<p>
Questa procedura esegue <code>risistema</code> su ognuno dei \(2^p\) nodi del $p$-esimo livello.
</p>

<p>
Dato che <code>risistema</code> è lineare rispetto all'altezza, si ottiene che nel caso peggiore il numero di confronti è
\[\Theta(\sum_{p=0}^h (h-p)2p)\]
L'ordine è quindi di \(2^{h+1}-2-h\) e quindi esponenziale rispetto all'altezza dell'albero.
</p>

<p>
Dato che l'altezza è logaritmica, la procedura di costruzione dello heap è <b>lineare</b> rispetto al numero di nodi.
</p>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-orgda75395" class="outline-3">
<h3 id="orgda75395">Algoritmi senza confronti</h3>
<div class="outline-text-3" id="text-orgda75395">
</div>
<div id="outline-container-orga89850b" class="outline-4">
<h4 id="orga89850b">BucketSort</h4>
<div class="outline-text-4" id="text-orga89850b">
<p>
Si usa per ordinare \(n\) <b>interi</b> nell'intervallo \([0,b-1]\).
</p>

<p>
L'idea è di avere un array di supporto che contiene delle code di elementi da ordinare.
</p>

<p>
Ogni elemento con chiave \(k\) si trova in posizione \(k\) dell'array.
</p>

<p>
Il numero di bucket in questa implementazione è \(b\), ovvero il masssimo nell'intervallo in cui si trovano i numeri da ordinare.
</p>
<pre class="example" id="org51df1c8">
ALGORITMO bucketSort(Array A[0..n-1], intero b)
    Sia Y[0..b-1] un array

    ;; Inizializza buckets Theta(b)
    FOR i &lt;- 0 TO b-1 DO
        Y[i] &lt;- coda vuota

    ;; Riempi buckets Theta(n)
    FOR i &lt;- 0 TO n-1 DO
        x &lt;- A[i].chiave
        Y[x].enqueue(A[i]))

    j &lt;- 0
    FOR i &lt;- 0 TO b-1 DO
        WHILE NOT Y[i].isEmpty() DO
            A[j] &lt;- Y[i].dequeue()
            j &lt;- j+1
</pre>

<p>
L'<b>analisi</b> è di \(O(n+b)\) in quanto la costruzione dei buckets costa \(O(b)\), mentre il riempimento e lo svuotamento $O(n).
</p>


<p>
Si potrebbe rendere più generale ammettendo altri intervalli che non partano da \(0\).
Ad esempio, sia \([a,b]\) l'intervallo, allora vi sono \(b-a\) buckets e la posizione dell'elemento con chiave \(k\) è \(k-a\).
</p>
</div>
<div id="outline-container-orgfb487d9" class="outline-5">
<h5 id="orgfb487d9">Differenza con integersort</h5>
<div class="outline-text-5" id="text-orgfb487d9">
<p>
In integerSort per \(n\) numeri fino a \(k\) mi basta usare un array di supporto grande \(k\). Non posso usarlo nei casi in cui all'intero sia associata una chiave.
</p>
</div>
</div>
</div>
<div id="outline-container-org9358443" class="outline-4">
<h4 id="org9358443">RadixSort</h4>
<div class="outline-text-4" id="text-org9358443">
<p>
Estende il <code>bucketSort</code> ammettendo che il numero di bucket sia <b>minore</b> del massimo intero da ordinare.
</p>

<p>
In particolare, il numero di bucket sarà la rappresentazione in base \(b\) della $t$-esima cifra.
</p>

<p>
Per recuperare la $t$-esima cifra bisogna controllare che la <b>divisione intera</b> fra \(k\) e \(b^t\) sia diversa da 0.
</p>
<pre class="example" id="org15f320f">
ALGORITMO bucketSort(Array A[0..n-1], interi b, t)
    Sia Y[0..b-1] un array

    ;; Inizializza buckets Theta(b)
    FOR i &lt;- 0 TO b-1 DO
        Y[i] &lt;- coda vuota

    ;; Riempi buckets Theta(n)
    FOR i &lt;- 0 TO n-1 DO
        c &lt;- t-esima cifra nella rappresentazione...
        ... in base t della chiave di A[i]
        Y[c].enqueue(A[i]))

    j &lt;- 0
    FOR i &lt;- 0 TO b-1 DO
        WHILE NOT Y[i].isEmpty() DO
            A[j] &lt;- Y[i].dequeue()
            j &lt;- j+1

ALGORITMO radixSort(array A[0..n-1])
    t &lt;- 0
    WHILE esiste chiave k in A la cui t-esima cifra != 0 DO
    bucketSort(A,b,t)
    t &lt;- t + 1
</pre>

<p>
Conviene usare una rappresentazione in base \(b\) con \(b = 2^i\) per qualche \(b\). In questo caso, il recupero della cifra in posizione \(t\) del numero \(x\) si ottiene attraverso \(t\) shift a destra di \(i\) posizioni e poi uno AND logico fra il numero ottenuto e \(2^i - 1\).
\[ (x>>ti) AND (2^i-1) \]
</p>

<p>
L'<b>analisi</b> è la seguente: per ogni cifra del numero massimo da ordinare \(m\), viene eseguito un <code>bucketSort</code> di complessità \(O(n + b)\).
</p>

<p>
Il numero di cifre di \(m\) in base \(b\) è \(log_b m\), quindi si ottiene \(log_b m \cdot O(n+b)\).
</p>

<p>
Se la base \(b\) è fissata, si ottiene \(O(n \log m)\). Di conseguenza ci sono due casi delicati:
</p>
<ul class="org-ul">
<li>\(k < n\), ottengo \(O(n\log k)\), mentre <code>bucketSort</code> normale ne richiede \(O(n)\)</li>
<li>\(k > n\), ottengo \(O(n \log n)\), simile o peggiore degli algoritmi basati su confronti.</li>
</ul>

<p>
Questo accade perchè non sfrutto il vantaggio che offre il <code>bucketSort</code> nell'ordinare \(n\) numeri in tempo lineare usando \(n\) buckets.
</p>

<p>
Invece, uso soltanto \(10\) buckets in ogni chiamata, con un tempo che <b>rimane lineare</b> (dato che devo ogni volta inserire e rimuovere gli \(n\) elementi dai buckets), ma lo faccio per \(log_{10} m\) volte.
</p>

<p>
Se, dall'altro lato, scegliessi \(b\) troppo grande, questo peserebbe più di \(n\) nel <code>bucketSort</code>, ovvero \(O(n+b)\) diventerebbe \(O(b)\).
</p>

<p>
Quindi conviene scegliere \(b = \Theta(n)\), in modo da minimizzare il numero di chiamate al <b>bucketSort</b> senza inficiare la loro efficienza.
</p>

<p>
In particolare, effettuo \(log_b k = O(log_n k) = O(\frac{\log_{k}}{\log_{n}})\) di chiamate al bucketSort che ci impiega \(O(n+b)=O(n)\), con un totale di \(O(n\cdot \frac{\log_{k}}{\log_{n}})\). Considerando il caso di \(k<n\), in cui effettuo una sola iterazione, ottengo
\[O(n(1+ \frac{\log_{k}}{\log_{n}}))\]
</p>
</div>
</div>
<div id="outline-container-org6ea68c1" class="outline-4">
<h4 id="org6ea68c1">Riassunto</h4>
<div class="outline-text-4" id="text-org6ea68c1">
<p>
Il <code>bucketSort</code> opera in tempo lineare al numero di elementi o la dimensione dell'intervallo. Quando l'intervallo è troppo grande rispetto al numero di elementi, spende tempo istanziando delle entrate nell'array di supporto che non userà e quel tempo prevale rispetto al reale ordinamento.
</p>

<p>
Per ottimizzare quel caso, introduco il <code>radixSort</code>. Esso mi permette di ridurre la dimensione dei buckets del <code>bucketSort</code> ad un numero arbitrario \(b< n\), così che la chiamata impieghi tempo lineare ad \(n\). In compenso, però, devo farlo più volte per ogni array, ovvero \(\log_b k\), dove \(k\) è la dimensione dell'intervallo che parte da \(0\) in cui si trovano gli elementi (può essere visto come l'elemento massimo).
Il <code>bucketSort</code> standard è una versione particolare del <code>radixSort</code> dove \(b=k\).
</p>

<p>
Quindi si tratta di bilanciare \(O(n+k)\) e \(O(\log_b k (b+n))\).
</p>

<p>
Quando \(b=10\) non ottengo nessun vantaggio dal <code>radixSort</code>, perchè un \(b\) costante non fornisce nessun vantaggio asintotico. Faccio una chiamata al <code>bucketSort</code> di tempo <b>lineare</b> per <b>ogni cifra</b>, ma una <b>sola</b> chiamata di <code>bucketSort</code> standard sull'intero array sarebbe comunque <b>lineare</b>, quindi mi risparmierebbe il fattore moltiplicativo logaritmico rispetto a \(k\).
</p>

<p>
Per ottenere un vantaggio bisogna ridurre al minimo il numero \(\log_{b} k\) di chiamate ricorsive, massimizzando \(b\) senza inficiare il tempo di esecuzione della chiamata a <code>bucketSort</code>.
</p>

<p>
Dato che la chiamata a <code>bucketSort</code> impiega \(O(n+b)\), un \(b>n\) aumenterebbe il tempo di esecuzione. Scegliamo quindi \(b=\Theta(n)\).
</p>

<p>
In questo modo ottengo un tempo sull'ordine di \(n\log_n k\) e quindi l'aumento dovuto all'aumento dell'intervallo \(k\) pesa meno di quanto farebbe nel <code>bucketSort</code> dove peserebbe linearmente.
</p>

<p>
Quindi <code>radixSort</code> con \(b=\Theta(n)\) è sempre meglio di \(b=10\) o quantità piccola.
</p>

<p>
I casi in cui <b>non conviene</b> usarlo sono quelli in cui \(k>>n\), perchè a un certo punto in \(n\log_n k\), aumentando \(k\) si arriva a superare \(n\log n\). Si può provare risolvendo l'equazione \(n(\frac{\log k}{\log n})>n\log n\) in \(k\) (che non so risolvere).
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org73a9288" class="outline-2">
<h2 id="org73a9288">Limite inferiore ai metodi basati sui confronti&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ATTACH">ATTACH</span></span></h2>
<div class="outline-text-2" id="text-org73a9288">
<p>
Vogliamo rispondere alla domanda: "è possibile ordinare array di \(n\) elementi utilizzando un numero di confronti tra chiavi che cresca meno di \(n\log n\)? No.
</p>

<p>
Consideriamo un albero di decisione, ovvero un albero in cui i nodi interni sono delle domande con delle risposte binarie.<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>
</p>

<p>
Costruiamo un 
Applichiamo questo concetto all'ordinamento, iniziando a chiederci se il primo elemento sia minore del secondo.
</p>

<p>
Se rispondessimo sì, dovremmo poi chiederci se il secondo è minore del terzo, e in quel caso avremmo finito, altrimenti rimarebbe da chiederci se il primo è minore del terzo prima che le risposte identifichino univocamente l'ordine. Possiamo fare lo stesso discorso anche nel caso in cui la prima risposta fosse no.
Ogni sequenza diversa di domande termina in una ed una sola foglia, con un valore diverso. Le foglie sono chiaramente \(n!\), perchè corrispondono ad ogni permutazione.
Adesso, io so che l'altezza dell'albero binario è necessariamente maggiore uguale del log2 del numero di nodi (perchè se uno dei lati è minore dell'altezza, l'altro dev'essere maggiore), che è necessariamente maggiore uguale del log2 del numero di foglie (controllare perchè).
Dato che i nodi sono i confronti e le foglie sono le permutazioni, il numero di confronti dev'essere maggiore uguale del log2 di n!.
Ora consideriamo che n! può essere approssimato come \(\sqrt{2\pi n}(\frac{n}{e})^{n}\) (formula di Stirling), e quindi devo calcolare il logaritmo di quella. Considero che il logaritmo di un prodotto è la somma di logaritmi e che il logaritmo di un esponente è l'esponente per il logaritmo. Esce fuori che questa funzione cresce come \(n log n\). Ne segue che ogni algoritmo basato su confronti deve fare un numero di confronti che cresca almeno come questa funzione.
Attenzione al fatto che parliamo del numero di confronti e non del tempo in generale. Il tempo è questo nel caso in cui i confronti richiedano tempo costante.
</p>

<p>
Vedi <a href="Algoritmi/lowerboundcomparisonsorting.pdf">Lower Bound Comparison Sorting</a>
</p>
</div>
</div>
<div id="outline-container-org7a9f6f6" class="outline-2">
<h2 id="org7a9f6f6">Riassunto ordinamento basato su confronti</h2>
<div class="outline-text-2" id="text-org7a9f6f6">
<p>
Nel selectionSort, la prima parte contiene degli elementi già ordinati e ogni volta cerchiamo il minimo della seconda parte e lo mettiamo al posto giusto. Il tempo e \(\Theta n^{2}\) sempre, mentre lo spazio è costante.
</p>

<p>
L'insertionSort ha \(\Theta n^{2}\) nel caso peggiore, ma \(n-1\) nel caso di array già ordinato.
</p>

<p>
Bubblesort fa passate successive, scambiando elementi adiacenti finchè non ne fa un completa senza fare scambi. Il caso peggiore è \(\Theta n^{2}\), ma se l'array è già ordinato fa una sola passata senza fare scambi e si ferma, quindi \(n-1\).
</p>

<p>
Tutti questi algoritmi, detti elementari, operano in loco e fra essi solo il selection non è stabile.
</p>

<p>
Nel mergeSort uso la tecnica divide et impera e divido per poi riunire, fino ad arrivare all'array con un solo elemento.
Usa spazio ovvero dell'ordine di n. Perchè serve uno spazio theta di n per l'array ausiliario e di log n per lo stack ricorsivo.
</p>

<p>
Nel quicksort il caso peggiore è \(n^{2}\), circa \(n log n\) nel caso migliore. Anche lui è divide et impera, ma quello che costa tanto è la divisione e infatti il caso migliore è quando viene diviso in due parti di lunghezza simile. In media, impiega \(1.39 n log n\). Quindi il caso peggiore contribuisce molto poco alla media e avviene poco frequentemente. L'algoritmo in sè è in loco, tuttavia c'è lo stack ricorsivo; quindi, nella versione base è su theta di n, ma in quella migliorata del log n
In heapsort il numero di confronti è \(\Theta(n\log n)\), opera in loco e non è stabile.
</p>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Per alcune domande, questo albero risulta essere abbastanza bilanciato, mentre in altri casi cresce solo da una parte, ad esempio l'albero di ricerca di un array se le domande fossero "è maggiore della metà" o "è questo o no?".
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="date">Created: 2025-02-02 Sun 11:41</p>
</div>
</body>
</html>
